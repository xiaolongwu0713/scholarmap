{"ts": "2026-01-11T02:34:59.083803+00:00", "event": "phase2.affiliation_extraction.prompt", "batch_size": 2, "model": "gpt-5.2", "prompt_file": "/Users/xiaowu/local_code/scholarmap/prompts/affiliation_extraction.md", "full_prompt": "You are a geographic data extractor for academic affiliations.\n\nExtract the following from each affiliation string:\n- country: Full country name (e.g., \"United States\", \"United Kingdom\", \"China\")\n- city: City name if present (e.g., \"Boston\", \"London\", \"Beijing\")\n- institution: Primary institution name if present (e.g., \"Harvard Medical School\", \"MIT\")\n\nRules:\n1. Return exact matches from the text, don't invent information\n2. If a field is missing or unclear, return null\n3. Use full country names, not abbreviations (USA → United States)\n4. confidence: \"high\" if all fields clear, \"medium\" if some unclear, \"low\" if very ambiguous, \"none\" if no geographic info\n\nIMPORTANT - City extraction rules:\n- DO NOT extract US state abbreviations (MD, OH, WV, NY, CA, etc.) as cities\n- DO NOT extract institution names (e.g., \"Department of Health\", \"UC Berkeley\", \"Harvard Medical School\") as cities\n- DO NOT extract department names (e.g., \"Department of Physiology\", \"Departments of Neurosurgery\") as cities\n- DO NOT extract format errors (e.g., \"New York NY USA\", \"MD USA\") as cities\n- Only extract actual city names (e.g., \"Boston\", \"Albany\", \"San Francisco\", \"New York\" without state/abbreviations)\n- If you see \"MD USA\" or \"OH USA\", the city should be null (these are state abbreviations, not cities)\n- If you see \"Department of X\" or \"UC Berkeley\", extract it as institution, not city\n\nReturn a JSON array with one object per affiliation in the EXACT same order as input:\n[\n  {\"country\": \"United States\", \"city\": \"Boston\", \"institution\": \"Massachusetts General Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"China\", \"city\": \"Beijing\", \"institution\": null, \"confidence\": \"medium\"},\n  ...\n]\n\nAffiliations to process:\n1. Anesthesiology and Perioperative Care; and.\n2. King Fahad Medical City, KFMC Neurosciences Center, Riyadh, Saudi Arabia; and.\n\n"}
{"ts": "2026-01-11T02:35:00.906802+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "```json\n[\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"none\"\n  },\n  {\n    \"country\": \"Saudi Arabia\",\n    \"city\": \"Riyadh\",\n    \"institution\": \"King Fahad Medical City, KFMC Neurosciences Center\",\n    \"confidence\": \"high\"\n  }\n]\n```"}
{"ts": "2026-01-11T02:35:00.907283+00:00", "event": "phase2.affiliation_extraction.response", "batch_size": 2, "model": "gpt-5.2", "raw_json_response": "```json\n[\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"none\"\n  },\n  {\n    \"country\": \"Saudi Arabia\",\n    \"city\": \"Riyadh\",\n    \"institution\": \"King Fahad Medical City, KFMC Neurosciences Center\",\n    \"confidence\": \"high\"\n  }\n]\n```"}
{"ts": "2026-01-11T04:06:22.971141+00:00", "event": "phase2.affiliation_extraction.prompt", "batch_size": 2, "model": "gpt-5.2", "prompt_file": "/Users/xiaowu/local_code/scholarmap/prompts/affiliation_extraction.md", "full_prompt": "You are a geographic data extractor for academic affiliations.\n\nExtract the following from each affiliation string:\n- country: Full country name (e.g., \"United States\", \"United Kingdom\", \"China\")\n- city: City name (e.g., \"Boston\", \"London\", \"Beijing\")\n- institution: Primary institution name if present (e.g., \"Harvard Medical School\", \"MIT\")\n\n\nRules:\n1. Guess the missing info based on the available info. \n2. Use full country names, not abbreviations (USA → United States)\n3. confidence: \"high\" if all fields clear, \"medium\" if some unclear, \"low\" if very ambiguous\n\nIMPORTANT - Country and City extraction rules:\n- DO NOT extract US state abbreviations (MD, OH, WV, NY, CA, etc.) as cities\n- Only extract actual city names (e.g., \"Boston\", \"Albany\", \"San Francisco\", \"New York\" without state/abbreviations)\n- The guess should be valid and true. For example, \"Massachusetts Institute of Technology, Cambridge, MA 02139\" should be inferred as United States. It would be wrong if it is inferred as 'Cambridge, Morocco', even MA is the country code for Morocco.\n\n\nReturn a JSON array with one object per affiliation in the EXACT same order as input:\n[\n  {\"country\": \"United States\", \"city\": \"Boston\", \"institution\": \"Massachusetts General Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"China\", \"city\": \"Beijing\", \"institution\": null, \"confidence\": \"medium\"},\n  ...\n]\n\nAffiliations to process:\n1. King Fahad Medical City, KFMC Neurosciences Center, Riyadh, Saudi Arabia; and.\n2. Anesthesiology and Perioperative Care; and.\n\n"}
{"ts": "2026-01-11T04:06:27.574171+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "[\n  {\n    \"country\": \"Saudi Arabia\",\n    \"city\": \"Riyadh\",\n    \"institution\": \"King Fahad Medical City\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"low\"\n  }\n]"}
{"ts": "2026-01-11T04:06:27.574912+00:00", "event": "phase2.affiliation_extraction.response", "batch_size": 2, "model": "gpt-5.2", "raw_json_response": "[\n  {\n    \"country\": \"Saudi Arabia\",\n    \"city\": \"Riyadh\",\n    \"institution\": \"King Fahad Medical City\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"low\"\n  }\n]"}
{"ts": "2026-01-11T04:11:00.218510+00:00", "event": "phase2.affiliation_extraction.prompt", "batch_size": 1, "model": "gpt-5.2", "prompt_file": "/Users/xiaowu/local_code/scholarmap/prompts/affiliation_extraction.md", "full_prompt": "You are a geographic data extractor for academic affiliations.\n\nExtract the following from each affiliation string:\n- country: Full country name (e.g., \"United States\", \"United Kingdom\", \"China\")\n- city: City name (e.g., \"Boston\", \"London\", \"Beijing\")\n- institution: Primary institution name if present (e.g., \"Harvard Medical School\", \"MIT\")\n\n\nRules:\n1. Guess the missing info based on the available info. \n2. Use full country names, not abbreviations (USA → United States)\n3. confidence: \"high\" if all fields clear, \"medium\" if some unclear, \"low\" if very ambiguous\n\nIMPORTANT - Country and City extraction rules:\n- DO NOT extract US state abbreviations (MD, OH, WV, NY, CA, etc.) as cities\n- Only extract actual city names (e.g., \"Boston\", \"Albany\", \"San Francisco\", \"New York\" without state/abbreviations)\n- The guess should be valid and true. For example, \"Massachusetts Institute of Technology, Cambridge, MA 02139\" should be inferred as United States. It would be wrong if it is inferred as 'Cambridge, Morocco', even MA is the country code for Morocco.\n\n\nReturn a JSON array with one object per affiliation in the EXACT same order as input:\n[\n  {\"country\": \"United States\", \"city\": \"Boston\", \"institution\": \"Massachusetts General Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"China\", \"city\": \"Beijing\", \"institution\": null, \"confidence\": \"medium\"},\n  ...\n]\n\nAffiliations to process:\n1. Anesthesiology and Perioperative Care; and.\n\n"}
{"ts": "2026-01-11T04:11:02.254768+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "[\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"low\"\n  }\n]"}
{"ts": "2026-01-11T04:11:02.255574+00:00", "event": "phase2.affiliation_extraction.response", "batch_size": 1, "model": "gpt-5.2", "raw_json_response": "[\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"low\"\n  }\n]"}
{"ts": "2026-01-11T04:32:21.759902+00:00", "event": "phase2.affiliation_extraction.prompt", "batch_size": 1, "model": "gpt-5.2", "prompt_file": "/Users/xiaowu/local_code/scholarmap/prompts/affiliation_extraction.md", "full_prompt": "You are a geographic data extractor for academic affiliations.\n\nExtract the following from each affiliation string:\n- country: Full country name (e.g., \"United States\", \"United Kingdom\", \"China\")\n- city: City name (e.g., \"Boston\", \"London\", \"Beijing\")\n- institution: Primary institution name if present (e.g., \"Harvard Medical School\", \"MIT\")\n\n\nRules:\n1. Guess the missing info based on the available info. \n2. Use full country names, not abbreviations (USA → United States)\n3. confidence: \"high\" if all fields clear, \"medium\" if some unclear, \"low\" if very ambiguous\n\nIMPORTANT - Country and City extraction rules:\n- DO NOT extract US state abbreviations (MD, OH, WV, NY, CA, etc.) as cities\n- Only extract actual city names (e.g., \"Boston\", \"Albany\", \"San Francisco\", \"New York\" without state/abbreviations)\n- The guess should be valid and true. For example, \"Massachusetts Institute of Technology, Cambridge, MA 02139\" should be inferred as United States. It would be wrong if it is inferred as 'Cambridge, Morocco', even MA is the country code for Morocco.\n\n\nReturn a JSON array with one object per affiliation in the EXACT same order as input:\n[\n  {\"country\": \"United States\", \"city\": \"Boston\", \"institution\": \"Massachusetts General Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"China\", \"city\": \"Beijing\", \"institution\": null, \"confidence\": \"medium\"},\n  ...\n]\n\nAffiliations to process:\n1. Anesthesiology and Perioperative Care; and.\n\n"}
{"ts": "2026-01-11T04:32:23.362105+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "[\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"low\"\n  }\n]"}
{"ts": "2026-01-11T04:32:23.362727+00:00", "event": "phase2.affiliation_extraction.response", "batch_size": 1, "model": "gpt-5.2", "raw_json_response": "[\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"low\"\n  }\n]"}
{"ts": "2026-01-11T04:48:28.559232+00:00", "event": "phase2.affiliation_extraction.prompt", "batch_size": 1, "model": "gpt-5.2", "prompt_file": "/Users/xiaowu/local_code/scholarmap/prompts/affiliation_extraction.md", "full_prompt": "You are a geographic data extractor for academic affiliations.\n\nExtract the following from each affiliation string:\n- country: Full country name (e.g., \"United States\", \"United Kingdom\", \"China\")\n- city: City name (e.g., \"Boston\", \"London\", \"Beijing\")\n- institution: Primary institution name if present (e.g., \"Harvard Medical School\", \"MIT\")\n\n\nRules:\n1. Guess the missing info based on the available info. \n2. Use full country names, not abbreviations (USA → United States)\n3. confidence: \"high\" if all fields clear, \"medium\" if some unclear, \"low\" if very ambiguous\n\nIMPORTANT - Country and City extraction rules:\n- DO NOT extract US state abbreviations (MD, OH, WV, NY, CA, etc.) as cities\n- Only extract actual city names (e.g., \"Boston\", \"Albany\", \"San Francisco\", \"New York\" without state/abbreviations)\n- The guess should be valid and true. For example, \"Massachusetts Institute of Technology, Cambridge, MA 02139\" should be inferred as United States. It would be wrong if it is inferred as 'Cambridge, Morocco', even MA is the country code for Morocco.\n\n\nReturn a JSON array with one object per affiliation in the EXACT same order as input:\n[\n  {\"country\": \"United States\", \"city\": \"Boston\", \"institution\": \"Massachusetts General Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"China\", \"city\": \"Beijing\", \"institution\": null, \"confidence\": \"medium\"},\n  ...\n]\n\nAffiliations to process:\n1. Anesthesiology and Perioperative Care; and.\n\n"}
{"ts": "2026-01-11T04:48:29.494439+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "[\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"low\"\n  }\n]"}
{"ts": "2026-01-11T04:48:29.495331+00:00", "event": "phase2.affiliation_extraction.response", "batch_size": 1, "model": "gpt-5.2", "raw_json_response": "[\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"low\"\n  }\n]"}
{"ts": "2026-01-11T04:55:04.848667+00:00", "event": "phase2.affiliation_extraction.prompt", "batch_size": 1, "model": "gpt-5.2", "prompt_file": "/Users/xiaowu/local_code/scholarmap/prompts/affiliation_extraction.md", "full_prompt": "You are a geographic data extractor for academic affiliations.\n\nExtract the following from each affiliation string:\n- country: Full country name (e.g., \"United States\", \"United Kingdom\", \"China\")\n- city: City name (e.g., \"Boston\", \"London\", \"Beijing\")\n- institution: Primary institution name if present (e.g., \"Harvard Medical School\", \"MIT\")\n\n\nRules:\n1. Guess the missing info based on the available info. \n2. Use full country names, not abbreviations (USA → United States)\n3. confidence: \"high\" if all fields clear, \"medium\" if some unclear, \"low\" if very ambiguous\n\nIMPORTANT - Country and City extraction rules:\n- DO NOT extract US state abbreviations (MD, OH, WV, NY, CA, etc.) as cities\n- Only extract actual city names (e.g., \"Boston\", \"Albany\", \"San Francisco\", \"New York\" without state/abbreviations)\n- The guess should be valid and true. For example, \"Massachusetts Institute of Technology, Cambridge, MA 02139\" should be inferred as United States. It would be wrong if it is inferred as 'Cambridge, Morocco', even MA is the country code for Morocco.\n\n\nReturn a JSON array with one object per affiliation in the EXACT same order as input:\n[\n  {\"country\": \"United States\", \"city\": \"Boston\", \"institution\": \"Massachusetts General Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"China\", \"city\": \"Beijing\", \"institution\": null, \"confidence\": \"medium\"},\n  ...\n]\n\nAffiliations to process:\n1. Anesthesiology and Perioperative Care; and.\n\n"}
{"ts": "2026-01-11T04:55:06.442659+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "[\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"low\"\n  }\n]"}
{"ts": "2026-01-11T04:55:06.443324+00:00", "event": "phase2.affiliation_extraction.response", "batch_size": 1, "model": "gpt-5.2", "raw_json_response": "[\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"low\"\n  }\n]"}
{"ts": "2026-01-11T05:32:01.462183+00:00", "event": "phase2.affiliation_extraction.prompt", "batch_size": 3, "model": "gpt-5.2", "prompt_file": "/Users/xiaowu/local_code/scholarmap/prompts/affiliation_extraction.md", "full_prompt": "You are a geographic data extractor for academic affiliations.\n\nExtract the following from each affiliation string:\n- country: Full country name (e.g., \"United States\", \"United Kingdom\", \"China\")\n- city: City name (e.g., \"Boston\", \"London\", \"Beijing\")\n- institution: Primary institution name if present (e.g., \"Harvard Medical School\", \"MIT\")\n\n\nRules:\n1. Guess the missing info based on the available info. \n2. Use full country names, not abbreviations (USA → United States)\n3. confidence: \"high\" if all fields clear, \"medium\" if some unclear, \"low\" if very ambiguous\n\nIMPORTANT - Country and City extraction rules:\n- DO NOT extract US state abbreviations (MD, OH, WV, NY, CA, etc.) as cities\n- Only extract actual city names (e.g., \"Boston\", \"Albany\", \"San Francisco\", \"New York\" without state/abbreviations)\n- The guess should be valid and true. For example, \"Massachusetts Institute of Technology, Cambridge, MA 02139\" should be inferred as United States. It would be wrong if it is inferred as 'Cambridge, Morocco', even MA is the country code for Morocco.\n\n\nReturn a JSON array with one object per affiliation in the EXACT same order as input:\n[\n  {\"country\": \"United States\", \"city\": \"Boston\", \"institution\": \"Massachusetts General Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"China\", \"city\": \"Beijing\", \"institution\": null, \"confidence\": \"medium\"},\n  ...\n]\n\nAffiliations to process:\n1. Anesthesiology and Perioperative Care; and.\n2. Brain & Cognitive Sciences Department, McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA 02139.\n3. Brain & Cognitive Sciences Department, McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA 02139 evelina.fedorenko@mgh.harvard.edu ngk@mit.edu.\n\n"}
{"ts": "2026-01-11T05:32:03.574421+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "```json\n[\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"low\"\n  },\n  {\n    \"country\": \"United States\",\n    \"city\": \"Cambridge\",\n    \"institution\": \"Massachusetts Institute of Technology\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"United States\",\n    \"city\": \"Cambridge\",\n    \"institution\": \"Massachusetts Institute of Technology\",\n    \"confidence\": \"high\"\n  }\n]\n```"}
{"ts": "2026-01-11T05:32:03.575039+00:00", "event": "phase2.affiliation_extraction.response", "batch_size": 3, "model": "gpt-5.2", "raw_json_response": "```json\n[\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"low\"\n  },\n  {\n    \"country\": \"United States\",\n    \"city\": \"Cambridge\",\n    \"institution\": \"Massachusetts Institute of Technology\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"United States\",\n    \"city\": \"Cambridge\",\n    \"institution\": \"Massachusetts Institute of Technology\",\n    \"confidence\": \"high\"\n  }\n]\n```"}
{"ts": "2026-01-11T06:43:42.716350+00:00", "event": "phase2.affiliation_extraction.prompt", "batch_size": 3, "model": "gpt-5.2", "prompt_file": "/Users/xiaowu/local_code/scholarmap/prompts/affiliation_extraction.md", "full_prompt": "You are a geographic data extractor for academic affiliations.\n\nExtract the following from each affiliation string:\n- country: Full country name (e.g., \"United States\", \"United Kingdom\", \"China\")\n- city: City name (e.g., \"Boston\", \"London\", \"Beijing\")\n- institution: Primary institution name if present (e.g., \"Harvard Medical School\", \"MIT\")\n\n\nRules:\n1. Guess the missing info based on the available info. \n2. Use full country names, not abbreviations (USA → United States)\n3. confidence: \"high\" if all fields clear, \"medium\" if some unclear, \"low\" if very ambiguous\n\nIMPORTANT - Country and City extraction rules:\n- DO NOT extract US state abbreviations (MD, OH, WV, NY, CA, etc.) as cities\n- Only extract actual city names (e.g., \"Boston\", \"Albany\", \"San Francisco\", \"New York\" without state/abbreviations)\n- The guess should be valid and true. For example, \"Massachusetts Institute of Technology, Cambridge, MA 02139\" should be inferred as United States. It would be wrong if it is inferred as 'Cambridge, Morocco', even MA is the country code for Morocco.\n\n\nReturn a JSON array with one object per affiliation in the EXACT same order as input:\n[\n  {\"country\": \"United States\", \"city\": \"Boston\", \"institution\": \"Massachusetts General Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"China\", \"city\": \"Beijing\", \"institution\": null, \"confidence\": \"medium\"},\n  ...\n]\n\nAffiliations to process:\n1. Anesthesiology and Perioperative Care; and.\n2. Brain & Cognitive Sciences Department, McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA 02139.\n3. Brain & Cognitive Sciences Department, McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, MA 02139 evelina.fedorenko@mgh.harvard.edu ngk@mit.edu.\n\n"}
{"ts": "2026-01-11T06:43:45.867280+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "```json\n[\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"low\"\n  },\n  {\n    \"country\": \"United States\",\n    \"city\": \"Cambridge\",\n    \"institution\": \"Massachusetts Institute of Technology\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"United States\",\n    \"city\": \"Cambridge\",\n    \"institution\": \"Massachusetts Institute of Technology\",\n    \"confidence\": \"high\"\n  }\n]\n```"}
{"ts": "2026-01-11T06:43:45.868166+00:00", "event": "phase2.affiliation_extraction.response", "batch_size": 3, "model": "gpt-5.2", "raw_json_response": "```json\n[\n  {\n    \"country\": null,\n    \"city\": null,\n    \"institution\": null,\n    \"confidence\": \"low\"\n  },\n  {\n    \"country\": \"United States\",\n    \"city\": \"Cambridge\",\n    \"institution\": \"Massachusetts Institute of Technology\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"United States\",\n    \"city\": \"Cambridge\",\n    \"institution\": \"Massachusetts Institute of Technology\",\n    \"confidence\": \"high\"\n  }\n]\n```"}
{"ts": "2026-01-12T02:54:25.513206+00:00", "event": "parse.stage1.prompt", "project_id": "2098072fb7af", "run_id": "8dfb44f56623", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/xiaowu/local_code/scholarmap/prompts/parse_stage1_understanding.md", "prompt": "你是“研究描述理解与规范化”模块。输入是一段纯文本候选研究描述。你的目标是帮助用户把研究描述变得合理且清晰，便于后续生成文献检索查询。\n\n你必须完成：\n1) 判断这段描述是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true.\n2) 如果是研究描述,进行常识可行性判断（plausibility_level）：\n- A_impossible：明显荒诞/违背当前科技常识（无法形成合理检索任务）\n- B_plausible：合理可行\n3) 如果合理可行，给出你对该研究描述的“当前理解”（normalized_understanding），用规范化、聚焦、可检索的英语重写，\n4) 判断当前理解是否已经清晰到可以用于检索；若不清晰，列出你仍不确定的点（疑问清单），并提出最多3个澄清问题（问题必须具体可回答）。\n5) 输出结构化提要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n6) 只输出JSON，不输出任何额外文本。\n\n候选研究描述：\n\"\"\"I focus on brain computer interface based on the invasive signals.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n}\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - ncertainties/missing_fields/suggested_questions为空数组[];\n  - structured_summary为全null；\n- normalized_understanding：300-600个英文字符，必须是你对研究的“当前理解”，语言规范、聚焦、可检索；不要写“我认为/可能”等口水话，直接用陈述句组织。\n\n- 如果 是B_plausible，且 is_clear_for_search=true，则：\n  - is_research_description = true\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空数组或只保留0-1条轻微风险\n\n- 如果 是B_plausible，且 is_clear_for_search=false，则：\n  - is_research_description = true\n  - uncertainties 至少2条\n  - missing_fields 仅列出缺失项\n  - suggested_questions 为1-3条，必须与 uncertainties/missing_fields 对应\n\n- 如果 plausibility_level=A_impossible，则：\n  - is_clear_for_search=false\n  - suggested_questions 为空\n  - uncertainties <=200英文字符：给出impossible的原因。\n"}
{"ts": "2026-01-12T02:54:37.179189+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on invasive-signal-based brain–computer interfaces (BCIs) that acquire neural activity via implanted electrodes (e.g., intracortical microelectrode arrays, ECoG grids, or depth electrodes) and decode these signals into control commands for external devices. The work may cover signal acquisition, preprocessing, feature extraction, neural decoding algorithms, and real-time closed-loop control, with attention to performance, robustness, and safety in human or animal studies.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces / neuroengineering\",\n    \"task\": \"Decode invasive neural signals into control outputs for communication or device control\",\n    \"subject_system\": \"Implanted neural recording systems (intracortical, ECoG, or depth electrodes) in humans or animals\",\n    \"methods\": \"Neural signal processing and decoding (feature extraction, machine learning / deep learning, real-time closed-loop control)\",\n    \"scope\": \"Invasive recording modalities and end-to-end BCI pipeline; specific modality/application not specified\",\n    \"intent\": \"Enable reliable BCI control using invasive neural recordings; improve accuracy/latency/robustness\",\n    \"exclusions\": \"Non-invasive BCIs (EEG/MEG/fNIRS) unless used for comparison\"\n  },\n  \"uncertainties\": [\n    \"The invasive modality is unspecified (intracortical spikes/LFP, ECoG, SEEG), which strongly affects keywords and relevant literature.\",\n    \"The target application and output type are unclear (motor prosthesis, cursor control, speech decoding, communication), limiting query focus.\",\n    \"The intended methods and evaluation setting are not defined (ML vs. classical decoding; human clinical vs. animal; online vs. offline).\"\n  ],\n  \"missing_fields\": [\"task\", \"subject_system\", \"methods\", \"scope\", \"intent\", \"exclusions\"],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Which invasive recording modality do you mean: intracortical microelectrode arrays (spikes/LFP), ECoG grids/strips, or depth electrodes (SEEG)?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What is the primary BCI application/output you target (e.g., cursor control, robotic/prosthetic limb control, speech decoding, communication speller)?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What decoding approach and evaluation setting are you focusing on (e.g., Kalman filter/LDA vs. deep learning; offline decoding vs. real-time closed-loop; human vs. animal data)?\"\n    }\n  ]\n}", "project_id": "2098072fb7af", "run_id": "8dfb44f56623", "stage": "stage1"}
{"ts": "2026-01-12T02:54:37.179945+00:00", "event": "parse.stage1.response", "project_id": "2098072fb7af", "run_id": "8dfb44f56623", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on invasive-signal-based brain–computer interfaces (BCIs) that acquire neural activity via implanted electrodes (e.g., intracortical microelectrode arrays, ECoG grids, or depth electrodes) and decode these signals into control commands for external devices. The work may cover signal acquisition, preprocessing, feature extraction, neural decoding algorithms, and real-time closed-loop control, with attention to performance, robustness, and safety in human or animal studies.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces / neuroengineering\",\n    \"task\": \"Decode invasive neural signals into control outputs for communication or device control\",\n    \"subject_system\": \"Implanted neural recording systems (intracortical, ECoG, or depth electrodes) in humans or animals\",\n    \"methods\": \"Neural signal processing and decoding (feature extraction, machine learning / deep learning, real-time closed-loop control)\",\n    \"scope\": \"Invasive recording modalities and end-to-end BCI pipeline; specific modality/application not specified\",\n    \"intent\": \"Enable reliable BCI control using invasive neural recordings; improve accuracy/latency/robustness\",\n    \"exclusions\": \"Non-invasive BCIs (EEG/MEG/fNIRS) unless used for comparison\"\n  },\n  \"uncertainties\": [\n    \"The invasive modality is unspecified (intracortical spikes/LFP, ECoG, SEEG), which strongly affects keywords and relevant literature.\",\n    \"The target application and output type are unclear (motor prosthesis, cursor control, speech decoding, communication), limiting query focus.\",\n    \"The intended methods and evaluation setting are not defined (ML vs. classical decoding; human clinical vs. animal; online vs. offline).\"\n  ],\n  \"missing_fields\": [\"task\", \"subject_system\", \"methods\", \"scope\", \"intent\", \"exclusions\"],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Which invasive recording modality do you mean: intracortical microelectrode arrays (spikes/LFP), ECoG grids/strips, or depth electrodes (SEEG)?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What is the primary BCI application/output you target (e.g., cursor control, robotic/prosthetic limb control, speech decoding, communication speller)?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What decoding approach and evaluation setting are you focusing on (e.g., Kalman filter/LDA vs. deep learning; offline decoding vs. real-time closed-loop; human vs. animal data)?\"\n    }\n  ]\n}"}
{"ts": "2026-01-12T02:57:07.825730+00:00", "event": "parse.stage2.prompt", "project_id": "2098072fb7af", "run_id": "8dfb44f56623", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/xiaowu/local_code/scholarmap/prompts/parse_stage2_converge.md", "prompt": "你是“研究描述自我收敛器”。你将收到三段文本：\n(1) 当前候选研究描述 current_description\n(2) 关于当前研究描述的问题question_for_user\n(3) 用户本轮补充信息 user_additional_info（可能回答了你上轮的问题，也可能没有）\n\n你的任务是：\n1) 判断当前候选研究描述和用户本轮补充信息是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true，并将两段文本融合，形成你对研究内容的“当前理解”，并判断更新后的研究内容是否合理：\n- A_impossible：明显荒诞/违背当前科技常识，无法形成合理检索任务\n- B_plausible：合理可行\n2) 如果A_impossible，给出简单的理由。如果新的理解是合理可行的，就用规范、聚焦、可检索的英文重写（300-600英文字符），这段重写用于帮助用户组织语言与规范表述。\n3) 判断本轮补充的信息是否对解答question_for_user有帮助。有帮助的话就返回 is_helpful=true。\n4) 如果在新增信息后仍不清晰：输出你仍不确定的点（uncertainties），并提出最多3个澄清问题（具体可回答，优先信息增益最大）。\n5) 如果已经清晰：不要再提问题；只输出你的理解与结构化摘要。\n6) 输出结构化摘要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n只输出JSON，不输出任何额外文字。\n\ncurrent_description：\n\"\"\"I focus on brain computer interface based on the invasive signals.\"\"\"\n\nquestion_for_user：\n\"\"\"Which invasive recording modality do you mean: intracortical microelectrode arrays (spikes/LFP), ECoG grids/strips, or depth electrodes (SEEG)?\nWhat is the primary BCI application/output you target (e.g., cursor control, robotic/prosthetic limb control, speech decoding, communication speller)?\nWhat decoding approach and evaluation setting are you focusing on (e.g., Kalman filter/LDA vs. deep learning; offline decoding vs. real-time closed-loop; human vs. animal data)?\"\"\"\n\n\nuser_additional_info（用户本轮补充信息，可能为空）：\n\"\"\"There is no restriction on the invasive recording modality, approach, or evaluation setting. The primary BCI application is movement.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"is_helpful\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n  }\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - 其他所有字段都为空。\n- normalized_understanding：300-600英文字符，必须是你融合两段文本后的“当前理解”，术语一致、范围聚焦。\n- 如果 plausibility_level=B_plausible且is_clear_for_search=true：\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空或最多1条轻微风险\n- 如果 plausibility_level=B_plausible且is_clear_for_search=false：\n  - uncertainties 至少2条\n  - suggested_questions 为1-3条，必须与uncertainties/missing_fields一致\n\n- 如果 plausibility_level=A_impossible：\n  - is_clear_for_search 必须为 false\n  - suggested_questions 必须为空数组\n  - uncertainties <=200英文字符：提示用户impossible的原因。\n"}
{"ts": "2026-01-12T02:57:17.603713+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"My research focuses on invasive-signal brain–computer interfaces for movement-related decoding and control. I aim to map neural activity recorded with invasive modalities (e.g., intracortical arrays, ECoG, or depth electrodes) to movement intent/kinematics for applications such as cursor or prosthetic/robotic limb control. I am open to a broad range of decoding approaches and evaluation settings, including classical and deep-learning methods, offline analyses, and real-time closed-loop experiments.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces (BCI); neural decoding from invasive recordings\",\n    \"task\": \"Decode movement intent/kinematics and generate control outputs\",\n    \"subject_system\": \"Invasive neural recordings (intracortical, ECoG, or depth electrodes) from human or animal subjects\",\n    \"methods\": \"Neural decoding models (classical filters/classifiers and deep learning); offline and/or real-time closed-loop evaluation\",\n    \"scope\": \"Movement-focused invasive BCI without restricting modality, algorithm family, or evaluation setting\",\n    \"intent\": \"Enable movement-related control (e.g., cursor/prosthetic/robotic limb) from invasive brain signals\",\n    \"exclusions\": \"Not specified\"\n  },\n  \"uncertainties\": [\n    \"The specific invasive modality, subject population, and movement output (kinematics vs discrete actions) are unspecified, which makes search queries broad.\",\n    \"The intended application context (cursor vs prosthetic/robotic limb vs general motor decoding) and evaluation regime (offline vs closed-loop) are not prioritized.\"\n  ],\n  \"missing_fields\": [\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Do you primarily work with human clinical recordings, non-human primates, or rodents, and which brain areas (e.g., M1/PMd/S1) are most relevant?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What movement output do you target: continuous kinematics (position/velocity/force), discrete reach/grasp classes, or muscle/EMG proxies?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which application should be emphasized for search: cursor control, prosthetic/robotic limb control, or general motor-intent decoding, and is closed-loop performance a key focus?\"\n    }\n  ]\n}", "project_id": "2098072fb7af", "run_id": "8dfb44f56623", "stage": "stage2"}
{"ts": "2026-01-12T02:57:17.604660+00:00", "event": "parse.stage2.response", "project_id": "2098072fb7af", "run_id": "8dfb44f56623", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"My research focuses on invasive-signal brain–computer interfaces for movement-related decoding and control. I aim to map neural activity recorded with invasive modalities (e.g., intracortical arrays, ECoG, or depth electrodes) to movement intent/kinematics for applications such as cursor or prosthetic/robotic limb control. I am open to a broad range of decoding approaches and evaluation settings, including classical and deep-learning methods, offline analyses, and real-time closed-loop experiments.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces (BCI); neural decoding from invasive recordings\",\n    \"task\": \"Decode movement intent/kinematics and generate control outputs\",\n    \"subject_system\": \"Invasive neural recordings (intracortical, ECoG, or depth electrodes) from human or animal subjects\",\n    \"methods\": \"Neural decoding models (classical filters/classifiers and deep learning); offline and/or real-time closed-loop evaluation\",\n    \"scope\": \"Movement-focused invasive BCI without restricting modality, algorithm family, or evaluation setting\",\n    \"intent\": \"Enable movement-related control (e.g., cursor/prosthetic/robotic limb) from invasive brain signals\",\n    \"exclusions\": \"Not specified\"\n  },\n  \"uncertainties\": [\n    \"The specific invasive modality, subject population, and movement output (kinematics vs discrete actions) are unspecified, which makes search queries broad.\",\n    \"The intended application context (cursor vs prosthetic/robotic limb vs general motor decoding) and evaluation regime (offline vs closed-loop) are not prioritized.\"\n  ],\n  \"missing_fields\": [\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Do you primarily work with human clinical recordings, non-human primates, or rodents, and which brain areas (e.g., M1/PMd/S1) are most relevant?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What movement output do you target: continuous kinematics (position/velocity/force), discrete reach/grasp classes, or muscle/EMG proxies?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which application should be emphasized for search: cursor control, prosthetic/robotic limb control, or general motor-intent decoding, and is closed-loop performance a key focus?\"\n    }\n  ]\n}"}
{"ts": "2026-01-12T03:19:42.759304+00:00", "event": "phase1.parse.prompt", "project_id": "2098072fb7af", "run_id": "8dfb44f56623", "model": "gpt-5.2", "reasoning_effort": "high", "prompt": "You are an expert academic search strategist specializing in exhaustive literature retrieval. \n\nBelow is a short research summary, your task is to take above research summary and directly produce a conceptual retrieval framework that can be used to systematically search for all relevant literature in that research field.\n\n-- research summary begin --\nMy research focuses on invasive-signal brain–computer interfaces for movement-related decoding and control. I aim to map neural activity recorded with invasive modalities (e.g., intracortical arrays, ECoG, or depth electrodes) to movement intent/kinematics for applications such as cursor or prosthetic/robotic limb control. I am open to a broad range of decoding approaches and evaluation settings, including classical and deep-learning methods, offline analyses, and real-time closed-loop experiments.\n-- research summary end --\n\nThis is NOT a query-generation task.\nThis is a concept-framework construction task.\n\nYou must follow these rules strictly:\n\n1. Base the framework ONLY on the content explicitly stated or clearly implied in the research summary.\n   - Do NOT introduce new research goals, populations, or application domains.\n   - Do NOT speculate beyond the summary.\n\n2. The output must define a SMALL NUMBER of concept blocks (typically 2–4).\n   - Each block represents a distinct and independently searchable conceptual dimension\nthat should not be merged with other dimensions if doing so would reduce recall.\n   - Examples include: research task, technical field/framing, data modality.\n   - All blocks together must uniquely define ONE narrow research field.\n\nIMPORTANT — Concept Block Separation Rule:\n\nWhen constructing concept blocks, prioritize retrieval independence over semantic compactness.\n\nIf two concepts frequently appear separately in relevant literature\n(e.g., one may be mentioned without the other in titles/abstracts),\nthey MUST be placed in separate concept blocks,\neven if they form a well-known combined phrase or subfield name.\n\nExample:\n- “speech” and “brain-computer interface” must be separate blocks,\n  because many relevant papers mention speech decoding without explicitly using “BCI”,\n  and others mention BCI without explicitly using “speech”.\n\n\n3. Each concept block must:\n   - Contain only terms that are conceptually equivalent within that block.\n   - Be expressed using terminology commonly found in academic databases.\n   - Include common synonyms, abbreviations, and canonical terms used in the literature.\n\n4. When the summary uses abstract or high-level language, normalize it into concrete, database-searchable concepts\n   ONLY when such normalization is standard practice in the field.\n   - Example: “invasive recordings” → ECoG, sEEG, intracortical recordings, MEA\n   - Do NOT introduce loosely related or adjacent techniques.\n\n5. All concept blocks must be REQUIRED.\n   - The framework should be designed for exhaustive retrieval within a specific field,\n     not for exploratory or cross-domain search.\n\n6. Do NOT generate executable Boolean queries.\n   - You MAY describe the logical relationship between blocks conceptually\n     (e.g., “documents must address all blocks simultaneously”),\n     but do not use database syntax.\n\n7. Explicitly prevent topic drift.\n   - The framework should clearly exclude adjacent but distinct research areas.\n\n### Output Format (must follow exactly):\n\n## Conceptual Retrieval Framework\n\n### Block A: [Concept Block Name]\n- Concept Role:\n- Normalized Search Terms:\n- Notes on Term Usage:\n\n### Block B: [Concept Block Name]\n- Concept Role:\n- Normalized Search Terms:\n- Notes on Term Usage:\n\n(Repeat blocks as needed)\n\n## Conceptual Combination Rule\nA single sentence explaining how all blocks jointly define the target literature set.\n\n## Scope Control\n- In-scope:\n- Out-of-scope:\n"}
{"ts": "2026-01-12T03:20:04.916397+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "## Conceptual Retrieval Framework\n\n### Block A: Invasive brain–computer interface / neural interface framing\n- Concept Role: Ensures the literature is explicitly about BCI/neural-interface systems intended for control/communication (not just neuroscience decoding).\n- Normalized Search Terms:\n  - brain–computer interface; brain computer interface; BCI\n  - brain–machine interface; brain machine interface; BMI\n  - neural interface; neural prosthesis; neuroprosthesis\n  - intracortical BCI; ECoG BCI; invasive BCI\n  - neural decoding (when used in a BCI/control context)\n- Notes on Term Usage:\n  - Many relevant papers use “BMI” rather than “BCI,” especially for motor control.\n  - “Neural prosthesis/neuroprosthesis” is often used for invasive motor-control systems even when “BCI” is not in the title/abstract.\n\n### Block B: Invasive neural recording modality (implant type / signal source)\n- Concept Role: Restricts retrieval to invasive signal acquisition methods (as opposed to noninvasive EEG/MEG/fNIRS).\n- Normalized Search Terms:\n  - intracortical recording; intracortical electrodes; microelectrode array; MEA; Utah array\n  - single-unit; multiunit; spiking activity; action potentials; spike trains\n  - local field potential; LFP (when from intracortical/depth electrodes)\n  - electrocorticography; ECoG; subdural electrodes; epidural ECoG\n  - depth electrodes; stereoelectroencephalography; sEEG; intracranial EEG; iEEG\n  - intracranial recording; implanted electrodes\n- Notes on Term Usage:\n  - “iEEG” can include ECoG and sEEG; include both explicit terms to avoid missing papers.\n  - “LFP” appears in both invasive and noninvasive contexts; keep it tied to intracortical/depth electrode language during screening.\n\n### Block C: Movement-related decoding target (intent/kinematics for control)\n- Concept Role: Captures the motor/movement intent or kinematic variables being decoded/estimated for control (not sensory, cognitive, or language targets).\n- Normalized Search Terms:\n  - movement decoding; motor decoding; motor intent; movement intention; intended movement\n  - kinematics; trajectory; position; velocity; acceleration; joint angle(s)\n  - reach; reaching; grasp; hand movement; arm movement; limb movement\n  - motor control; cursor control; point-and-click; computer cursor\n  - prosthetic control; robotic arm control; robotic limb control; neuroprosthetic control\n- Notes on Term Usage:\n  - Some papers emphasize “cursor control” without explicitly stating “kinematics”; others emphasize “kinematics/trajectory” without “cursor.”\n  - Keep terms broad enough to include both endpoint (cursor) and limb/prosthesis kinematics.\n\n### Block D: Decoding / mapping method and evaluation setting (offline and closed-loop)\n- Concept Role: Ensures inclusion of the core methodological theme: mapping neural activity to movement variables, including both offline decoding and real-time closed-loop control.\n- Normalized Search Terms:\n  - decoder; decoding algorithm; neural decoding; state-space model; Kalman filter; Wiener filter\n  - regression; classification (when used for movement intent/commands)\n  - deep learning; neural network; convolutional neural network; CNN; recurrent neural network; RNN; LSTM; transformer (when used for decoding)\n  - real-time; online decoding; closed-loop; brain-controlled; neural control; feedback control\n  - offline analysis; offline decoding; open-loop (as contrasted with closed-loop)\n- Notes on Term Usage:\n  - “Closed-loop” and “online” are often used interchangeably; include both.\n  - Method terms are frequently absent from titles/abstracts; this block is still useful for systematic expansion and screening but should not be used to exclude papers that clearly satisfy Blocks A–C.\n\n## Conceptual Combination Rule\nDocuments must simultaneously address (A) BCI/neural-interface control framing, (B) invasive intracranial recording signals, (C) movement intent/kinematics as the decoded/control target, and (D) an explicit decoding/mapping approach evaluated offline and/or in real-time closed-loop settings.\n\n## Scope Control\n- In-scope:\n  - Invasive (intracortical, ECoG, sEEG/depth, iEEG) BCI/BMI systems that decode movement intent or kinematics for cursor or prosthetic/robotic limb control, using classical or deep-learning decoders, in offline analyses and/or online closed-loop experiments.\n- Out-of-scope:\n  - Noninvasive BCIs (e.g., scalp EEG, MEG, fNIRS) even if motor decoding is performed.\n  - Intracranial studies decoding non-movement targets (e.g., speech/language, vision, memory, affect) without movement-intent/kinematics control.\n  - Pure motor neuroscience decoding papers that do not involve a BCI/BMI/neural-interface control framing (i.e., no intent-to-control application).\n  - Stimulation-only neural interfaces (no invasive recording used for decoding/control).", "project_id": "2098072fb7af", "run_id": "8dfb44f56623", "step": "parse"}
{"ts": "2026-01-12T03:20:04.918243+00:00", "event": "phase1.parse.response", "project_id": "2098072fb7af", "run_id": "8dfb44f56623", "model": "gpt-5.2", "response": "## Conceptual Retrieval Framework\n\n### Block A: Invasive brain–computer interface / neural interface framing\n- Concept Role: Ensures the literature is explicitly about BCI/neural-interface systems intended for control/communication (not just neuroscience decoding).\n- Normalized Search Terms:\n  - brain–computer interface; brain computer interface; BCI\n  - brain–machine interface; brain machine interface; BMI\n  - neural interface; neural prosthesis; neuroprosthesis\n  - intracortical BCI; ECoG BCI; invasive BCI\n  - neural decoding (when used in a BCI/control context)\n- Notes on Term Usage:\n  - Many relevant papers use “BMI” rather than “BCI,” especially for motor control.\n  - “Neural prosthesis/neuroprosthesis” is often used for invasive motor-control systems even when “BCI” is not in the title/abstract.\n\n### Block B: Invasive neural recording modality (implant type / signal source)\n- Concept Role: Restricts retrieval to invasive signal acquisition methods (as opposed to noninvasive EEG/MEG/fNIRS).\n- Normalized Search Terms:\n  - intracortical recording; intracortical electrodes; microelectrode array; MEA; Utah array\n  - single-unit; multiunit; spiking activity; action potentials; spike trains\n  - local field potential; LFP (when from intracortical/depth electrodes)\n  - electrocorticography; ECoG; subdural electrodes; epidural ECoG\n  - depth electrodes; stereoelectroencephalography; sEEG; intracranial EEG; iEEG\n  - intracranial recording; implanted electrodes\n- Notes on Term Usage:\n  - “iEEG” can include ECoG and sEEG; include both explicit terms to avoid missing papers.\n  - “LFP” appears in both invasive and noninvasive contexts; keep it tied to intracortical/depth electrode language during screening.\n\n### Block C: Movement-related decoding target (intent/kinematics for control)\n- Concept Role: Captures the motor/movement intent or kinematic variables being decoded/estimated for control (not sensory, cognitive, or language targets).\n- Normalized Search Terms:\n  - movement decoding; motor decoding; motor intent; movement intention; intended movement\n  - kinematics; trajectory; position; velocity; acceleration; joint angle(s)\n  - reach; reaching; grasp; hand movement; arm movement; limb movement\n  - motor control; cursor control; point-and-click; computer cursor\n  - prosthetic control; robotic arm control; robotic limb control; neuroprosthetic control\n- Notes on Term Usage:\n  - Some papers emphasize “cursor control” without explicitly stating “kinematics”; others emphasize “kinematics/trajectory” without “cursor.”\n  - Keep terms broad enough to include both endpoint (cursor) and limb/prosthesis kinematics.\n\n### Block D: Decoding / mapping method and evaluation setting (offline and closed-loop)\n- Concept Role: Ensures inclusion of the core methodological theme: mapping neural activity to movement variables, including both offline decoding and real-time closed-loop control.\n- Normalized Search Terms:\n  - decoder; decoding algorithm; neural decoding; state-space model; Kalman filter; Wiener filter\n  - regression; classification (when used for movement intent/commands)\n  - deep learning; neural network; convolutional neural network; CNN; recurrent neural network; RNN; LSTM; transformer (when used for decoding)\n  - real-time; online decoding; closed-loop; brain-controlled; neural control; feedback control\n  - offline analysis; offline decoding; open-loop (as contrasted with closed-loop)\n- Notes on Term Usage:\n  - “Closed-loop” and “online” are often used interchangeably; include both.\n  - Method terms are frequently absent from titles/abstracts; this block is still useful for systematic expansion and screening but should not be used to exclude papers that clearly satisfy Blocks A–C.\n\n## Conceptual Combination Rule\nDocuments must simultaneously address (A) BCI/neural-interface control framing, (B) invasive intracranial recording signals, (C) movement intent/kinematics as the decoded/control target, and (D) an explicit decoding/mapping approach evaluated offline and/or in real-time closed-loop settings.\n\n## Scope Control\n- In-scope:\n  - Invasive (intracortical, ECoG, sEEG/depth, iEEG) BCI/BMI systems that decode movement intent or kinematics for cursor or prosthetic/robotic limb control, using classical or deep-learning decoders, in offline analyses and/or online closed-loop experiments.\n- Out-of-scope:\n  - Noninvasive BCIs (e.g., scalp EEG, MEG, fNIRS) even if motor decoding is performed.\n  - Intracranial studies decoding non-movement targets (e.g., speech/language, vision, memory, affect) without movement-intent/kinematics control.\n  - Pure motor neuroscience decoding papers that do not involve a BCI/BMI/neural-interface control framing (i.e., no intent-to-control application).\n  - Stimulation-only neural interfaces (no invasive recording used for decoding/control)."}
{"ts": "2026-01-12T03:33:38.740960+00:00", "event": "parse.stage1.prompt", "project_id": "2098072fb7af", "run_id": "87cd3ae67453", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/xiaowu/local_code/scholarmap/prompts/parse_stage1_understanding.md", "prompt": "你是“研究描述理解与规范化”模块。输入是一段纯文本候选研究描述。你的目标是帮助用户把研究描述变得合理且清晰，便于后续生成文献检索查询。\n\n你必须完成：\n1) 判断这段描述是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true.\n2) 如果是研究描述,进行常识可行性判断（plausibility_level）：\n- A_impossible：明显荒诞/违背当前科技常识（无法形成合理检索任务）\n- B_plausible：合理可行\n3) 如果合理可行，给出你对该研究描述的“当前理解”（normalized_understanding），用规范化、聚焦、可检索的英语重写，\n4) 判断当前理解是否已经清晰到可以用于检索；若不清晰，列出你仍不确定的点（疑问清单），并提出最多3个澄清问题（问题必须具体可回答）。\n5) 输出结构化提要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n6) 只输出JSON，不输出任何额外文本。\n\n候选研究描述：\n\"\"\"I focus on brain computer interface using invasive signals.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n}\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - ncertainties/missing_fields/suggested_questions为空数组[];\n  - structured_summary为全null；\n- normalized_understanding：300-600个英文字符，必须是你对研究的“当前理解”，语言规范、聚焦、可检索；不要写“我认为/可能”等口水话，直接用陈述句组织。\n\n- 如果 是B_plausible，且 is_clear_for_search=true，则：\n  - is_research_description = true\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空数组或只保留0-1条轻微风险\n\n- 如果 是B_plausible，且 is_clear_for_search=false，则：\n  - is_research_description = true\n  - uncertainties 至少2条\n  - missing_fields 仅列出缺失项\n  - suggested_questions 为1-3条，必须与 uncertainties/missing_fields 对应\n\n- 如果 plausibility_level=A_impossible，则：\n  - is_clear_for_search=false\n  - suggested_questions 为空\n  - uncertainties <=200英文字符：给出impossible的原因。\n"}
{"ts": "2026-01-12T03:33:50.649731+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on invasive brain–computer interfaces (BCIs) that use intracranial neural recordings (e.g., ECoG, depth electrodes, or microelectrode arrays) to decode brain activity and translate it into control signals for external devices. The work targets signal acquisition and preprocessing, feature extraction, and machine-learning decoding for real-time communication or motor control, with attention to performance, robustness, and safety constraints in human or animal studies.\",\n  \"structured_summary\": {\n    \"domain\": \"Neuroengineering / Brain–computer interfaces\",\n    \"task\": \"Decode intracranial neural signals into control commands for communication or device control\",\n    \"subject_system\": \"Invasive intracranial recordings (ECoG, SEEG/depth electrodes, microelectrode arrays) in humans and/or animals\",\n    \"methods\": \"Neural signal processing and machine-learning decoding (feature extraction, classification/regression, real-time pipelines)\",\n    \"scope\": \"Invasive BCI using implanted electrodes; online or offline decoding; application-dependent\",\n    \"intent\": \"Enable reliable high-performance BCI control and improve decoding accuracy/robustness under clinical and safety constraints\",\n    \"exclusions\": \"Non-invasive BCIs (EEG/MEG/fNIRS) unless used only for comparison\"\n  },\n  \"uncertainties\": [\n    \"The specific invasive modality is unspecified (ECoG vs SEEG vs microelectrode arrays), which affects keywords and relevant literature.\",\n    \"The target application and output (speech/handwriting, cursor control, prosthetic limb, stimulation control) are not defined.\",\n    \"The intended study population and setting (clinical human implants vs animal models; chronic vs acute recordings) are unclear.\"\n  ],\n  \"missing_fields\": [\"scope\", \"intent\"],\n  \"suggested_questions\": [\n    {\n      \"field\": \"methods\",\n      \"question\": \"Which invasive signal type(s) are you focusing on: ECoG, SEEG/depth electrodes, Utah/microelectrode arrays, or a specific implant system?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What is the primary BCI output/application you want to decode (e.g., cursor/typing, speech/phonemes, limb kinematics, grasp force, or other)?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Are you targeting human clinical recordings (epilepsy/DBS patients) or animal models, and is the focus on real-time online control or offline decoding benchmarks?\"\n    }\n  ]\n}", "project_id": "2098072fb7af", "run_id": "87cd3ae67453", "stage": "stage1"}
{"ts": "2026-01-12T03:33:50.650494+00:00", "event": "parse.stage1.response", "project_id": "2098072fb7af", "run_id": "87cd3ae67453", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on invasive brain–computer interfaces (BCIs) that use intracranial neural recordings (e.g., ECoG, depth electrodes, or microelectrode arrays) to decode brain activity and translate it into control signals for external devices. The work targets signal acquisition and preprocessing, feature extraction, and machine-learning decoding for real-time communication or motor control, with attention to performance, robustness, and safety constraints in human or animal studies.\",\n  \"structured_summary\": {\n    \"domain\": \"Neuroengineering / Brain–computer interfaces\",\n    \"task\": \"Decode intracranial neural signals into control commands for communication or device control\",\n    \"subject_system\": \"Invasive intracranial recordings (ECoG, SEEG/depth electrodes, microelectrode arrays) in humans and/or animals\",\n    \"methods\": \"Neural signal processing and machine-learning decoding (feature extraction, classification/regression, real-time pipelines)\",\n    \"scope\": \"Invasive BCI using implanted electrodes; online or offline decoding; application-dependent\",\n    \"intent\": \"Enable reliable high-performance BCI control and improve decoding accuracy/robustness under clinical and safety constraints\",\n    \"exclusions\": \"Non-invasive BCIs (EEG/MEG/fNIRS) unless used only for comparison\"\n  },\n  \"uncertainties\": [\n    \"The specific invasive modality is unspecified (ECoG vs SEEG vs microelectrode arrays), which affects keywords and relevant literature.\",\n    \"The target application and output (speech/handwriting, cursor control, prosthetic limb, stimulation control) are not defined.\",\n    \"The intended study population and setting (clinical human implants vs animal models; chronic vs acute recordings) are unclear.\"\n  ],\n  \"missing_fields\": [\"scope\", \"intent\"],\n  \"suggested_questions\": [\n    {\n      \"field\": \"methods\",\n      \"question\": \"Which invasive signal type(s) are you focusing on: ECoG, SEEG/depth electrodes, Utah/microelectrode arrays, or a specific implant system?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What is the primary BCI output/application you want to decode (e.g., cursor/typing, speech/phonemes, limb kinematics, grasp force, or other)?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Are you targeting human clinical recordings (epilepsy/DBS patients) or animal models, and is the focus on real-time online control or offline decoding benchmarks?\"\n    }\n  ]\n}"}
{"ts": "2026-01-12T03:35:21.581845+00:00", "event": "parse.stage2.prompt", "project_id": "2098072fb7af", "run_id": "87cd3ae67453", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/xiaowu/local_code/scholarmap/prompts/parse_stage2_converge.md", "prompt": "你是“研究描述自我收敛器”。你将收到三段文本：\n(1) 当前候选研究描述 current_description\n(2) 关于当前研究描述的问题question_for_user\n(3) 用户本轮补充信息 user_additional_info（可能回答了你上轮的问题，也可能没有）\n\n你的任务是：\n1) 判断当前候选研究描述和用户本轮补充信息是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true，并将两段文本融合，形成你对研究内容的“当前理解”，并判断更新后的研究内容是否合理：\n- A_impossible：明显荒诞/违背当前科技常识，无法形成合理检索任务\n- B_plausible：合理可行\n2) 如果A_impossible，给出简单的理由。如果新的理解是合理可行的，就用规范、聚焦、可检索的英文重写（300-600英文字符），这段重写用于帮助用户组织语言与规范表述。\n3) 判断本轮补充的信息是否对解答question_for_user有帮助。有帮助的话就返回 is_helpful=true。\n4) 如果在新增信息后仍不清晰：输出你仍不确定的点（uncertainties），并提出最多3个澄清问题（具体可回答，优先信息增益最大）。\n5) 如果已经清晰：不要再提问题；只输出你的理解与结构化摘要。\n6) 输出结构化摘要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n只输出JSON，不输出任何额外文字。\n\ncurrent_description：\n\"\"\"I focus on brain computer interface using invasive signals.\"\"\"\n\nquestion_for_user：\n\"\"\"Which invasive signal type(s) are you focusing on: ECoG, SEEG/depth electrodes, Utah/microelectrode arrays, or a specific implant system?\nWhat is the primary BCI output/application you want to decode (e.g., cursor/typing, speech/phonemes, limb kinematics, grasp force, or other)?\nAre you targeting human clinical recordings (epilepsy/DBS patients) or animal models, and is the focus on real-time online control or offline decoding benchmarks?\"\"\"\n\n\nuser_additional_info（用户本轮补充信息，可能为空）：\n\"\"\"There is no restriction on the signal types. The primary output is movement. Includes both human and animal, real-time and offline.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"is_helpful\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n  }\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - 其他所有字段都为空。\n- normalized_understanding：300-600英文字符，必须是你融合两段文本后的“当前理解”，术语一致、范围聚焦。\n- 如果 plausibility_level=B_plausible且is_clear_for_search=true：\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空或最多1条轻微风险\n- 如果 plausibility_level=B_plausible且is_clear_for_search=false：\n  - uncertainties 至少2条\n  - suggested_questions 为1-3条，必须与uncertainties/missing_fields一致\n\n- 如果 plausibility_level=A_impossible：\n  - is_clear_for_search 必须为 false\n  - suggested_questions 必须为空数组\n  - uncertainties <=200英文字符：提示用户impossible的原因。\n"}
{"ts": "2026-01-12T03:35:35.203844+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"My research focuses on invasive brain–computer interfaces that decode movement-related intent from intracranial neural recordings. I aim to develop and evaluate decoding algorithms that can work across multiple invasive signal modalities (e.g., ECoG, depth electrodes, microelectrode arrays) and support both offline benchmarking and real-time online control. The work spans human clinical recordings and animal models, with movement as the primary output variable.\",\n  \"structured_summary\": {\n    \"domain\": \"Invasive brain–computer interfaces (BCI) / neural decoding\",\n    \"task\": \"Decode movement intent/kinematics from invasive neural signals for offline and real-time control\",\n    \"subject_system\": \"Human clinical intracranial recordings and animal models; invasive electrodes (ECoG/SEEG/microelectrode arrays)\",\n    \"methods\": \"Signal processing and machine-learning/neural decoding models; offline evaluation and online closed-loop control\",\n    \"scope\": \"Broad across invasive signal types, species, and online/offline settings; movement-focused outputs\",\n    \"intent\": \"Build generalizable movement decoders and assess performance across modalities and experimental contexts\",\n    \"exclusions\": \"Not specified (e.g., non-motor outputs, non-invasive EEG/MEG, specific clinical endpoints)\"\n  },\n  \"uncertainties\": [\n    \"“Movement” is underspecified (e.g., reach kinematics, grasp force, gait, EMG proxies), which affects search keywords and evaluation metrics.\",\n    \"The intended contribution is unclear (new model/architecture, cross-subject transfer, cross-modality generalization, dataset/benchmark, or implant/system comparison).\",\n    \"Recording context details are missing (brain areas, sampling rates/band features, task paradigms), limiting precise retrieval.\"\n  ],\n  \"missing_fields\": [\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"What specific movement variable(s) do you decode (e.g., 2D/3D cursor velocity, joint angles, reach direction, grasp force, gait), and what are the primary performance metrics?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What modeling approach is central (e.g., Kalman/GLM, RNN/Transformer, state-space models, self-supervised learning), and are you targeting cross-session/subject generalization or within-session decoding?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which recording sites and paradigms are most relevant (e.g., M1/PMd/S1, center-out reaching, grasp tasks), and do you emphasize spike-based, LFP/bandpower, or multi-scale features?\"\n    }\n  ]\n}", "project_id": "2098072fb7af", "run_id": "87cd3ae67453", "stage": "stage2"}
{"ts": "2026-01-12T03:35:35.204634+00:00", "event": "parse.stage2.response", "project_id": "2098072fb7af", "run_id": "87cd3ae67453", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"My research focuses on invasive brain–computer interfaces that decode movement-related intent from intracranial neural recordings. I aim to develop and evaluate decoding algorithms that can work across multiple invasive signal modalities (e.g., ECoG, depth electrodes, microelectrode arrays) and support both offline benchmarking and real-time online control. The work spans human clinical recordings and animal models, with movement as the primary output variable.\",\n  \"structured_summary\": {\n    \"domain\": \"Invasive brain–computer interfaces (BCI) / neural decoding\",\n    \"task\": \"Decode movement intent/kinematics from invasive neural signals for offline and real-time control\",\n    \"subject_system\": \"Human clinical intracranial recordings and animal models; invasive electrodes (ECoG/SEEG/microelectrode arrays)\",\n    \"methods\": \"Signal processing and machine-learning/neural decoding models; offline evaluation and online closed-loop control\",\n    \"scope\": \"Broad across invasive signal types, species, and online/offline settings; movement-focused outputs\",\n    \"intent\": \"Build generalizable movement decoders and assess performance across modalities and experimental contexts\",\n    \"exclusions\": \"Not specified (e.g., non-motor outputs, non-invasive EEG/MEG, specific clinical endpoints)\"\n  },\n  \"uncertainties\": [\n    \"“Movement” is underspecified (e.g., reach kinematics, grasp force, gait, EMG proxies), which affects search keywords and evaluation metrics.\",\n    \"The intended contribution is unclear (new model/architecture, cross-subject transfer, cross-modality generalization, dataset/benchmark, or implant/system comparison).\",\n    \"Recording context details are missing (brain areas, sampling rates/band features, task paradigms), limiting precise retrieval.\"\n  ],\n  \"missing_fields\": [\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"What specific movement variable(s) do you decode (e.g., 2D/3D cursor velocity, joint angles, reach direction, grasp force, gait), and what are the primary performance metrics?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What modeling approach is central (e.g., Kalman/GLM, RNN/Transformer, state-space models, self-supervised learning), and are you targeting cross-session/subject generalization or within-session decoding?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which recording sites and paradigms are most relevant (e.g., M1/PMd/S1, center-out reaching, grasp tasks), and do you emphasize spike-based, LFP/bandpower, or multi-scale features?\"\n    }\n  ]\n}"}
{"ts": "2026-01-12T03:35:41.148360+00:00", "event": "phase1.parse.prompt", "project_id": "2098072fb7af", "run_id": "87cd3ae67453", "model": "gpt-5.2", "reasoning_effort": "high", "prompt": "You are an expert academic search strategist specializing in exhaustive literature retrieval. \n\nBelow is a short research summary, your task is to take above research summary and directly produce a conceptual retrieval framework that can be used to systematically search for all relevant literature in that research field.\n\n-- research summary begin --\nMy research focuses on invasive brain–computer interfaces that decode movement-related intent from intracranial neural recordings. I aim to develop and evaluate decoding algorithms that can work across multiple invasive signal modalities (e.g., ECoG, depth electrodes, microelectrode arrays) and support both offline benchmarking and real-time online control. The work spans human clinical recordings and animal models, with movement as the primary output variable.\n-- research summary end --\n\nThis is NOT a query-generation task.\nThis is a concept-framework construction task.\n\nYou must follow these rules strictly:\n\n1. Base the framework ONLY on the content explicitly stated or clearly implied in the research summary.\n   - Do NOT introduce new research goals, populations, or application domains.\n   - Do NOT speculate beyond the summary.\n\n2. The output must define a SMALL NUMBER of concept blocks (typically 2–4).\n   - Each block represents a distinct and independently searchable conceptual dimension\nthat should not be merged with other dimensions if doing so would reduce recall.\n   - Examples include: research task, technical field/framing, data modality.\n   - All blocks together must uniquely define ONE narrow research field.\n\nIMPORTANT — Concept Block Separation Rule:\n\nWhen constructing concept blocks, prioritize retrieval independence over semantic compactness.\n\nIf two concepts frequently appear separately in relevant literature\n(e.g., one may be mentioned without the other in titles/abstracts),\nthey MUST be placed in separate concept blocks,\neven if they form a well-known combined phrase or subfield name.\n\nExample:\n- “speech” and “brain-computer interface” must be separate blocks,\n  because many relevant papers mention speech decoding without explicitly using “BCI”,\n  and others mention BCI without explicitly using “speech”.\n\n\n3. Each concept block must:\n   - Contain only terms that are conceptually equivalent within that block.\n   - Be expressed using terminology commonly found in academic databases.\n   - Include common synonyms, abbreviations, and canonical terms used in the literature.\n\n4. When the summary uses abstract or high-level language, normalize it into concrete, database-searchable concepts\n   ONLY when such normalization is standard practice in the field.\n   - Example: “invasive recordings” → ECoG, sEEG, intracortical recordings, MEA\n   - Do NOT introduce loosely related or adjacent techniques.\n\n5. All concept blocks must be REQUIRED.\n   - The framework should be designed for exhaustive retrieval within a specific field,\n     not for exploratory or cross-domain search.\n\n6. Do NOT generate executable Boolean queries.\n   - You MAY describe the logical relationship between blocks conceptually\n     (e.g., “documents must address all blocks simultaneously”),\n     but do not use database syntax.\n\n7. Explicitly prevent topic drift.\n   - The framework should clearly exclude adjacent but distinct research areas.\n\n### Output Format (must follow exactly):\n\n## Conceptual Retrieval Framework\n\n### Block A: [Concept Block Name]\n- Concept Role:\n- Normalized Search Terms:\n- Notes on Term Usage:\n\n### Block B: [Concept Block Name]\n- Concept Role:\n- Normalized Search Terms:\n- Notes on Term Usage:\n\n(Repeat blocks as needed)\n\n## Conceptual Combination Rule\nA single sentence explaining how all blocks jointly define the target literature set.\n\n## Scope Control\n- In-scope:\n- Out-of-scope:\n"}
{"ts": "2026-01-12T03:36:06.743192+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "## Conceptual Retrieval Framework\n\n### Block A: Invasive brain–computer interface / intracranial neural interface (field framing)\n- Concept Role: Anchors the literature to invasive BCIs/neural interfaces (not noninvasive EEG/MEG/fNIRS), including both offline decoding studies and online control demonstrations.\n- Normalized Search Terms:\n  - “brain-computer interface” / “brain–computer interface” / BCI\n  - “brain-machine interface” / BMI\n  - “neural interface” / “intracranial neural interface”\n  - “invasive BCI” / “implantable BCI” / “intracranial BCI”\n  - “intracranial” (as a descriptor tied to interface/BCI contexts)\n- Notes on Term Usage:\n  - Many relevant papers use BMI instead of BCI, or “neural interface” without explicitly saying BCI; keep these as equivalents within this block.\n  - This block is required to prevent drift into general motor decoding from intracranial recordings that is not positioned as an interface/control system.\n\n### Block B: Intracranial recording modalities (signal source constraint)\n- Concept Role: Ensures the neural data are invasive intracranial recordings and captures the multi-modality emphasis (ECoG, depth/sEEG, intracortical/MEA).\n- Normalized Search Terms:\n  - ECoG / “electrocorticography” / “subdural electrodes” / “cortical surface electrodes”\n  - sEEG / SEEG / “stereo-EEG” / “depth electrodes” / “intracranial EEG” / iEEG\n  - “intracortical recording” / “intracortical electrodes”\n  - “microelectrode array” / MEA / “Utah array”\n  - “single-unit” / “multiunit” / “spike” / “spiking activity” (when explicitly tied to intracortical arrays)\n  - “local field potential” / LFP (when explicitly tied to intracranial/intracortical recordings)\n- Notes on Term Usage:\n  - iEEG is often used as an umbrella term that can include ECoG and sEEG; include both the umbrella and the specific modalities.\n  - Keep modality terms separate from “BCI” terms (Block A) because many papers foreground the recording type without naming BCI in titles/abstracts.\n\n### Block C: Movement-related intent decoding / motor decoding (task/output variable)\n- Concept Role: Constrains the decoded variable to movement-related intent/kinematics (motor output), excluding other BCI targets (e.g., speech, vision, affect).\n- Normalized Search Terms:\n  - “movement intent” / “motor intent” / “intended movement”\n  - “motor decoding” / “movement decoding” / “decode movement”\n  - “kinematic decoding” / “trajectory decoding” / “reach” / “reaching”\n  - “motor control” (in the context of decoding/control)\n  - “motor imagery” (only when used as the movement-related target for decoding/control)\n- Notes on Term Usage:\n  - “Motor” and “movement” are used variably; include both to avoid missing papers that only use one framing.\n  - Keep this block distinct from BCI/interface framing because some BCI papers emphasize “control” without explicitly stating “movement intent,” and some decoding papers emphasize “kinematics” without saying “BCI.”\n\n### Block D: Decoding algorithms and evaluation mode (offline benchmarking + online/real-time control)\n- Concept Role: Captures the algorithmic decoding focus and the evaluation setting spanning offline analyses and real-time/online closed-loop control.\n- Normalized Search Terms:\n  - “decoder” / “decoding algorithm” / “neural decoding”\n  - “real-time” / “online” / “closed-loop” / “closed loop”\n  - “brain-controlled” / “neural control” / “online control”\n  - “offline” / “offline analysis” / “benchmarking” / “benchmark”\n- Notes on Term Usage:\n  - “Closed-loop” and “online” are often used without “real-time”; include all as equivalents.\n  - “Benchmarking” may appear as “offline evaluation” or “offline decoding performance”; keep these together to capture the offline component.\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously address (A) invasive BCI/neural interface framing, (B) intracranial recording modalities, (C) movement-related intent/motor output decoding, and (D) decoding algorithms evaluated in offline and/or online/real-time control contexts.\n\n## Scope Control\n- In-scope:\n  - Invasive BCIs/BMIs using intracranial recordings (ECoG, sEEG/depth, intracortical/MEA) to decode movement-related intent/kinematics, including algorithm development and evaluation in offline benchmarking and/or real-time online control.\n  - Studies in humans and animal models, provided the above conceptual blocks are met.\n- Out-of-scope:\n  - Noninvasive BCIs (e.g., scalp EEG, MEG, fNIRS) without intracranial recordings.\n  - BCIs focused on non-movement outputs (e.g., speech/language decoding, visual decoding, cognitive state, affect) even if invasive.\n  - Pure neurophysiology/motor cortex studies using intracranial recordings that do not involve decoding algorithms or BCI/neural interface/control framing.\n  - Stimulation-only neural interface work (e.g., DBS, cortical stimulation) unless it is explicitly part of a decoding-based invasive BCI for movement intent.", "project_id": "2098072fb7af", "run_id": "87cd3ae67453", "step": "parse"}
{"ts": "2026-01-12T03:36:06.743854+00:00", "event": "phase1.parse.response", "project_id": "2098072fb7af", "run_id": "87cd3ae67453", "model": "gpt-5.2", "response": "## Conceptual Retrieval Framework\n\n### Block A: Invasive brain–computer interface / intracranial neural interface (field framing)\n- Concept Role: Anchors the literature to invasive BCIs/neural interfaces (not noninvasive EEG/MEG/fNIRS), including both offline decoding studies and online control demonstrations.\n- Normalized Search Terms:\n  - “brain-computer interface” / “brain–computer interface” / BCI\n  - “brain-machine interface” / BMI\n  - “neural interface” / “intracranial neural interface”\n  - “invasive BCI” / “implantable BCI” / “intracranial BCI”\n  - “intracranial” (as a descriptor tied to interface/BCI contexts)\n- Notes on Term Usage:\n  - Many relevant papers use BMI instead of BCI, or “neural interface” without explicitly saying BCI; keep these as equivalents within this block.\n  - This block is required to prevent drift into general motor decoding from intracranial recordings that is not positioned as an interface/control system.\n\n### Block B: Intracranial recording modalities (signal source constraint)\n- Concept Role: Ensures the neural data are invasive intracranial recordings and captures the multi-modality emphasis (ECoG, depth/sEEG, intracortical/MEA).\n- Normalized Search Terms:\n  - ECoG / “electrocorticography” / “subdural electrodes” / “cortical surface electrodes”\n  - sEEG / SEEG / “stereo-EEG” / “depth electrodes” / “intracranial EEG” / iEEG\n  - “intracortical recording” / “intracortical electrodes”\n  - “microelectrode array” / MEA / “Utah array”\n  - “single-unit” / “multiunit” / “spike” / “spiking activity” (when explicitly tied to intracortical arrays)\n  - “local field potential” / LFP (when explicitly tied to intracranial/intracortical recordings)\n- Notes on Term Usage:\n  - iEEG is often used as an umbrella term that can include ECoG and sEEG; include both the umbrella and the specific modalities.\n  - Keep modality terms separate from “BCI” terms (Block A) because many papers foreground the recording type without naming BCI in titles/abstracts.\n\n### Block C: Movement-related intent decoding / motor decoding (task/output variable)\n- Concept Role: Constrains the decoded variable to movement-related intent/kinematics (motor output), excluding other BCI targets (e.g., speech, vision, affect).\n- Normalized Search Terms:\n  - “movement intent” / “motor intent” / “intended movement”\n  - “motor decoding” / “movement decoding” / “decode movement”\n  - “kinematic decoding” / “trajectory decoding” / “reach” / “reaching”\n  - “motor control” (in the context of decoding/control)\n  - “motor imagery” (only when used as the movement-related target for decoding/control)\n- Notes on Term Usage:\n  - “Motor” and “movement” are used variably; include both to avoid missing papers that only use one framing.\n  - Keep this block distinct from BCI/interface framing because some BCI papers emphasize “control” without explicitly stating “movement intent,” and some decoding papers emphasize “kinematics” without saying “BCI.”\n\n### Block D: Decoding algorithms and evaluation mode (offline benchmarking + online/real-time control)\n- Concept Role: Captures the algorithmic decoding focus and the evaluation setting spanning offline analyses and real-time/online closed-loop control.\n- Normalized Search Terms:\n  - “decoder” / “decoding algorithm” / “neural decoding”\n  - “real-time” / “online” / “closed-loop” / “closed loop”\n  - “brain-controlled” / “neural control” / “online control”\n  - “offline” / “offline analysis” / “benchmarking” / “benchmark”\n- Notes on Term Usage:\n  - “Closed-loop” and “online” are often used without “real-time”; include all as equivalents.\n  - “Benchmarking” may appear as “offline evaluation” or “offline decoding performance”; keep these together to capture the offline component.\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously address (A) invasive BCI/neural interface framing, (B) intracranial recording modalities, (C) movement-related intent/motor output decoding, and (D) decoding algorithms evaluated in offline and/or online/real-time control contexts.\n\n## Scope Control\n- In-scope:\n  - Invasive BCIs/BMIs using intracranial recordings (ECoG, sEEG/depth, intracortical/MEA) to decode movement-related intent/kinematics, including algorithm development and evaluation in offline benchmarking and/or real-time online control.\n  - Studies in humans and animal models, provided the above conceptual blocks are met.\n- Out-of-scope:\n  - Noninvasive BCIs (e.g., scalp EEG, MEG, fNIRS) without intracranial recordings.\n  - BCIs focused on non-movement outputs (e.g., speech/language decoding, visual decoding, cognitive state, affect) even if invasive.\n  - Pure neurophysiology/motor cortex studies using intracranial recordings that do not involve decoding algorithms or BCI/neural interface/control framing.\n  - Stimulation-only neural interface work (e.g., DBS, cortical stimulation) unless it is explicitly part of a decoding-based invasive BCI for movement intent."}
{"ts": "2026-01-12T03:36:26.995950+00:00", "event": "phase1.query_build.prompt", "project_id": "2098072fb7af", "run_id": "87cd3ae67453", "model": "gpt-5.2", "reasoning_effort": "high", "prompt": "You are an expert biomedical information retrieval engineer specializing in PubMed search strategies.\n\nBelow is a Conceptual Retrieval Framework, your task is to convert the framework into one or more executable PubMed search queries.\n\n-- Conceptual Retrieval Framework begin --\n## Conceptual Retrieval Framework\n\n### Block A: Invasive brain–computer interface / intracranial neural interface (field framing)\n- Concept Role: Anchors the literature to invasive BCIs/neural interfaces (not noninvasive EEG/MEG/fNIRS), including both offline decoding studies and online control demonstrations.\n- Normalized Search Terms:\n  - “brain-computer interface” / “brain–computer interface” / BCI\n  - “brain-machine interface” / BMI\n  - “neural interface” / “intracranial neural interface”\n  - “invasive BCI” / “implantable BCI” / “intracranial BCI”\n  - “intracranial” (as a descriptor tied to interface/BCI contexts)\n- Notes on Term Usage:\n  - Many relevant papers use BMI instead of BCI, or “neural interface” without explicitly saying BCI; keep these as equivalents within this block.\n  - This block is required to prevent drift into general motor decoding from intracranial recordings that is not positioned as an interface/control system.\n\n### Block B: Intracranial recording modalities (signal source constraint)\n- Concept Role: Ensures the neural data are invasive intracranial recordings and captures the multi-modality emphasis (ECoG, depth/sEEG, intracortical/MEA).\n- Normalized Search Terms:\n  - ECoG / “electrocorticography” / “subdural electrodes” / “cortical surface electrodes”\n  - sEEG / SEEG / “stereo-EEG” / “depth electrodes” / “intracranial EEG” / iEEG\n  - “intracortical recording” / “intracortical electrodes”\n  - “microelectrode array” / MEA / “Utah array”\n  - “single-unit” / “multiunit” / “spike” / “spiking activity” (when explicitly tied to intracortical arrays)\n  - “local field potential” / LFP (when explicitly tied to intracranial/intracortical recordings)\n- Notes on Term Usage:\n  - iEEG is often used as an umbrella term that can include ECoG and sEEG; include both the umbrella and the specific modalities.\n  - Keep modality terms separate from “BCI” terms (Block A) because many papers foreground the recording type without naming BCI in titles/abstracts.\n\n### Block C: Movement-related intent decoding / motor decoding (task/output variable)\n- Concept Role: Constrains the decoded variable to movement-related intent/kinematics (motor output), excluding other BCI targets (e.g., speech, vision, affect).\n- Normalized Search Terms:\n  - “movement intent” / “motor intent” / “intended movement”\n  - “motor decoding” / “movement decoding” / “decode movement”\n  - “kinematic decoding” / “trajectory decoding” / “reach” / “reaching”\n  - “motor control” (in the context of decoding/control)\n  - “motor imagery” (only when used as the movement-related target for decoding/control)\n- Notes on Term Usage:\n  - “Motor” and “movement” are used variably; include both to avoid missing papers that only use one framing.\n  - Keep this block distinct from BCI/interface framing because some BCI papers emphasize “control” without explicitly stating “movement intent,” and some decoding papers emphasize “kinematics” without saying “BCI.”\n\n### Block D: Decoding algorithms and evaluation mode (offline benchmarking + online/real-time control)\n- Concept Role: Captures the algorithmic decoding focus and the evaluation setting spanning offline analyses and real-time/online closed-loop control.\n- Normalized Search Terms:\n  - “decoder” / “decoding algorithm” / “neural decoding”\n  - “real-time” / “online” / “closed-loop” / “closed loop”\n  - “brain-controlled” / “neural control” / “online control”\n  - “offline” / “offline analysis” / “benchmarking” / “benchmark”\n- Notes on Term Usage:\n  - “Closed-loop” and “online” are often used without “real-time”; include all as equivalents.\n  - “Benchmarking” may appear as “offline evaluation” or “offline decoding performance”; keep these together to capture the offline component.\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously address (A) invasive BCI/neural interface framing, (B) intracranial recording modalities, (C) movement-related intent/motor output decoding, and (D) decoding algorithms evaluated in offline and/or online/real-time control contexts.\n\n## Scope Control\n- In-scope:\n  - Invasive BCIs/BMIs using intracranial recordings (ECoG, sEEG/depth, intracortical/MEA) to decode movement-related intent/kinematics, including algorithm development and evaluation in offline benchmarking and/or real-time online control.\n  - Studies in humans and animal models, provided the above conceptual blocks are met.\n- Out-of-scope:\n  - Noninvasive BCIs (e.g., scalp EEG, MEG, fNIRS) without intracranial recordings.\n  - BCIs focused on non-movement outputs (e.g., speech/language decoding, visual decoding, cognitive state, affect) even if invasive.\n  - Pure neurophysiology/motor cortex studies using intracranial recordings that do not involve decoding algorithms or BCI/neural interface/control framing.\n  - Stimulation-only neural interface work (e.g., DBS, cortical stimulation) unless it is explicitly part of a decoding-based invasive BCI for movement intent.\n-- Conceptual Retrieval Framework end --\n\n\nYou must follow these rules strictly:\n\n1. Do NOT reinterpret, merge, or split any concept blocks.\n   - Treat each concept block as an independent retrieval dimension.\n   - Preserve the block structure exactly as given.\n\n2. For each concept block:\n   - Combine all normalized search terms within that block using OR.\n   - Apply PubMed field tags consistently, using Title/Abstract fields\n     unless a term is a standard abbreviation or acronym.\n\n3. Across concept blocks:\n   - Combine blocks using AND.\n   - The final query must require that all blocks are satisfied simultaneously.\n\n4. Do NOT introduce new search terms, synonyms, or expansions.\n   - Use ONLY the terms explicitly listed in the framework.\n\n5. Phrase handling:\n   - Multi-word terms must be enclosed in double quotation marks.\n   - Singular/plural variations should be preserved as given; do not infer new ones.\n\n6. PubMed field usage:\n   - Use [Title/Abstract] for most terms.\n   - Acronyms (e.g., BCI, ECoG, iEEG) may be used without field tags\n     only if they are standard and unambiguous.\n   - Do NOT use MeSH terms in this step.\n\n7. If a block contains usage constraints (e.g., “only when paired with X”),\n   enforce this by block-level AND logic, not by modifying individual terms.\n\n8. Output formatting:\n   - Clearly label each block’s query segment.\n   - Provide the final combined PubMed query in a single code block.\n   - Do NOT include explanatory text outside the required output format.\n\n### Output Format (must follow exactly):\n\n## PubMed Query Blocks\n\n### Block A Query\n(query text)\n\n### Block B Query\n(query text)\n\n(Repeat for each block)\n\n## Final Combined PubMed Query\n```text\n(full PubMed query)\n"}
{"ts": "2026-01-12T03:36:36.676467+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "## PubMed Query Blocks\n\n### Block A Query\n(\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR BMI OR \"neural interface\"[Title/Abstract] OR \"intracranial neural interface\"[Title/Abstract] OR \"invasive BCI\"[Title/Abstract] OR \"implantable BCI\"[Title/Abstract] OR \"intracranial BCI\"[Title/Abstract] OR \"intracranial\"[Title/Abstract])\n\n### Block B Query\n(ECoG OR \"electrocorticography\"[Title/Abstract] OR \"subdural electrodes\"[Title/Abstract] OR \"cortical surface electrodes\"[Title/Abstract] OR sEEG OR SEEG OR \"stereo-EEG\"[Title/Abstract] OR \"depth electrodes\"[Title/Abstract] OR \"intracranial EEG\"[Title/Abstract] OR iEEG OR \"intracortical recording\"[Title/Abstract] OR \"intracortical electrodes\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"Utah array\"[Title/Abstract] OR \"single-unit\"[Title/Abstract] OR \"multiunit\"[Title/Abstract] OR \"spike\"[Title/Abstract] OR \"spiking activity\"[Title/Abstract] OR \"local field potential\"[Title/Abstract] OR LFP)\n\n### Block C Query\n(\"movement intent\"[Title/Abstract] OR \"motor intent\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"decode movement\"[Title/Abstract] OR \"kinematic decoding\"[Title/Abstract] OR \"trajectory decoding\"[Title/Abstract] OR \"reach\"[Title/Abstract] OR \"reaching\"[Title/Abstract] OR \"motor control\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract])\n\n### Block D Query\n(\"decoder\"[Title/Abstract] OR \"decoding algorithm\"[Title/Abstract] OR \"neural decoding\"[Title/Abstract] OR \"real-time\"[Title/Abstract] OR \"online\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"closed loop\"[Title/Abstract] OR \"brain-controlled\"[Title/Abstract] OR \"neural control\"[Title/Abstract] OR \"online control\"[Title/Abstract] OR \"offline\"[Title/Abstract] OR \"offline analysis\"[Title/Abstract] OR \"benchmarking\"[Title/Abstract] OR \"benchmark\"[Title/Abstract])\n\n## Final Combined PubMed Query\n```text\n(\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR BMI OR \"neural interface\"[Title/Abstract] OR \"intracranial neural interface\"[Title/Abstract] OR \"invasive BCI\"[Title/Abstract] OR \"implantable BCI\"[Title/Abstract] OR \"intracranial BCI\"[Title/Abstract] OR \"intracranial\"[Title/Abstract])\nAND\n(ECoG OR \"electrocorticography\"[Title/Abstract] OR \"subdural electrodes\"[Title/Abstract] OR \"cortical surface electrodes\"[Title/Abstract] OR sEEG OR SEEG OR \"stereo-EEG\"[Title/Abstract] OR \"depth electrodes\"[Title/Abstract] OR \"intracranial EEG\"[Title/Abstract] OR iEEG OR \"intracortical recording\"[Title/Abstract] OR \"intracortical electrodes\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"Utah array\"[Title/Abstract] OR \"single-unit\"[Title/Abstract] OR \"multiunit\"[Title/Abstract] OR \"spike\"[Title/Abstract] OR \"spiking activity\"[Title/Abstract] OR \"local field potential\"[Title/Abstract] OR LFP)\nAND\n(\"movement intent\"[Title/Abstract] OR \"motor intent\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"decode movement\"[Title/Abstract] OR \"kinematic decoding\"[Title/Abstract] OR \"trajectory decoding\"[Title/Abstract] OR \"reach\"[Title/Abstract] OR \"reaching\"[Title/Abstract] OR \"motor control\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract])\nAND\n(\"decoder\"[Title/Abstract] OR \"decoding algorithm\"[Title/Abstract] OR \"neural decoding\"[Title/Abstract] OR \"real-time\"[Title/Abstract] OR \"online\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"closed loop\"[Title/Abstract] OR \"brain-controlled\"[Title/Abstract] OR \"neural control\"[Title/Abstract] OR \"online control\"[Title/Abstract] OR \"offline\"[Title/Abstract] OR \"offline analysis\"[Title/Abstract] OR \"benchmarking\"[Title/Abstract] OR \"benchmark\"[Title/Abstract])\n```", "project_id": "2098072fb7af", "run_id": "87cd3ae67453", "step": "query_build"}
{"ts": "2026-01-12T03:36:36.677001+00:00", "event": "phase1.query_build.response", "project_id": "2098072fb7af", "run_id": "87cd3ae67453", "model": "gpt-5.2", "response": "## PubMed Query Blocks\n\n### Block A Query\n(\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR BMI OR \"neural interface\"[Title/Abstract] OR \"intracranial neural interface\"[Title/Abstract] OR \"invasive BCI\"[Title/Abstract] OR \"implantable BCI\"[Title/Abstract] OR \"intracranial BCI\"[Title/Abstract] OR \"intracranial\"[Title/Abstract])\n\n### Block B Query\n(ECoG OR \"electrocorticography\"[Title/Abstract] OR \"subdural electrodes\"[Title/Abstract] OR \"cortical surface electrodes\"[Title/Abstract] OR sEEG OR SEEG OR \"stereo-EEG\"[Title/Abstract] OR \"depth electrodes\"[Title/Abstract] OR \"intracranial EEG\"[Title/Abstract] OR iEEG OR \"intracortical recording\"[Title/Abstract] OR \"intracortical electrodes\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"Utah array\"[Title/Abstract] OR \"single-unit\"[Title/Abstract] OR \"multiunit\"[Title/Abstract] OR \"spike\"[Title/Abstract] OR \"spiking activity\"[Title/Abstract] OR \"local field potential\"[Title/Abstract] OR LFP)\n\n### Block C Query\n(\"movement intent\"[Title/Abstract] OR \"motor intent\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"decode movement\"[Title/Abstract] OR \"kinematic decoding\"[Title/Abstract] OR \"trajectory decoding\"[Title/Abstract] OR \"reach\"[Title/Abstract] OR \"reaching\"[Title/Abstract] OR \"motor control\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract])\n\n### Block D Query\n(\"decoder\"[Title/Abstract] OR \"decoding algorithm\"[Title/Abstract] OR \"neural decoding\"[Title/Abstract] OR \"real-time\"[Title/Abstract] OR \"online\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"closed loop\"[Title/Abstract] OR \"brain-controlled\"[Title/Abstract] OR \"neural control\"[Title/Abstract] OR \"online control\"[Title/Abstract] OR \"offline\"[Title/Abstract] OR \"offline analysis\"[Title/Abstract] OR \"benchmarking\"[Title/Abstract] OR \"benchmark\"[Title/Abstract])\n\n## Final Combined PubMed Query\n```text\n(\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR BMI OR \"neural interface\"[Title/Abstract] OR \"intracranial neural interface\"[Title/Abstract] OR \"invasive BCI\"[Title/Abstract] OR \"implantable BCI\"[Title/Abstract] OR \"intracranial BCI\"[Title/Abstract] OR \"intracranial\"[Title/Abstract])\nAND\n(ECoG OR \"electrocorticography\"[Title/Abstract] OR \"subdural electrodes\"[Title/Abstract] OR \"cortical surface electrodes\"[Title/Abstract] OR sEEG OR SEEG OR \"stereo-EEG\"[Title/Abstract] OR \"depth electrodes\"[Title/Abstract] OR \"intracranial EEG\"[Title/Abstract] OR iEEG OR \"intracortical recording\"[Title/Abstract] OR \"intracortical electrodes\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"Utah array\"[Title/Abstract] OR \"single-unit\"[Title/Abstract] OR \"multiunit\"[Title/Abstract] OR \"spike\"[Title/Abstract] OR \"spiking activity\"[Title/Abstract] OR \"local field potential\"[Title/Abstract] OR LFP)\nAND\n(\"movement intent\"[Title/Abstract] OR \"motor intent\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"decode movement\"[Title/Abstract] OR \"kinematic decoding\"[Title/Abstract] OR \"trajectory decoding\"[Title/Abstract] OR \"reach\"[Title/Abstract] OR \"reaching\"[Title/Abstract] OR \"motor control\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract])\nAND\n(\"decoder\"[Title/Abstract] OR \"decoding algorithm\"[Title/Abstract] OR \"neural decoding\"[Title/Abstract] OR \"real-time\"[Title/Abstract] OR \"online\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"closed loop\"[Title/Abstract] OR \"brain-controlled\"[Title/Abstract] OR \"neural control\"[Title/Abstract] OR \"online control\"[Title/Abstract] OR \"offline\"[Title/Abstract] OR \"offline analysis\"[Title/Abstract] OR \"benchmarking\"[Title/Abstract] OR \"benchmark\"[Title/Abstract])\n```"}
{"ts": "2026-01-12T03:38:38.579084+00:00", "event": "phase2.affiliation_extraction.prompt", "batch_size": 3, "model": "gpt-5.2", "prompt_file": "/Users/xiaowu/local_code/scholarmap/prompts/affiliation_extraction.md", "full_prompt": "You are a geographic data extractor for academic affiliations.\n\nExtract the following from each affiliation string:\n- country: Full country name (e.g., \"United States\", \"United Kingdom\", \"China\")\n- city: City name (e.g., \"Boston\", \"London\", \"Beijing\")\n- institution: Primary institution name if present (e.g., \"Harvard Medical School\", \"MIT\")\n\n\nRules:\n1. Guess the missing info based on the available info. \n2. Use full country names, not abbreviations (USA → United States)\n3. confidence: \"high\" if all fields clear, \"medium\" if some unclear, \"low\" if very ambiguous\n\nIMPORTANT - Country and City extraction rules:\n- DO NOT extract US state abbreviations (MD, OH, WV, NY, CA, etc.) as cities\n- Only extract actual city names (e.g., \"Boston\", \"Albany\", \"San Francisco\", \"New York\" without state/abbreviations)\n- The guess should be valid and true. For example, \"Massachusetts Institute of Technology, Cambridge, MA 02139\" should be inferred as United States. It would be wrong if it is inferred as 'Cambridge, Morocco', even MA is the country code for Morocco.\n\n\nReturn a JSON array with one object per affiliation in the EXACT same order as input:\n[\n  {\"country\": \"United States\", \"city\": \"Boston\", \"institution\": \"Massachusetts General Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"China\", \"city\": \"Beijing\", \"institution\": null, \"confidence\": \"medium\"},\n  ...\n]\n\nAffiliations to process:\n1. Department of Medical Physics and Biomedical Engineering, School of Medicine, Tehran University of Medical Science (TUMS), Tehran, Iran.\n2. Faculty of Electrical Engineering, Shahid Beheshti University, Tehran, Iran.\n3. Unité de Neuroscience, Information et Complexité, Centre National de la Recherche Scientifique Gif-sur-Yvette, France.\n\n"}
{"ts": "2026-01-12T03:38:41.569546+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "```json\n[\n  {\n    \"country\": \"Iran\",\n    \"city\": \"Tehran\",\n    \"institution\": \"Tehran University of Medical Science (TUMS)\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"Iran\",\n    \"city\": \"Tehran\",\n    \"institution\": \"Shahid Beheshti University\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"France\",\n    \"city\": \"Gif-sur-Yvette\",\n    \"institution\": \"Centre National de la Recherche Scientifique\",\n    \"confidence\": \"high\"\n  }\n]\n```"}
{"ts": "2026-01-12T03:38:41.570140+00:00", "event": "phase2.affiliation_extraction.response", "batch_size": 3, "model": "gpt-5.2", "raw_json_response": "```json\n[\n  {\n    \"country\": \"Iran\",\n    \"city\": \"Tehran\",\n    \"institution\": \"Tehran University of Medical Science (TUMS)\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"Iran\",\n    \"city\": \"Tehran\",\n    \"institution\": \"Shahid Beheshti University\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"France\",\n    \"city\": \"Gif-sur-Yvette\",\n    \"institution\": \"Centre National de la Recherche Scientifique\",\n    \"confidence\": \"high\"\n  }\n]\n```"}
{"ts": "2026-01-12T04:07:49.430545+00:00", "event": "phase2.affiliation_extraction.prompt", "batch_size": 2, "model": "gpt-5.2", "prompt_file": "/Users/xiaowu/local_code/scholarmap/prompts/affiliation_extraction.md", "full_prompt": "You are a geographic data extractor for academic affiliations.\n\nExtract the following from each affiliation string:\n- country: Full country name (e.g., \"United States\", \"United Kingdom\", \"China\")\n- city: City name (e.g., \"Boston\", \"London\", \"Beijing\")\n- institution: Primary institution name if present (e.g., \"Harvard Medical School\", \"MIT\")\n\n\nRules:\n1. Guess the missing info based on the available info. \n2. Use full country names, not abbreviations (USA → United States)\n3. confidence: \"high\" if all fields clear, \"medium\" if some unclear, \"low\" if very ambiguous\n\nIMPORTANT - Country and City extraction rules:\n- DO NOT extract US state abbreviations (MD, OH, WV, NY, CA, etc.) as cities\n- Only extract actual city names (e.g., \"Boston\", \"Albany\", \"San Francisco\", \"New York\" without state/abbreviations)\n- The guess should be valid and true. For example, \"Massachusetts Institute of Technology, Cambridge, MA 02139\" should be inferred as United States. It would be wrong if it is inferred as 'Cambridge, Morocco', even MA is the country code for Morocco.\n\n\nReturn a JSON array with one object per affiliation in the EXACT same order as input:\n[\n  {\"country\": \"United States\", \"city\": \"Boston\", \"institution\": \"Massachusetts General Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"China\", \"city\": \"Beijing\", \"institution\": null, \"confidence\": \"medium\"},\n  ...\n]\n\nAffiliations to process:\n1. Department of Medical Physics and Biomedical Engineering, School of Medicine, Tehran University of Medical Science (TUMS), Tehran, Iran.\n2. Unité de Neuroscience, Information et Complexité, Centre National de la Recherche Scientifique Gif-sur-Yvette, France.\n\n"}
{"ts": "2026-01-12T04:07:51.189967+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "```json\n[\n  {\n    \"country\": \"Iran\",\n    \"city\": \"Tehran\",\n    \"institution\": \"Tehran University of Medical Science (TUMS)\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"France\",\n    \"city\": \"Gif-sur-Yvette\",\n    \"institution\": \"Centre National de la Recherche Scientifique\",\n    \"confidence\": \"high\"\n  }\n]\n```"}
{"ts": "2026-01-12T04:07:51.190795+00:00", "event": "phase2.affiliation_extraction.response", "batch_size": 2, "model": "gpt-5.2", "raw_json_response": "```json\n[\n  {\n    \"country\": \"Iran\",\n    \"city\": \"Tehran\",\n    \"institution\": \"Tehran University of Medical Science (TUMS)\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"France\",\n    \"city\": \"Gif-sur-Yvette\",\n    \"institution\": \"Centre National de la Recherche Scientifique\",\n    \"confidence\": \"high\"\n  }\n]\n```"}
{"ts": "2026-01-21T16:41:05.495682+00:00", "event": "parse.stage1.prompt", "project_id": "6af7ac1b6254", "run_id": "a0d5fe7219d3", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage1_understanding.md", "prompt": "你是“研究描述理解与规范化”模块。输入是一段纯文本候选研究描述。你的目标是帮助用户把研究描述变得合理且清晰，便于后续生成文献检索查询。\n\n你必须完成：\n1) 判断这段描述是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true.\n2) 如果是研究描述,进行常识可行性判断（plausibility_level）：\n- A_impossible：明显荒诞/违背当前科技常识（无法形成合理检索任务）\n- B_plausible：合理可行\n3) 如果合理可行，给出你对该研究描述的“当前理解”（normalized_understanding），用规范化、聚焦、可检索的英语重写，\n4) 判断当前理解是否已经清晰到可以用于检索；若不清晰，列出你仍不确定的点（疑问清单），并提出最多3个澄清问题（问题必须具体可回答）。\n5) 输出结构化提要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n6) 只输出JSON，不输出任何额外文本。\n\n候选研究描述：\n\"\"\"I focus on motor brain-computer interface based on the invasive EEG signals.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n}\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - ncertainties/missing_fields/suggested_questions为空数组[];\n  - structured_summary为全null；\n- normalized_understanding：300-600个英文字符，必须是你对研究的“当前理解”，语言规范、聚焦、可检索；不要写“我认为/可能”等口水话，直接用陈述句组织。\n\n- 如果 是B_plausible，且 is_clear_for_search=true，则：\n  - is_research_description = true\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空数组或只保留0-1条轻微风险\n\n- 如果 是B_plausible，且 is_clear_for_search=false，则：\n  - is_research_description = true\n  - uncertainties 至少2条\n  - missing_fields 仅列出缺失项\n  - suggested_questions 为1-3条，必须与 uncertainties/missing_fields 对应\n\n- 如果 plausibility_level=A_impossible，则：\n  - is_clear_for_search=false\n  - suggested_questions 为空\n  - uncertainties <=200英文字符：给出impossible的原因。\n"}
{"ts": "2026-01-21T16:41:18.802274+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces (BCIs) that decode movement intention and control external devices using invasive electrophysiological recordings from the brain (intracranial EEG/ECoG). The work targets signal processing and machine-learning decoding of motor-related neural activity for real-time cursor/robot/prosthesis control, emphasizing performance, robustness, and practical deployment constraints in invasive BCI settings.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces; neuroengineering; neural signal processing\",\n    \"task\": \"Decode motor intention/movement parameters for device control\",\n    \"subject_system\": \"Humans or animal models with implanted intracranial electrodes (iEEG/ECoG)\",\n    \"methods\": \"Invasive neural recording; feature extraction; machine-learning/decoding algorithms; real-time BCI control\",\n    \"scope\": \"Motor BCI using invasive electrophysiology (clarify iEEG vs ECoG, target effectors, and application device)\",\n    \"intent\": \"Enable reliable motor control via invasive BCI; improve decoding accuracy and robustness\",\n    \"exclusions\": \"Non-invasive EEG-only BCIs; non-motor cognitive BCIs\"\n  },\n  \"uncertainties\": [\n    \"The phrase 'invasive EEG' is ambiguous; it could mean iEEG (sEEG) or ECoG, which affects terminology and search keywords.\",\n    \"The specific motor task and output modality are unspecified (e.g., grasping vs gait; cursor vs prosthetic limb vs robot).\",\n    \"Key methodological focus is unclear (signal features, deep learning vs classical ML, closed-loop adaptation, clinical translation).\"\n  ],\n  \"missing_fields\": [\"subject_system\", \"methods\", \"scope\"],\n  \"suggested_questions\": [\n    {\n      \"field\": \"scope\",\n      \"question\": \"When you say 'invasive EEG', do you mean ECoG (subdural grids/strips) or stereotactic iEEG (sEEG depth electrodes), and in what population (human clinical implants vs animal experiments)?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What motor function is decoded (e.g., hand grasp, arm reaching, finger kinematics, gait) and what is the BCI output device (cursor, robotic arm, prosthetic limb, FES)?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"Which decoding approach is central (e.g., spectral features + linear models, RNN/CNN deep learning, Kalman filters, adaptive/closed-loop learning), and is real-time online control required?\"\n    }\n  ]\n}", "project_id": "6af7ac1b6254", "run_id": "a0d5fe7219d3", "stage": "stage1"}
{"ts": "2026-01-21T16:41:18.802940+00:00", "event": "parse.stage1.response", "project_id": "6af7ac1b6254", "run_id": "a0d5fe7219d3", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces (BCIs) that decode movement intention and control external devices using invasive electrophysiological recordings from the brain (intracranial EEG/ECoG). The work targets signal processing and machine-learning decoding of motor-related neural activity for real-time cursor/robot/prosthesis control, emphasizing performance, robustness, and practical deployment constraints in invasive BCI settings.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces; neuroengineering; neural signal processing\",\n    \"task\": \"Decode motor intention/movement parameters for device control\",\n    \"subject_system\": \"Humans or animal models with implanted intracranial electrodes (iEEG/ECoG)\",\n    \"methods\": \"Invasive neural recording; feature extraction; machine-learning/decoding algorithms; real-time BCI control\",\n    \"scope\": \"Motor BCI using invasive electrophysiology (clarify iEEG vs ECoG, target effectors, and application device)\",\n    \"intent\": \"Enable reliable motor control via invasive BCI; improve decoding accuracy and robustness\",\n    \"exclusions\": \"Non-invasive EEG-only BCIs; non-motor cognitive BCIs\"\n  },\n  \"uncertainties\": [\n    \"The phrase 'invasive EEG' is ambiguous; it could mean iEEG (sEEG) or ECoG, which affects terminology and search keywords.\",\n    \"The specific motor task and output modality are unspecified (e.g., grasping vs gait; cursor vs prosthetic limb vs robot).\",\n    \"Key methodological focus is unclear (signal features, deep learning vs classical ML, closed-loop adaptation, clinical translation).\"\n  ],\n  \"missing_fields\": [\"subject_system\", \"methods\", \"scope\"],\n  \"suggested_questions\": [\n    {\n      \"field\": \"scope\",\n      \"question\": \"When you say 'invasive EEG', do you mean ECoG (subdural grids/strips) or stereotactic iEEG (sEEG depth electrodes), and in what population (human clinical implants vs animal experiments)?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What motor function is decoded (e.g., hand grasp, arm reaching, finger kinematics, gait) and what is the BCI output device (cursor, robotic arm, prosthetic limb, FES)?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"Which decoding approach is central (e.g., spectral features + linear models, RNN/CNN deep learning, Kalman filters, adaptive/closed-loop learning), and is real-time online control required?\"\n    }\n  ]\n}"}
{"ts": "2026-01-21T16:43:09.874330+00:00", "event": "parse.stage2.prompt", "project_id": "6af7ac1b6254", "run_id": "a0d5fe7219d3", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage2_converge.md", "prompt": "你是“研究描述自我收敛器”。你将收到三段文本：\n(1) 当前候选研究描述 current_description\n(2) 关于当前研究描述的问题question_for_user\n(3) 用户本轮补充信息 user_additional_info（可能回答了你上轮的问题，也可能没有）\n\n你的任务是：\n1) 判断当前候选研究描述和用户本轮补充信息是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true，并将两段文本融合，形成你对研究内容的“当前理解”，并判断更新后的研究内容是否合理：\n- A_impossible：明显荒诞/违背当前科技常识，无法形成合理检索任务\n- B_plausible：合理可行\n2) 如果A_impossible，给出简单的理由。如果新的理解是合理可行的，就用规范、聚焦、可检索的英文重写（300-600英文字符），这段重写用于帮助用户组织语言与规范表述。\n3) 判断本轮补充的信息是否对解答question_for_user有帮助。有帮助的话就返回 is_helpful=true。\n4) 如果在新增信息后仍不清晰：输出你仍不确定的点（uncertainties），并提出最多3个澄清问题（具体可回答，优先信息增益最大）。\n5) 如果已经清晰：不要再提问题；只输出你的理解与结构化摘要。\n6) 输出结构化摘要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n只输出JSON，不输出任何额外文字。\n\ncurrent_description：\n\"\"\"I focus on motor brain-computer interface based on the invasive EEG signals.\"\"\"\n\nquestion_for_user：\n\"\"\"When you say 'invasive EEG', do you mean ECoG (subdural grids/strips) or stereotactic iEEG (sEEG depth electrodes), and in what population (human clinical implants vs animal experiments)?\nWhat motor function is decoded (e.g., hand grasp, arm reaching, finger kinematics, gait) and what is the BCI output device (cursor, robotic arm, prosthetic limb, FES)?\nWhich decoding approach is central (e.g., spectral features + linear models, RNN/CNN deep learning, Kalman filters, adaptive/closed-loop learning), and is real-time online control required?\"\"\"\n\n\nuser_additional_info（用户本轮补充信息，可能为空）：\n\"\"\"Invasive EEG, I mean ECoG, sEEG, or MEA (micro-electric array). There is no restriction on population, decoded function, output device, or the decoding approach.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"is_helpful\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n  }\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - 其他所有字段都为空。\n- normalized_understanding：300-600英文字符，必须是你融合两段文本后的“当前理解”，术语一致、范围聚焦。\n- 如果 plausibility_level=B_plausible且is_clear_for_search=true：\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空或最多1条轻微风险\n- 如果 plausibility_level=B_plausible且is_clear_for_search=false：\n  - uncertainties 至少2条\n  - suggested_questions 为1-3条，必须与uncertainties/missing_fields一致\n\n- 如果 plausibility_level=A_impossible：\n  - is_clear_for_search 必须为 false\n  - suggested_questions 必须为空数组\n  - uncertainties <=200英文字符：提示用户impossible的原因。\n"}
{"ts": "2026-01-21T16:43:24.513516+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"The research focuses on motor brain–computer interfaces using invasive electrophysiological recordings, broadly defined to include ECoG (subdural grids/strips), stereotactic iEEG/sEEG depth electrodes, and microelectrode arrays (MEA). The goal is to decode motor-related neural activity for BCI control, without restricting the target population (human clinical implants or animal models), the motor function decoded, the output device, or the decoding/learning approach (classical feature-based models or deep learning; offline or online).\",\n  \"structured_summary\": {\n    \"domain\": \"Neuroengineering; invasive neural signal processing; motor brain–computer interfaces\",\n    \"task\": \"Decode motor intent/kinematics from invasive electrophysiology for BCI control\",\n    \"subject_system\": \"ECoG, sEEG/iEEG depth electrodes, and microelectrode arrays (MEA) in humans and/or animals\",\n    \"methods\": \"Unspecified; may include spectral features + linear models, state-space/Kalman filters, CNN/RNN deep learning, adaptive/closed-loop decoding\",\n    \"scope\": \"Broad, modality-agnostic invasive recordings; no constraints on motor task, device output, population, or real-time requirement\",\n    \"intent\": \"Develop/compare decoding approaches for motor BCI using invasive signals\",\n    \"exclusions\": \"Not specified\"\n  },\n  \"uncertainties\": [\n    \"The scope is too broad across recording modalities, populations, motor tasks, and outputs, making targeted literature search and positioning difficult.\",\n    \"It is unclear whether the primary contribution is algorithmic decoding, neural feature characterization, online closed-loop control, or system/device integration.\"\n  ],\n  \"missing_fields\": [\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which recording modality is your primary focus for the core contribution (ECoG vs sEEG vs MEA), and is the work mainly in humans, animals, or both?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What specific motor variable(s) do you aim to decode (e.g., discrete movement classes, continuous kinematics, grasp force), and is the target use offline decoding or real-time online control?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What is the central methodological angle: feature engineering + classical models, deep learning, adaptive/closed-loop learning, or neural signal/biomarker analysis?\"\n    }\n  ]\n}", "project_id": "6af7ac1b6254", "run_id": "a0d5fe7219d3", "stage": "stage2"}
{"ts": "2026-01-21T16:43:24.515909+00:00", "event": "parse.stage2.response", "project_id": "6af7ac1b6254", "run_id": "a0d5fe7219d3", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"The research focuses on motor brain–computer interfaces using invasive electrophysiological recordings, broadly defined to include ECoG (subdural grids/strips), stereotactic iEEG/sEEG depth electrodes, and microelectrode arrays (MEA). The goal is to decode motor-related neural activity for BCI control, without restricting the target population (human clinical implants or animal models), the motor function decoded, the output device, or the decoding/learning approach (classical feature-based models or deep learning; offline or online).\",\n  \"structured_summary\": {\n    \"domain\": \"Neuroengineering; invasive neural signal processing; motor brain–computer interfaces\",\n    \"task\": \"Decode motor intent/kinematics from invasive electrophysiology for BCI control\",\n    \"subject_system\": \"ECoG, sEEG/iEEG depth electrodes, and microelectrode arrays (MEA) in humans and/or animals\",\n    \"methods\": \"Unspecified; may include spectral features + linear models, state-space/Kalman filters, CNN/RNN deep learning, adaptive/closed-loop decoding\",\n    \"scope\": \"Broad, modality-agnostic invasive recordings; no constraints on motor task, device output, population, or real-time requirement\",\n    \"intent\": \"Develop/compare decoding approaches for motor BCI using invasive signals\",\n    \"exclusions\": \"Not specified\"\n  },\n  \"uncertainties\": [\n    \"The scope is too broad across recording modalities, populations, motor tasks, and outputs, making targeted literature search and positioning difficult.\",\n    \"It is unclear whether the primary contribution is algorithmic decoding, neural feature characterization, online closed-loop control, or system/device integration.\"\n  ],\n  \"missing_fields\": [\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which recording modality is your primary focus for the core contribution (ECoG vs sEEG vs MEA), and is the work mainly in humans, animals, or both?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What specific motor variable(s) do you aim to decode (e.g., discrete movement classes, continuous kinematics, grasp force), and is the target use offline decoding or real-time online control?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What is the central methodological angle: feature engineering + classical models, deep learning, adaptive/closed-loop learning, or neural signal/biomarker analysis?\"\n    }\n  ]\n}"}
{"ts": "2026-01-21T16:43:48.047622+00:00", "event": "phase1.parse.prompt", "project_id": "6af7ac1b6254", "run_id": "a0d5fe7219d3", "model": "gpt-5.2", "reasoning_effort": "high", "prompt": "You are an expert academic search strategist specializing in exhaustive literature retrieval. \n\nBelow is a short research summary, your task is to take above research summary and directly produce a conceptual retrieval framework that can be used to systematically search for all relevant literature in that research field.\n\n-- research summary begin --\nThe research focuses on motor brain–computer interfaces using invasive electrophysiological recordings, broadly defined to include ECoG (subdural grids/strips), stereotactic iEEG/sEEG depth electrodes, and microelectrode arrays (MEA). The goal is to decode motor-related neural activity for BCI control, without restricting the target population (human clinical implants or animal models), the motor function decoded, the output device, or the decoding/learning approach (classical feature-based models or deep learning; offline or online).\n-- research summary end --\n\nThis is NOT a query-generation task.\nThis is a concept-framework construction task.\n\nYou must follow these rules strictly:\n\n1. Base the framework ONLY on the content explicitly stated or clearly implied in the research summary.\n   - Do NOT introduce new research goals, populations, or application domains.\n   - Do NOT speculate beyond the summary.\n\n2. The output must define a SMALL NUMBER of concept blocks (typically 2–4).\n   - Each block represents a distinct and independently searchable conceptual dimension\nthat should not be merged with other dimensions if doing so would reduce recall.\n   - Examples include: research task, technical field/framing, data modality.\n   - All blocks together must uniquely define ONE narrow research field.\n\nIMPORTANT — Concept Block Separation Rule:\n\nWhen constructing concept blocks, prioritize retrieval independence over semantic compactness.\n\nIf two concepts frequently appear separately in relevant literature\n(e.g., one may be mentioned without the other in titles/abstracts),\nthey MUST be placed in separate concept blocks,\neven if they form a well-known combined phrase or subfield name.\n\nExample:\n- “speech” and “brain-computer interface” must be separate blocks,\n  because many relevant papers mention speech decoding without explicitly using “BCI”,\n  and others mention BCI without explicitly using “speech”.\n\n\n3. Each concept block must:\n   - Contain only terms that are conceptually equivalent within that block.\n   - Be expressed using terminology commonly found in academic databases.\n   - Include common synonyms, abbreviations, and canonical terms used in the literature.\n\n4. When the summary uses abstract or high-level language, normalize it into concrete, database-searchable concepts\n   ONLY when such normalization is standard practice in the field.\n   - Example: “invasive recordings” → ECoG, sEEG, intracortical recordings, MEA\n   - Do NOT introduce loosely related or adjacent techniques.\n\n5. All concept blocks must be REQUIRED.\n   - The framework should be designed for exhaustive retrieval within a specific field,\n     not for exploratory or cross-domain search.\n\n6. Do NOT generate executable Boolean queries.\n   - You MAY describe the logical relationship between blocks conceptually\n     (e.g., “documents must address all blocks simultaneously”),\n     but do not use database syntax.\n\n7. Explicitly prevent topic drift.\n   - The framework should clearly exclude adjacent but distinct research areas.\n\n### Output Format (must follow exactly):\n\n## Conceptual Retrieval Framework\n\n### Block A: [Concept Block Name]\n- Concept Role:\n- Normalized Search Terms:\n- Notes on Term Usage:\n\n### Block B: [Concept Block Name]\n- Concept Role:\n- Normalized Search Terms:\n- Notes on Term Usage:\n\n(Repeat blocks as needed)\n\n## Conceptual Combination Rule\nA single sentence explaining how all blocks jointly define the target literature set.\n\n## Scope Control\n- In-scope:\n- Out-of-scope:\n"}
{"ts": "2026-01-21T16:44:11.600240+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "## Conceptual Retrieval Framework\n\n### Block A: Brain–Computer Interface / Neural Interface (Motor Control Context)\n- Concept Role: Captures the BCI/neural-interface framing (including papers that may use “neural prosthesis” language rather than “BCI”).\n- Normalized Search Terms:\n  - brain-computer interface; brain–computer interface; BCI\n  - brain-machine interface; brain–machine interface; BMI\n  - neural interface; direct neural interface\n  - neural prosthesis; neuroprosthesis; brain-controlled; neural decoding for control\n- Notes on Term Usage:\n  - Include both “BCI” and “BMI” because communities use them interchangeably.\n  - “Neural prosthesis/neuroprosthesis” is often used in invasive motor-control decoding papers without explicitly saying “BCI.”\n\n### Block B: Invasive Electrophysiological Recording Modality (ECoG / iEEG / sEEG / MEA)\n- Concept Role: Restricts retrieval to invasive electrophysiological recordings explicitly named in the summary (subdural ECoG, stereotactic depth iEEG/sEEG, and microelectrode arrays/intracortical).\n- Normalized Search Terms:\n  - electrocorticography; electrocorticographic; ECoG; subdural grid; subdural strip; cortical surface electrodes\n  - intracranial EEG; iEEG; intracranial electroencephalography\n  - stereoelectroencephalography; stereo-EEG; sEEG; depth electrode; stereotactic EEG\n  - microelectrode array; MEA; intracortical recording; intracortical electrode; Utah array\n- Notes on Term Usage:\n  - Keep ECoG and iEEG/sEEG terms together as “invasive electrophysiology,” but list them explicitly because many records only mention one modality.\n  - “Intracortical” and “Utah array/MEA” are common labels for microelectrode-array studies.\n\n### Block C: Motor-Related Neural Decoding (Movement/Action Intent)\n- Concept Role: Ensures the paper is about decoding motor-related neural activity (motor intent, movement, action) rather than other cognitive/sensory decoding.\n- Normalized Search Terms:\n  - motor decoding; movement decoding; action decoding\n  - motor intention; movement intention; intended movement; motor intent\n  - motor imagery (when used as a motor-control decoding paradigm)\n  - reach; reaching; grasp; hand movement; finger movement; limb movement; arm movement\n  - kinematics decoding; trajectory decoding; movement direction; velocity decoding\n- Notes on Term Usage:\n  - Motor tasks are described variably (e.g., “reach,” “grasp,” “kinematics”); include both generic (“motor decoding”) and task/variable terms (“trajectory,” “velocity”).\n  - This block is required to prevent drift into non-motor BCI (e.g., spelling, vision, affect).\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously (i) involve a brain–computer/neural interface framing, (ii) use invasive electrophysiological recordings specifically ECoG/iEEG/sEEG/MEA, and (iii) decode motor-related neural activity for control/intent.\n\n## Scope Control\n- In-scope:\n  - Motor BCIs using ECoG (subdural grids/strips), stereotactic iEEG/sEEG depth electrodes, or microelectrode arrays/intracortical MEAs.\n  - Human clinical implant studies and animal-model studies.\n  - Any motor function decoded (e.g., reach/grasp/hand/limb movement, kinematics) and any decoding approach (classical or deep learning; offline or online).\n- Out-of-scope:\n  - Non-invasive recordings (e.g., scalp EEG, MEG, fNIRS).\n  - Non-motor decoding BCIs (e.g., speech/language, visual, auditory, affective, memory) unless explicitly tied to motor decoding/control.\n  - Invasive neuromodulation/DBS-focused studies that do not perform motor decoding for BCI control.\n  - Pure physiology/motor neuroscience papers using these recordings without a BCI/neural-interface control/decoding objective.", "project_id": "6af7ac1b6254", "run_id": "a0d5fe7219d3", "step": "parse"}
{"ts": "2026-01-21T16:44:11.602274+00:00", "event": "phase1.parse.response", "project_id": "6af7ac1b6254", "run_id": "a0d5fe7219d3", "model": "gpt-5.2", "response": "## Conceptual Retrieval Framework\n\n### Block A: Brain–Computer Interface / Neural Interface (Motor Control Context)\n- Concept Role: Captures the BCI/neural-interface framing (including papers that may use “neural prosthesis” language rather than “BCI”).\n- Normalized Search Terms:\n  - brain-computer interface; brain–computer interface; BCI\n  - brain-machine interface; brain–machine interface; BMI\n  - neural interface; direct neural interface\n  - neural prosthesis; neuroprosthesis; brain-controlled; neural decoding for control\n- Notes on Term Usage:\n  - Include both “BCI” and “BMI” because communities use them interchangeably.\n  - “Neural prosthesis/neuroprosthesis” is often used in invasive motor-control decoding papers without explicitly saying “BCI.”\n\n### Block B: Invasive Electrophysiological Recording Modality (ECoG / iEEG / sEEG / MEA)\n- Concept Role: Restricts retrieval to invasive electrophysiological recordings explicitly named in the summary (subdural ECoG, stereotactic depth iEEG/sEEG, and microelectrode arrays/intracortical).\n- Normalized Search Terms:\n  - electrocorticography; electrocorticographic; ECoG; subdural grid; subdural strip; cortical surface electrodes\n  - intracranial EEG; iEEG; intracranial electroencephalography\n  - stereoelectroencephalography; stereo-EEG; sEEG; depth electrode; stereotactic EEG\n  - microelectrode array; MEA; intracortical recording; intracortical electrode; Utah array\n- Notes on Term Usage:\n  - Keep ECoG and iEEG/sEEG terms together as “invasive electrophysiology,” but list them explicitly because many records only mention one modality.\n  - “Intracortical” and “Utah array/MEA” are common labels for microelectrode-array studies.\n\n### Block C: Motor-Related Neural Decoding (Movement/Action Intent)\n- Concept Role: Ensures the paper is about decoding motor-related neural activity (motor intent, movement, action) rather than other cognitive/sensory decoding.\n- Normalized Search Terms:\n  - motor decoding; movement decoding; action decoding\n  - motor intention; movement intention; intended movement; motor intent\n  - motor imagery (when used as a motor-control decoding paradigm)\n  - reach; reaching; grasp; hand movement; finger movement; limb movement; arm movement\n  - kinematics decoding; trajectory decoding; movement direction; velocity decoding\n- Notes on Term Usage:\n  - Motor tasks are described variably (e.g., “reach,” “grasp,” “kinematics”); include both generic (“motor decoding”) and task/variable terms (“trajectory,” “velocity”).\n  - This block is required to prevent drift into non-motor BCI (e.g., spelling, vision, affect).\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously (i) involve a brain–computer/neural interface framing, (ii) use invasive electrophysiological recordings specifically ECoG/iEEG/sEEG/MEA, and (iii) decode motor-related neural activity for control/intent.\n\n## Scope Control\n- In-scope:\n  - Motor BCIs using ECoG (subdural grids/strips), stereotactic iEEG/sEEG depth electrodes, or microelectrode arrays/intracortical MEAs.\n  - Human clinical implant studies and animal-model studies.\n  - Any motor function decoded (e.g., reach/grasp/hand/limb movement, kinematics) and any decoding approach (classical or deep learning; offline or online).\n- Out-of-scope:\n  - Non-invasive recordings (e.g., scalp EEG, MEG, fNIRS).\n  - Non-motor decoding BCIs (e.g., speech/language, visual, auditory, affective, memory) unless explicitly tied to motor decoding/control.\n  - Invasive neuromodulation/DBS-focused studies that do not perform motor decoding for BCI control.\n  - Pure physiology/motor neuroscience papers using these recordings without a BCI/neural-interface control/decoding objective."}
{"ts": "2026-01-21T16:45:32.016338+00:00", "event": "phase1.query_build.prompt", "project_id": "6af7ac1b6254", "run_id": "a0d5fe7219d3", "model": "gpt-5.2", "reasoning_effort": "high", "prompt": "You are an expert biomedical information retrieval engineer specializing in PubMed search strategies.\n\nBelow is a Conceptual Retrieval Framework, your task is to convert the framework into one or more executable PubMed search queries.\n\n-- Conceptual Retrieval Framework begin --\n## Conceptual Retrieval Framework\n\n### Block A: Brain–Computer Interface / Neural Interface (Motor Control Context)\n- Concept Role: Captures the BCI/neural-interface framing (including papers that may use “neural prosthesis” language rather than “BCI”).\n- Normalized Search Terms:\n  - brain-computer interface; brain–computer interface; BCI\n  - brain-machine interface; brain–machine interface; BMI\n  - neural interface; direct neural interface\n  - neural prosthesis; neuroprosthesis; brain-controlled; neural decoding for control\n- Notes on Term Usage:\n  - Include both “BCI” and “BMI” because communities use them interchangeably.\n  - “Neural prosthesis/neuroprosthesis” is often used in invasive motor-control decoding papers without explicitly saying “BCI.”\n\n### Block B: Invasive Electrophysiological Recording Modality (ECoG / iEEG / sEEG / MEA)\n- Concept Role: Restricts retrieval to invasive electrophysiological recordings explicitly named in the summary (subdural ECoG, stereotactic depth iEEG/sEEG, and microelectrode arrays/intracortical).\n- Normalized Search Terms:\n  - electrocorticography; electrocorticographic; ECoG; subdural grid; subdural strip; cortical surface electrodes\n  - intracranial EEG; iEEG; intracranial electroencephalography\n  - stereoelectroencephalography; stereo-EEG; sEEG; depth electrode; stereotactic EEG\n  - microelectrode array; MEA; intracortical recording; intracortical electrode; Utah array\n- Notes on Term Usage:\n  - Keep ECoG and iEEG/sEEG terms together as “invasive electrophysiology,” but list them explicitly because many records only mention one modality.\n  - “Intracortical” and “Utah array/MEA” are common labels for microelectrode-array studies.\n\n### Block C: Motor-Related Neural Decoding (Movement/Action Intent)\n- Concept Role: Ensures the paper is about decoding motor-related neural activity (motor intent, movement, action) rather than other cognitive/sensory decoding.\n- Normalized Search Terms:\n  - motor decoding; movement decoding; action decoding\n  - motor intention; movement intention; intended movement; motor intent\n  - motor imagery (when used as a motor-control decoding paradigm)\n  - reach; reaching; grasp; hand movement; finger movement; limb movement; arm movement\n  - kinematics decoding; trajectory decoding; movement direction; velocity decoding\n- Notes on Term Usage:\n  - Motor tasks are described variably (e.g., “reach,” “grasp,” “kinematics”); include both generic (“motor decoding”) and task/variable terms (“trajectory,” “velocity”).\n  - This block is required to prevent drift into non-motor BCI (e.g., spelling, vision, affect).\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously (i) involve a brain–computer/neural interface framing, (ii) use invasive electrophysiological recordings specifically ECoG/iEEG/sEEG/MEA, and (iii) decode motor-related neural activity for control/intent.\n\n## Scope Control\n- In-scope:\n  - Motor BCIs using ECoG (subdural grids/strips), stereotactic iEEG/sEEG depth electrodes, or microelectrode arrays/intracortical MEAs.\n  - Human clinical implant studies and animal-model studies.\n  - Any motor function decoded (e.g., reach/grasp/hand/limb movement, kinematics) and any decoding approach (classical or deep learning; offline or online).\n- Out-of-scope:\n  - Non-invasive recordings (e.g., scalp EEG, MEG, fNIRS).\n  - Non-motor decoding BCIs (e.g., speech/language, visual, auditory, affective, memory) unless explicitly tied to motor decoding/control.\n  - Invasive neuromodulation/DBS-focused studies that do not perform motor decoding for BCI control.\n  - Pure physiology/motor neuroscience papers using these recordings without a BCI/neural-interface control/decoding objective.\n-- Conceptual Retrieval Framework end --\n\n\nYou must follow these rules strictly:\n\n1. Do NOT reinterpret, merge, or split any concept blocks.\n   - Treat each concept block as an independent retrieval dimension.\n   - Preserve the block structure exactly as given.\n\n2. For each concept block:\n   - Combine all normalized search terms within that block using OR.\n   - Apply PubMed field tags consistently, using Title/Abstract fields\n     unless a term is a standard abbreviation or acronym.\n\n3. Across concept blocks:\n   - Combine blocks using AND.\n   - The final query must require that all blocks are satisfied simultaneously.\n\n4. Do NOT introduce new search terms, synonyms, or expansions.\n   - Use ONLY the terms explicitly listed in the framework.\n\n5. Phrase handling:\n   - Multi-word terms must be enclosed in double quotation marks.\n   - Singular/plural variations should be preserved as given; do not infer new ones.\n\n6. PubMed field usage:\n   - Use [Title/Abstract] for most terms.\n   - Acronyms (e.g., BCI, ECoG, iEEG) may be used without field tags\n     only if they are standard and unambiguous.\n   - Do NOT use MeSH terms in this step.\n\n7. If a block contains usage constraints (e.g., “only when paired with X”),\n   enforce this by block-level AND logic, not by modifying individual terms.\n\n8. Output formatting:\n   - Clearly label each block’s query segment.\n   - Provide the final combined PubMed query in a single code block.\n   - Do NOT include explanatory text outside the required output format.\n\n### Output Format (must follow exactly):\n\n## PubMed Query Blocks\n\n### Block A Query\n(query text)\n\n### Block B Query\n(query text)\n\n(Repeat for each block)\n\n## Final Combined PubMed Query\n```text\n(full PubMed query)\n"}
{"ts": "2026-01-21T16:45:48.797699+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "## PubMed Query Blocks\n\n### Block A Query\n(\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR \"brain–machine interface\"[Title/Abstract] OR BMI OR \"neural interface\"[Title/Abstract] OR \"direct neural interface\"[Title/Abstract] OR \"neural prosthesis\"[Title/Abstract] OR neuroprosthesis[Title/Abstract] OR \"brain-controlled\"[Title/Abstract] OR \"neural decoding for control\"[Title/Abstract])\n\n### Block B Query\n(electrocorticography[Title/Abstract] OR electrocorticographic[Title/Abstract] OR ECoG OR \"subdural grid\"[Title/Abstract] OR \"subdural strip\"[Title/Abstract] OR \"cortical surface electrodes\"[Title/Abstract] OR \"intracranial EEG\"[Title/Abstract] OR iEEG OR \"intracranial electroencephalography\"[Title/Abstract] OR stereoelectroencephalography[Title/Abstract] OR \"stereo-EEG\"[Title/Abstract] OR sEEG OR \"depth electrode\"[Title/Abstract] OR \"stereotactic EEG\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"intracortical recording\"[Title/Abstract] OR \"intracortical electrode\"[Title/Abstract] OR \"Utah array\"[Title/Abstract])\n\n### Block C Query\n(\"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"action decoding\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"movement intention\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor intent\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract] OR reach[Title/Abstract] OR reaching[Title/Abstract] OR grasp[Title/Abstract] OR \"hand movement\"[Title/Abstract] OR \"finger movement\"[Title/Abstract] OR \"limb movement\"[Title/Abstract] OR \"arm movement\"[Title/Abstract] OR \"kinematics decoding\"[Title/Abstract] OR \"trajectory decoding\"[Title/Abstract] OR \"movement direction\"[Title/Abstract] OR \"velocity decoding\"[Title/Abstract])\n\n## Final Combined PubMed Query\n```text\n((\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR \"brain–machine interface\"[Title/Abstract] OR BMI OR \"neural interface\"[Title/Abstract] OR \"direct neural interface\"[Title/Abstract] OR \"neural prosthesis\"[Title/Abstract] OR neuroprosthesis[Title/Abstract] OR \"brain-controlled\"[Title/Abstract] OR \"neural decoding for control\"[Title/Abstract])\nAND\n(electrocorticography[Title/Abstract] OR electrocorticographic[Title/Abstract] OR ECoG OR \"subdural grid\"[Title/Abstract] OR \"subdural strip\"[Title/Abstract] OR \"cortical surface electrodes\"[Title/Abstract] OR \"intracranial EEG\"[Title/Abstract] OR iEEG OR \"intracranial electroencephalography\"[Title/Abstract] OR stereoelectroencephalography[Title/Abstract] OR \"stereo-EEG\"[Title/Abstract] OR sEEG OR \"depth electrode\"[Title/Abstract] OR \"stereotactic EEG\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"intracortical recording\"[Title/Abstract] OR \"intracortical electrode\"[Title/Abstract] OR \"Utah array\"[Title/Abstract])\nAND\n(\"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"action decoding\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"movement intention\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor intent\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract] OR reach[Title/Abstract] OR reaching[Title/Abstract] OR grasp[Title/Abstract] OR \"hand movement\"[Title/Abstract] OR \"finger movement\"[Title/Abstract] OR \"limb movement\"[Title/Abstract] OR \"arm movement\"[Title/Abstract] OR \"kinematics decoding\"[Title/Abstract] OR \"trajectory decoding\"[Title/Abstract] OR \"movement direction\"[Title/Abstract] OR \"velocity decoding\"[Title/Abstract]))\n```", "project_id": "6af7ac1b6254", "run_id": "a0d5fe7219d3", "step": "query_build"}
{"ts": "2026-01-21T16:45:48.799497+00:00", "event": "phase1.query_build.response", "project_id": "6af7ac1b6254", "run_id": "a0d5fe7219d3", "model": "gpt-5.2", "response": "## PubMed Query Blocks\n\n### Block A Query\n(\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR \"brain–machine interface\"[Title/Abstract] OR BMI OR \"neural interface\"[Title/Abstract] OR \"direct neural interface\"[Title/Abstract] OR \"neural prosthesis\"[Title/Abstract] OR neuroprosthesis[Title/Abstract] OR \"brain-controlled\"[Title/Abstract] OR \"neural decoding for control\"[Title/Abstract])\n\n### Block B Query\n(electrocorticography[Title/Abstract] OR electrocorticographic[Title/Abstract] OR ECoG OR \"subdural grid\"[Title/Abstract] OR \"subdural strip\"[Title/Abstract] OR \"cortical surface electrodes\"[Title/Abstract] OR \"intracranial EEG\"[Title/Abstract] OR iEEG OR \"intracranial electroencephalography\"[Title/Abstract] OR stereoelectroencephalography[Title/Abstract] OR \"stereo-EEG\"[Title/Abstract] OR sEEG OR \"depth electrode\"[Title/Abstract] OR \"stereotactic EEG\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"intracortical recording\"[Title/Abstract] OR \"intracortical electrode\"[Title/Abstract] OR \"Utah array\"[Title/Abstract])\n\n### Block C Query\n(\"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"action decoding\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"movement intention\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor intent\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract] OR reach[Title/Abstract] OR reaching[Title/Abstract] OR grasp[Title/Abstract] OR \"hand movement\"[Title/Abstract] OR \"finger movement\"[Title/Abstract] OR \"limb movement\"[Title/Abstract] OR \"arm movement\"[Title/Abstract] OR \"kinematics decoding\"[Title/Abstract] OR \"trajectory decoding\"[Title/Abstract] OR \"movement direction\"[Title/Abstract] OR \"velocity decoding\"[Title/Abstract])\n\n## Final Combined PubMed Query\n```text\n((\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR \"brain–machine interface\"[Title/Abstract] OR BMI OR \"neural interface\"[Title/Abstract] OR \"direct neural interface\"[Title/Abstract] OR \"neural prosthesis\"[Title/Abstract] OR neuroprosthesis[Title/Abstract] OR \"brain-controlled\"[Title/Abstract] OR \"neural decoding for control\"[Title/Abstract])\nAND\n(electrocorticography[Title/Abstract] OR electrocorticographic[Title/Abstract] OR ECoG OR \"subdural grid\"[Title/Abstract] OR \"subdural strip\"[Title/Abstract] OR \"cortical surface electrodes\"[Title/Abstract] OR \"intracranial EEG\"[Title/Abstract] OR iEEG OR \"intracranial electroencephalography\"[Title/Abstract] OR stereoelectroencephalography[Title/Abstract] OR \"stereo-EEG\"[Title/Abstract] OR sEEG OR \"depth electrode\"[Title/Abstract] OR \"stereotactic EEG\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"intracortical recording\"[Title/Abstract] OR \"intracortical electrode\"[Title/Abstract] OR \"Utah array\"[Title/Abstract])\nAND\n(\"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"action decoding\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"movement intention\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor intent\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract] OR reach[Title/Abstract] OR reaching[Title/Abstract] OR grasp[Title/Abstract] OR \"hand movement\"[Title/Abstract] OR \"finger movement\"[Title/Abstract] OR \"limb movement\"[Title/Abstract] OR \"arm movement\"[Title/Abstract] OR \"kinematics decoding\"[Title/Abstract] OR \"trajectory decoding\"[Title/Abstract] OR \"movement direction\"[Title/Abstract] OR \"velocity decoding\"[Title/Abstract]))\n```"}
{"ts": "2026-01-21T16:47:51.233329+00:00", "event": "phase2.affiliation_extraction.prompt", "batch_size": 4, "model": "gpt-5.2", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/affiliation_extraction.md", "full_prompt": "You are a geographic data extractor for academic affiliations.\n\nExtract the following from each affiliation string:\n- country: Full country name (e.g., \"United States\", \"United Kingdom\", \"China\")\n- city: City name (e.g., \"Boston\", \"London\", \"Beijing\")\n- institution: Primary institution name if present (e.g., \"Harvard Medical School\", \"MIT\")\n\n\nRules:\n1. Guess the missing info based on the available info. \n2. Use full country names, not abbreviations (USA → United States)\n3. confidence: \"high\" if all fields clear, \"medium\" if some unclear, \"low\" if very ambiguous\n\nIMPORTANT - Country and City extraction rules:\n- DO NOT extract US state abbreviations (MD, OH, WV, NY, CA, etc.) as cities\n- Only extract actual city names (e.g., \"Boston\", \"Albany\", \"San Francisco\", \"New York\" without state/abbreviations)\n- The guess should be valid and true. For example, \"Massachusetts Institute of Technology, Cambridge, MA 02139\" should be inferred as United States. It would be wrong if it is inferred as 'Cambridge, Morocco', even MA is the country code for Morocco.\n\n\nReturn a JSON array with one object per affiliation in the EXACT same order as input:\n[\n  {\"country\": \"United States\", \"city\": \"Boston\", \"institution\": \"Massachusetts General Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"China\", \"city\": \"Beijing\", \"institution\": null, \"confidence\": \"medium\"},\n  ...\n]\n\nAffiliations to process:\n1. Department of Biomedical Engineering, School of Electrical Engineering, Iran University of Science and Technology (IUST), Iran Neural Technology Research Centre, Tehran, Iran.\n2. Department of Computer Engineering, Wilhelm-Schickard-Institute, Eberhard Karls Universität Tübingen Tübingen, Germany.\n3. John Hopkins University Applied Physics Laboratory, Laurel, MD 20723.\n4. Defense Advanced Research Projects Agency, Arlington, VA 22203.\n\n"}
{"ts": "2026-01-21T16:47:53.974606+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "```json\n[\n  {\n    \"country\": \"Iran\",\n    \"city\": \"Tehran\",\n    \"institution\": \"Iran University of Science and Technology (IUST)\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"Germany\",\n    \"city\": \"Tübingen\",\n    \"institution\": \"Eberhard Karls Universität Tübingen\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"United States\",\n    \"city\": \"Laurel\",\n    \"institution\": \"Johns Hopkins University Applied Physics Laboratory\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"United States\",\n    \"city\": \"Arlington\",\n    \"institution\": \"Defense Advanced Research Projects Agency\",\n    \"confidence\": \"high\"\n  }\n]\n```"}
{"ts": "2026-01-21T16:47:53.974949+00:00", "event": "phase2.affiliation_extraction.response", "batch_size": 4, "model": "gpt-5.2", "raw_json_response": "```json\n[\n  {\n    \"country\": \"Iran\",\n    \"city\": \"Tehran\",\n    \"institution\": \"Iran University of Science and Technology (IUST)\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"Germany\",\n    \"city\": \"Tübingen\",\n    \"institution\": \"Eberhard Karls Universität Tübingen\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"United States\",\n    \"city\": \"Laurel\",\n    \"institution\": \"Johns Hopkins University Applied Physics Laboratory\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"United States\",\n    \"city\": \"Arlington\",\n    \"institution\": \"Defense Advanced Research Projects Agency\",\n    \"confidence\": \"high\"\n  }\n]\n```"}
{"ts": "2026-01-21T17:24:26.319962+00:00", "event": "parse.stage1.prompt", "project_id": "6af7ac1b6254", "run_id": "4dbd2ac34e0f", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage1_understanding.md", "prompt": "你是“研究描述理解与规范化”模块。输入是一段纯文本候选研究描述。你的目标是帮助用户把研究描述变得合理且清晰，便于后续生成文献检索查询。\n\n你必须完成：\n1) 判断这段描述是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true.\n2) 如果是研究描述,进行常识可行性判断（plausibility_level）：\n- A_impossible：明显荒诞/违背当前科技常识（无法形成合理检索任务）\n- B_plausible：合理可行\n3) 如果合理可行，给出你对该研究描述的“当前理解”（normalized_understanding），用规范化、聚焦、可检索的英语重写，\n4) 判断当前理解是否已经清晰到可以用于检索；若不清晰，列出你仍不确定的点（疑问清单），并提出最多3个澄清问题（问题必须具体可回答）。\n5) 输出结构化提要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n6) 只输出JSON，不输出任何额外文本。\n\n候选研究描述：\n\"\"\"I focus on motor brain-computer interface based on the invasive EEG signals.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n}\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - ncertainties/missing_fields/suggested_questions为空数组[];\n  - structured_summary为全null；\n- normalized_understanding：300-600个英文字符，必须是你对研究的“当前理解”，语言规范、聚焦、可检索；不要写“我认为/可能”等口水话，直接用陈述句组织。\n\n- 如果 是B_plausible，且 is_clear_for_search=true，则：\n  - is_research_description = true\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空数组或只保留0-1条轻微风险\n\n- 如果 是B_plausible，且 is_clear_for_search=false，则：\n  - is_research_description = true\n  - uncertainties 至少2条\n  - missing_fields 仅列出缺失项\n  - suggested_questions 为1-3条，必须与 uncertainties/missing_fields 对应\n\n- 如果 plausibility_level=A_impossible，则：\n  - is_clear_for_search=false\n  - suggested_questions 为空\n  - uncertainties <=200英文字符：给出impossible的原因。\n"}
{"ts": "2026-01-21T17:24:40.979769+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces (BCIs) that decode movement intention from invasively recorded electrophysiological brain signals (e.g., intracranial EEG/ECoG) to control external devices or restore motor function. The work targets signal acquisition, preprocessing, feature extraction, and machine-learning decoding of motor-related neural activity, with evaluation on human or animal datasets and real-time BCI performance metrics.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces; neuroengineering; neural signal processing\",\n    \"task\": \"Decode motor intention/kinematics from invasive electrophysiological recordings for BCI control\",\n    \"subject_system\": \"Invasive recordings from motor-related cortex (intracranial EEG/ECoG; possibly depth electrodes) in humans or animals\",\n    \"methods\": \"Neural signal preprocessing, time–frequency features, machine learning/deep learning decoders, real-time BCI evaluation\",\n    \"scope\": \"Motor BCI using invasive electrophysiology; online or offline decoding; device control or motor restoration\",\n    \"intent\": \"Improve accuracy, robustness, and usability of motor BCIs based on invasive neural signals\",\n    \"exclusions\": \"Non-invasive EEG-only BCIs; non-motor cognitive BCIs; purely clinical stimulation without decoding\"\n  },\n  \"uncertainties\": [\n    \"The phrase 'invasive EEG' is ambiguous; it could mean ECoG, intracranial EEG (sEEG), or other invasive recordings.\",\n    \"The specific motor task and output (discrete commands vs continuous kinematics; cursor/robot/prosthesis control) are not specified.\",\n    \"Target population and study setting (human clinical implants vs animal models; online closed-loop vs offline analysis) are unclear.\"\n  ],\n  \"missing_fields\": [\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"What invasive signal modality do you mean by 'invasive EEG' (ECoG grids/strips, stereotactic depth iEEG/sEEG, or microelectrode arrays), and from which brain regions?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What motor decoding target is studied (e.g., movement intention classification, grasp type, continuous hand/arm kinematics, gait), and what is the controlled effector/device?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Is the focus on offline decoding benchmarks or real-time closed-loop BCI control, and in which population (human patients, healthy participants, or animal models)?\"\n    }\n  ]\n}", "project_id": "6af7ac1b6254", "run_id": "4dbd2ac34e0f", "stage": "stage1"}
{"ts": "2026-01-21T17:24:40.981605+00:00", "event": "parse.stage1.response", "project_id": "6af7ac1b6254", "run_id": "4dbd2ac34e0f", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces (BCIs) that decode movement intention from invasively recorded electrophysiological brain signals (e.g., intracranial EEG/ECoG) to control external devices or restore motor function. The work targets signal acquisition, preprocessing, feature extraction, and machine-learning decoding of motor-related neural activity, with evaluation on human or animal datasets and real-time BCI performance metrics.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces; neuroengineering; neural signal processing\",\n    \"task\": \"Decode motor intention/kinematics from invasive electrophysiological recordings for BCI control\",\n    \"subject_system\": \"Invasive recordings from motor-related cortex (intracranial EEG/ECoG; possibly depth electrodes) in humans or animals\",\n    \"methods\": \"Neural signal preprocessing, time–frequency features, machine learning/deep learning decoders, real-time BCI evaluation\",\n    \"scope\": \"Motor BCI using invasive electrophysiology; online or offline decoding; device control or motor restoration\",\n    \"intent\": \"Improve accuracy, robustness, and usability of motor BCIs based on invasive neural signals\",\n    \"exclusions\": \"Non-invasive EEG-only BCIs; non-motor cognitive BCIs; purely clinical stimulation without decoding\"\n  },\n  \"uncertainties\": [\n    \"The phrase 'invasive EEG' is ambiguous; it could mean ECoG, intracranial EEG (sEEG), or other invasive recordings.\",\n    \"The specific motor task and output (discrete commands vs continuous kinematics; cursor/robot/prosthesis control) are not specified.\",\n    \"Target population and study setting (human clinical implants vs animal models; online closed-loop vs offline analysis) are unclear.\"\n  ],\n  \"missing_fields\": [\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"What invasive signal modality do you mean by 'invasive EEG' (ECoG grids/strips, stereotactic depth iEEG/sEEG, or microelectrode arrays), and from which brain regions?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What motor decoding target is studied (e.g., movement intention classification, grasp type, continuous hand/arm kinematics, gait), and what is the controlled effector/device?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Is the focus on offline decoding benchmarks or real-time closed-loop BCI control, and in which population (human patients, healthy participants, or animal models)?\"\n    }\n  ]\n}"}
{"ts": "2026-01-21T17:26:15.604535+00:00", "event": "parse.stage2.prompt", "project_id": "6af7ac1b6254", "run_id": "4dbd2ac34e0f", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage2_converge.md", "prompt": "你是“研究描述自我收敛器”。你将收到三段文本：\n(1) 当前候选研究描述 current_description\n(2) 关于当前研究描述的问题question_for_user\n(3) 用户本轮补充信息 user_additional_info（可能回答了你上轮的问题，也可能没有）\n\n你的任务是：\n1) 判断当前候选研究描述和用户本轮补充信息是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true，并将两段文本融合，形成你对研究内容的“当前理解”，并判断更新后的研究内容是否合理：\n- A_impossible：明显荒诞/违背当前科技常识，无法形成合理检索任务\n- B_plausible：合理可行\n2) 如果A_impossible，给出简单的理由。如果新的理解是合理可行的，就用规范、聚焦、可检索的英文重写（300-600英文字符），这段重写用于帮助用户组织语言与规范表述。\n3) 判断本轮补充的信息是否对解答question_for_user有帮助。有帮助的话就返回 is_helpful=true。\n4) 如果在新增信息后仍不清晰：输出你仍不确定的点（uncertainties），并提出最多3个澄清问题（具体可回答，优先信息增益最大）。\n5) 如果已经清晰：不要再提问题；只输出你的理解与结构化摘要。\n6) 输出结构化摘要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n只输出JSON，不输出任何额外文字。\n\ncurrent_description：\n\"\"\"I focus on motor brain-computer interface based on the invasive EEG signals.\"\"\"\n\nquestion_for_user：\n\"\"\"What invasive signal modality do you mean by 'invasive EEG' (ECoG grids/strips, stereotactic depth iEEG/sEEG, or microelectrode arrays), and from which brain regions?\nWhat motor decoding target is studied (e.g., movement intention classification, grasp type, continuous hand/arm kinematics, gait), and what is the controlled effector/device?\nIs the focus on offline decoding benchmarks or real-time closed-loop BCI control, and in which population (human patients, healthy participants, or animal models)?\"\"\"\n\n\nuser_additional_info（用户本轮补充信息，可能为空）：\n\"\"\"For invasive EEG, I mean ECog, sEEG, MEA. There is no restriction on the brain region, decoding target, effector or population. It could be both offline and real-time control.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"is_helpful\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n  }\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - 其他所有字段都为空。\n- normalized_understanding：300-600英文字符，必须是你融合两段文本后的“当前理解”，术语一致、范围聚焦。\n- 如果 plausibility_level=B_plausible且is_clear_for_search=true：\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空或最多1条轻微风险\n- 如果 plausibility_level=B_plausible且is_clear_for_search=false：\n  - uncertainties 至少2条\n  - suggested_questions 为1-3条，必须与uncertainties/missing_fields一致\n\n- 如果 plausibility_level=A_impossible：\n  - is_clear_for_search 必须为 false\n  - suggested_questions 必须为空数组\n  - uncertainties <=200英文字符：提示用户impossible的原因。\n"}
{"ts": "2026-01-21T17:26:27.965682+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"The research focuses on motor brain–computer interfaces using invasive electrophysiology, including ECoG grids/strips, stereotactic depth iEEG (sEEG), and microelectrode arrays (MEA). It broadly targets decoding motor-related information from these signals and translating it into BCI outputs, potentially covering both offline decoding benchmarks and real-time closed-loop control. No specific constraints are set on brain regions, decoding targets, effectors/devices, or subject populations.\",\n  \"structured_summary\": {\n    \"domain\": \"Motor brain–computer interfaces (BCI) using invasive neural recordings\",\n    \"task\": \"Decode motor-related intent/kinematics from ECoG/sEEG/MEA for BCI control (offline and/or closed-loop)\",\n    \"subject_system\": \"Invasive cortical/depth electrophysiology (ECoG, sEEG, MEA) from motor-related brain areas (unspecified); subjects/populations unspecified\",\n    \"methods\": \"Neural signal processing and machine learning/decoding models for motor BCI (specific algorithms unspecified)\",\n    \"scope\": \"Broad: any brain region, decoding target, effector/device, and population; includes offline and real-time control\",\n    \"intent\": \"Develop and evaluate invasive-signal motor decoding and BCI control approaches\",\n    \"exclusions\": \"Not specified\"\n  },\n  \"uncertainties\": [\n    \"The scope is too unconstrained (region/target/effector/population), making the description hard to search and compare against prior work.\",\n    \"It is unclear whether the primary contribution is decoding algorithms, feature representations, closed-loop control design, or clinical translation/validation.\"\n  ],\n  \"missing_fields\": [\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"What is your primary motor decoding objective (e.g., discrete intention/grasp classification, continuous hand/arm kinematics, speech-motor, gait), and what is the intended controlled effector/device?\"\n    },\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Which recording modality is your main focus (ECoG vs sEEG vs MEA), and what are the typical target regions (e.g., M1, PMd, SMA, PPC, STN) and subject population (human patients, animals)?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What methodological contribution do you emphasize (e.g., deep learning vs state-space/Kalman, self-supervised learning, domain adaptation, neural feature engineering, real-time closed-loop adaptation)?\"\n    }\n  ]\n}", "project_id": "6af7ac1b6254", "run_id": "4dbd2ac34e0f", "stage": "stage2"}
{"ts": "2026-01-21T17:26:27.967966+00:00", "event": "parse.stage2.response", "project_id": "6af7ac1b6254", "run_id": "4dbd2ac34e0f", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"The research focuses on motor brain–computer interfaces using invasive electrophysiology, including ECoG grids/strips, stereotactic depth iEEG (sEEG), and microelectrode arrays (MEA). It broadly targets decoding motor-related information from these signals and translating it into BCI outputs, potentially covering both offline decoding benchmarks and real-time closed-loop control. No specific constraints are set on brain regions, decoding targets, effectors/devices, or subject populations.\",\n  \"structured_summary\": {\n    \"domain\": \"Motor brain–computer interfaces (BCI) using invasive neural recordings\",\n    \"task\": \"Decode motor-related intent/kinematics from ECoG/sEEG/MEA for BCI control (offline and/or closed-loop)\",\n    \"subject_system\": \"Invasive cortical/depth electrophysiology (ECoG, sEEG, MEA) from motor-related brain areas (unspecified); subjects/populations unspecified\",\n    \"methods\": \"Neural signal processing and machine learning/decoding models for motor BCI (specific algorithms unspecified)\",\n    \"scope\": \"Broad: any brain region, decoding target, effector/device, and population; includes offline and real-time control\",\n    \"intent\": \"Develop and evaluate invasive-signal motor decoding and BCI control approaches\",\n    \"exclusions\": \"Not specified\"\n  },\n  \"uncertainties\": [\n    \"The scope is too unconstrained (region/target/effector/population), making the description hard to search and compare against prior work.\",\n    \"It is unclear whether the primary contribution is decoding algorithms, feature representations, closed-loop control design, or clinical translation/validation.\"\n  ],\n  \"missing_fields\": [\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"What is your primary motor decoding objective (e.g., discrete intention/grasp classification, continuous hand/arm kinematics, speech-motor, gait), and what is the intended controlled effector/device?\"\n    },\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Which recording modality is your main focus (ECoG vs sEEG vs MEA), and what are the typical target regions (e.g., M1, PMd, SMA, PPC, STN) and subject population (human patients, animals)?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What methodological contribution do you emphasize (e.g., deep learning vs state-space/Kalman, self-supervised learning, domain adaptation, neural feature engineering, real-time closed-loop adaptation)?\"\n    }\n  ]\n}"}
{"ts": "2026-01-21T17:26:40.195720+00:00", "event": "phase1.parse.prompt", "project_id": "6af7ac1b6254", "run_id": "4dbd2ac34e0f", "model": "gpt-5.2", "reasoning_effort": "high", "prompt": "You are an expert academic search strategist specializing in exhaustive literature retrieval. \n\nBelow is a short research summary, your task is to take above research summary and directly produce a conceptual retrieval framework that can be used to systematically search for all relevant literature in that research field.\n\n-- research summary begin --\nThe research focuses on motor brain–computer interfaces using invasive electrophysiology, including ECoG grids/strips, stereotactic depth iEEG (sEEG), and microelectrode arrays (MEA). It broadly targets decoding motor-related information from these signals and translating it into BCI outputs, potentially covering both offline decoding benchmarks and real-time closed-loop control. No specific constraints are set on brain regions, decoding targets, effectors/devices, or subject populations.\n-- research summary end --\n\nThis is NOT a query-generation task.\nThis is a concept-framework construction task.\n\nYou must follow these rules strictly:\n\n1. Base the framework ONLY on the content explicitly stated or clearly implied in the research summary.\n   - Do NOT introduce new research goals, populations, or application domains.\n   - Do NOT speculate beyond the summary.\n\n2. The output must define a SMALL NUMBER of concept blocks (typically 2–4).\n   - Each block represents a distinct and independently searchable conceptual dimension\nthat should not be merged with other dimensions if doing so would reduce recall.\n   - Examples include: research task, technical field/framing, data modality.\n   - All blocks together must uniquely define ONE narrow research field.\n\nIMPORTANT — Concept Block Separation Rule:\n\nWhen constructing concept blocks, prioritize retrieval independence over semantic compactness.\n\nIf two concepts frequently appear separately in relevant literature\n(e.g., one may be mentioned without the other in titles/abstracts),\nthey MUST be placed in separate concept blocks,\neven if they form a well-known combined phrase or subfield name.\n\nExample:\n- “speech” and “brain-computer interface” must be separate blocks,\n  because many relevant papers mention speech decoding without explicitly using “BCI”,\n  and others mention BCI without explicitly using “speech”.\n\n\n3. Each concept block must:\n   - Contain only terms that are conceptually equivalent within that block.\n   - Be expressed using terminology commonly found in academic databases.\n   - Include common synonyms, abbreviations, and canonical terms used in the literature.\n\n4. When the summary uses abstract or high-level language, normalize it into concrete, database-searchable concepts\n   ONLY when such normalization is standard practice in the field.\n   - Example: “invasive recordings” → ECoG, sEEG, intracortical recordings, MEA\n   - Do NOT introduce loosely related or adjacent techniques.\n\n5. All concept blocks must be REQUIRED.\n   - The framework should be designed for exhaustive retrieval within a specific field,\n     not for exploratory or cross-domain search.\n\n6. Do NOT generate executable Boolean queries.\n   - You MAY describe the logical relationship between blocks conceptually\n     (e.g., “documents must address all blocks simultaneously”),\n     but do not use database syntax.\n\n7. Explicitly prevent topic drift.\n   - The framework should clearly exclude adjacent but distinct research areas.\n\n### Output Format (must follow exactly):\n\n## Conceptual Retrieval Framework\n\n### Block A: [Concept Block Name]\n- Concept Role:\n- Normalized Search Terms:\n- Notes on Term Usage:\n\n### Block B: [Concept Block Name]\n- Concept Role:\n- Normalized Search Terms:\n- Notes on Term Usage:\n\n(Repeat blocks as needed)\n\n## Conceptual Combination Rule\nA single sentence explaining how all blocks jointly define the target literature set.\n\n## Scope Control\n- In-scope:\n- Out-of-scope:\n"}
{"ts": "2026-01-21T17:27:09.998584+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "## Conceptual Retrieval Framework\n\n### Block A: Brain–Computer Interface / Neural Interface Framing\n- Concept Role: Ensures the literature is explicitly about translating neural signals into control/communication outputs (BCI/BMI/neural prosthetics), including offline decoding benchmarks and real-time/closed-loop use.\n- Normalized Search Terms:\n  - “brain-computer interface”\n  - BCI\n  - “brain-machine interface”\n  - BMI\n  - “neural interface”\n  - “neural prosthesis” / “neural prosthetic”\n  - “cortical prosthesis” / “cortical prosthetic”\n  - “neuroprosthesis” / “neuroprosthetic”\n  - “direct neural interface”\n  - “closed-loop” (as used in BCI/neural interface contexts)\n  - “real-time” (as used in BCI/neural interface contexts)\n- Notes on Term Usage:\n  - Many relevant papers use BMI rather than BCI, or “neural prosthesis” without the word BCI; keep these equivalent within this block.\n  - “Closed-loop” and “real-time” are not required subtopics, but are common descriptors of BCI operation and help capture control-oriented papers.\n\n### Block B: Invasive Electrophysiology Recording Modality (ECoG / iEEG / sEEG / MEA)\n- Concept Role: Restricts retrieval to invasive electrophysiological signals specifically named in the summary (ECoG grids/strips, stereotactic depth iEEG/sEEG, and microelectrode arrays/intracortical recordings).\n- Normalized Search Terms:\n  - ECoG / electrocorticography / electrocorticogram\n  - “subdural grid” / “subdural grids”\n  - “subdural strip” / “subdural strips”\n  - iEEG / “intracranial EEG” / “intracranial electroencephalography”\n  - “intracranial electrophysiology”\n  - sEEG / SEEG / “stereo-EEG” / “stereoelectroencephalography”\n  - “depth electrode” / “depth electrodes”\n  - “microelectrode array” / MEA\n  - “intracortical recording” / “intracortical recordings”\n  - “single-unit” / “multiunit” / “spike” / “spiking activity” (when used as intracortical/MEA outputs)\n  - “local field potential” / LFP (when used in intracortical/MEA contexts)\n- Notes on Term Usage:\n  - Use both umbrella terms (iEEG, intracranial EEG) and device-specific terms (grid/strip, depth electrode, microelectrode array) because papers vary in how explicitly they name the hardware.\n  - Keep this block strictly invasive electrophysiology; do not substitute noninvasive modalities.\n\n### Block C: Motor Information Decoding / Motor Control Targets\n- Concept Role: Captures the core analytic task: decoding motor-related information from invasive electrophysiology for BCI outputs (movement/kinematics/intention/action-related neural decoding).\n- Normalized Search Terms:\n  - “motor decoding”\n  - “movement decoding”\n  - “motor intention” / “movement intention”\n  - “motor imagery” (when used as a motor-related decoding target)\n  - “motor control”\n  - “movement” / “voluntary movement” (in decoding contexts)\n  - “kinematics” / “trajectory” / “position” / “velocity” / “acceleration” (as decoded variables)\n  - “force” / “grip force” (as decoded variables)\n  - “reach” / “reaching”\n  - “grasp” / “gripping”\n  - “hand” / “arm” / “finger” movement (as decoded effectors)\n  - “cursor control” (as a motor BCI output/control proxy)\n  - “neural decoding” / “decode” / “decoder” (paired with motor terms)\n- Notes on Term Usage:\n  - Motor BCI papers may describe outputs as “cursor control” or “control signals” without naming a specific effector; include these as motor-control proxies but keep the block anchored to motor/movement language.\n  - Avoid adding specific brain regions or populations; the summary sets no constraints there.\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously (1) frame a brain–computer/brain–machine/neural interface, (2) use invasive electrophysiology specifically including ECoG/iEEG/sEEG and/or microelectrode arrays, and (3) decode motor-related information for BCI output/control (offline decoding and/or real-time closed-loop).\n\n## Scope Control\n- In-scope:\n  - Motor BCIs/BMIs using ECoG grids/strips, sEEG/depth iEEG, and/or microelectrode arrays/intracortical recordings.\n  - Studies focused on decoding motor-related variables (movement/kinematics/force/intention) and translating them into BCI outputs, including offline decoding benchmarks and real-time/closed-loop control.\n- Out-of-scope:\n  - Noninvasive BCIs (e.g., scalp EEG, MEG, fNIRS) and non-electrophysiology modalities (e.g., fMRI) even if motor decoding is present.\n  - Invasive electrophysiology papers that are not BCI/neural-interface oriented (e.g., purely clinical mapping, seizure localization) without a BCI/control/decoder framing.\n  - BCIs using invasive signals but targeting non-motor domains (e.g., language/speech, vision) unless motor decoding/control is a central target.", "project_id": "6af7ac1b6254", "run_id": "4dbd2ac34e0f", "step": "parse"}
{"ts": "2026-01-21T17:27:09.999440+00:00", "event": "phase1.parse.response", "project_id": "6af7ac1b6254", "run_id": "4dbd2ac34e0f", "model": "gpt-5.2", "response": "## Conceptual Retrieval Framework\n\n### Block A: Brain–Computer Interface / Neural Interface Framing\n- Concept Role: Ensures the literature is explicitly about translating neural signals into control/communication outputs (BCI/BMI/neural prosthetics), including offline decoding benchmarks and real-time/closed-loop use.\n- Normalized Search Terms:\n  - “brain-computer interface”\n  - BCI\n  - “brain-machine interface”\n  - BMI\n  - “neural interface”\n  - “neural prosthesis” / “neural prosthetic”\n  - “cortical prosthesis” / “cortical prosthetic”\n  - “neuroprosthesis” / “neuroprosthetic”\n  - “direct neural interface”\n  - “closed-loop” (as used in BCI/neural interface contexts)\n  - “real-time” (as used in BCI/neural interface contexts)\n- Notes on Term Usage:\n  - Many relevant papers use BMI rather than BCI, or “neural prosthesis” without the word BCI; keep these equivalent within this block.\n  - “Closed-loop” and “real-time” are not required subtopics, but are common descriptors of BCI operation and help capture control-oriented papers.\n\n### Block B: Invasive Electrophysiology Recording Modality (ECoG / iEEG / sEEG / MEA)\n- Concept Role: Restricts retrieval to invasive electrophysiological signals specifically named in the summary (ECoG grids/strips, stereotactic depth iEEG/sEEG, and microelectrode arrays/intracortical recordings).\n- Normalized Search Terms:\n  - ECoG / electrocorticography / electrocorticogram\n  - “subdural grid” / “subdural grids”\n  - “subdural strip” / “subdural strips”\n  - iEEG / “intracranial EEG” / “intracranial electroencephalography”\n  - “intracranial electrophysiology”\n  - sEEG / SEEG / “stereo-EEG” / “stereoelectroencephalography”\n  - “depth electrode” / “depth electrodes”\n  - “microelectrode array” / MEA\n  - “intracortical recording” / “intracortical recordings”\n  - “single-unit” / “multiunit” / “spike” / “spiking activity” (when used as intracortical/MEA outputs)\n  - “local field potential” / LFP (when used in intracortical/MEA contexts)\n- Notes on Term Usage:\n  - Use both umbrella terms (iEEG, intracranial EEG) and device-specific terms (grid/strip, depth electrode, microelectrode array) because papers vary in how explicitly they name the hardware.\n  - Keep this block strictly invasive electrophysiology; do not substitute noninvasive modalities.\n\n### Block C: Motor Information Decoding / Motor Control Targets\n- Concept Role: Captures the core analytic task: decoding motor-related information from invasive electrophysiology for BCI outputs (movement/kinematics/intention/action-related neural decoding).\n- Normalized Search Terms:\n  - “motor decoding”\n  - “movement decoding”\n  - “motor intention” / “movement intention”\n  - “motor imagery” (when used as a motor-related decoding target)\n  - “motor control”\n  - “movement” / “voluntary movement” (in decoding contexts)\n  - “kinematics” / “trajectory” / “position” / “velocity” / “acceleration” (as decoded variables)\n  - “force” / “grip force” (as decoded variables)\n  - “reach” / “reaching”\n  - “grasp” / “gripping”\n  - “hand” / “arm” / “finger” movement (as decoded effectors)\n  - “cursor control” (as a motor BCI output/control proxy)\n  - “neural decoding” / “decode” / “decoder” (paired with motor terms)\n- Notes on Term Usage:\n  - Motor BCI papers may describe outputs as “cursor control” or “control signals” without naming a specific effector; include these as motor-control proxies but keep the block anchored to motor/movement language.\n  - Avoid adding specific brain regions or populations; the summary sets no constraints there.\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously (1) frame a brain–computer/brain–machine/neural interface, (2) use invasive electrophysiology specifically including ECoG/iEEG/sEEG and/or microelectrode arrays, and (3) decode motor-related information for BCI output/control (offline decoding and/or real-time closed-loop).\n\n## Scope Control\n- In-scope:\n  - Motor BCIs/BMIs using ECoG grids/strips, sEEG/depth iEEG, and/or microelectrode arrays/intracortical recordings.\n  - Studies focused on decoding motor-related variables (movement/kinematics/force/intention) and translating them into BCI outputs, including offline decoding benchmarks and real-time/closed-loop control.\n- Out-of-scope:\n  - Noninvasive BCIs (e.g., scalp EEG, MEG, fNIRS) and non-electrophysiology modalities (e.g., fMRI) even if motor decoding is present.\n  - Invasive electrophysiology papers that are not BCI/neural-interface oriented (e.g., purely clinical mapping, seizure localization) without a BCI/control/decoder framing.\n  - BCIs using invasive signals but targeting non-motor domains (e.g., language/speech, vision) unless motor decoding/control is a central target."}
{"ts": "2026-01-21T17:27:36.279099+00:00", "event": "phase1.query_build.prompt", "project_id": "6af7ac1b6254", "run_id": "4dbd2ac34e0f", "model": "gpt-5.2", "reasoning_effort": "high", "prompt": "You are an expert biomedical information retrieval engineer specializing in PubMed search strategies.\n\nBelow is a Conceptual Retrieval Framework, your task is to convert the framework into one or more executable PubMed search queries.\n\n-- Conceptual Retrieval Framework begin --\n## Conceptual Retrieval Framework\n\n### Block A: Brain–Computer Interface / Neural Interface Framing\n- Concept Role: Ensures the literature is explicitly about translating neural signals into control/communication outputs (BCI/BMI/neural prosthetics), including offline decoding benchmarks and real-time/closed-loop use.\n- Normalized Search Terms:\n  - “brain-computer interface”\n  - BCI\n  - “brain-machine interface”\n  - BMI\n  - “neural interface”\n  - “neural prosthesis” / “neural prosthetic”\n  - “cortical prosthesis” / “cortical prosthetic”\n  - “neuroprosthesis” / “neuroprosthetic”\n  - “direct neural interface”\n  - “closed-loop” (as used in BCI/neural interface contexts)\n  - “real-time” (as used in BCI/neural interface contexts)\n- Notes on Term Usage:\n  - Many relevant papers use BMI rather than BCI, or “neural prosthesis” without the word BCI; keep these equivalent within this block.\n  - “Closed-loop” and “real-time” are not required subtopics, but are common descriptors of BCI operation and help capture control-oriented papers.\n\n### Block B: Invasive Electrophysiology Recording Modality (ECoG / iEEG / sEEG / MEA)\n- Concept Role: Restricts retrieval to invasive electrophysiological signals specifically named in the summary (ECoG grids/strips, stereotactic depth iEEG/sEEG, and microelectrode arrays/intracortical recordings).\n- Normalized Search Terms:\n  - ECoG / electrocorticography / electrocorticogram\n  - “subdural grid” / “subdural grids”\n  - “subdural strip” / “subdural strips”\n  - iEEG / “intracranial EEG” / “intracranial electroencephalography”\n  - “intracranial electrophysiology”\n  - sEEG / SEEG / “stereo-EEG” / “stereoelectroencephalography”\n  - “depth electrode” / “depth electrodes”\n  - “microelectrode array” / MEA\n  - “intracortical recording” / “intracortical recordings”\n  - “single-unit” / “multiunit” / “spike” / “spiking activity” (when used as intracortical/MEA outputs)\n  - “local field potential” / LFP (when used in intracortical/MEA contexts)\n- Notes on Term Usage:\n  - Use both umbrella terms (iEEG, intracranial EEG) and device-specific terms (grid/strip, depth electrode, microelectrode array) because papers vary in how explicitly they name the hardware.\n  - Keep this block strictly invasive electrophysiology; do not substitute noninvasive modalities.\n\n### Block C: Motor Information Decoding / Motor Control Targets\n- Concept Role: Captures the core analytic task: decoding motor-related information from invasive electrophysiology for BCI outputs (movement/kinematics/intention/action-related neural decoding).\n- Normalized Search Terms:\n  - “motor decoding”\n  - “movement decoding”\n  - “motor intention” / “movement intention”\n  - “motor imagery” (when used as a motor-related decoding target)\n  - “motor control”\n  - “movement” / “voluntary movement” (in decoding contexts)\n  - “kinematics” / “trajectory” / “position” / “velocity” / “acceleration” (as decoded variables)\n  - “force” / “grip force” (as decoded variables)\n  - “reach” / “reaching”\n  - “grasp” / “gripping”\n  - “hand” / “arm” / “finger” movement (as decoded effectors)\n  - “cursor control” (as a motor BCI output/control proxy)\n  - “neural decoding” / “decode” / “decoder” (paired with motor terms)\n- Notes on Term Usage:\n  - Motor BCI papers may describe outputs as “cursor control” or “control signals” without naming a specific effector; include these as motor-control proxies but keep the block anchored to motor/movement language.\n  - Avoid adding specific brain regions or populations; the summary sets no constraints there.\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously (1) frame a brain–computer/brain–machine/neural interface, (2) use invasive electrophysiology specifically including ECoG/iEEG/sEEG and/or microelectrode arrays, and (3) decode motor-related information for BCI output/control (offline decoding and/or real-time closed-loop).\n\n## Scope Control\n- In-scope:\n  - Motor BCIs/BMIs using ECoG grids/strips, sEEG/depth iEEG, and/or microelectrode arrays/intracortical recordings.\n  - Studies focused on decoding motor-related variables (movement/kinematics/force/intention) and translating them into BCI outputs, including offline decoding benchmarks and real-time/closed-loop control.\n- Out-of-scope:\n  - Noninvasive BCIs (e.g., scalp EEG, MEG, fNIRS) and non-electrophysiology modalities (e.g., fMRI) even if motor decoding is present.\n  - Invasive electrophysiology papers that are not BCI/neural-interface oriented (e.g., purely clinical mapping, seizure localization) without a BCI/control/decoder framing.\n  - BCIs using invasive signals but targeting non-motor domains (e.g., language/speech, vision) unless motor decoding/control is a central target.\n-- Conceptual Retrieval Framework end --\n\n\nYou must follow these rules strictly:\n\n1. Do NOT reinterpret, merge, or split any concept blocks.\n   - Treat each concept block as an independent retrieval dimension.\n   - Preserve the block structure exactly as given.\n\n2. For each concept block:\n   - Combine all normalized search terms within that block using OR.\n   - Apply PubMed field tags consistently, using Title/Abstract fields\n     unless a term is a standard abbreviation or acronym.\n\n3. Across concept blocks:\n   - Combine blocks using AND.\n   - The final query must require that all blocks are satisfied simultaneously.\n\n4. Do NOT introduce new search terms, synonyms, or expansions.\n   - Use ONLY the terms explicitly listed in the framework.\n\n5. Phrase handling:\n   - Multi-word terms must be enclosed in double quotation marks.\n   - Singular/plural variations should be preserved as given; do not infer new ones.\n\n6. PubMed field usage:\n   - Use [Title/Abstract] for most terms.\n   - Acronyms (e.g., BCI, ECoG, iEEG) may be used without field tags\n     only if they are standard and unambiguous.\n   - Do NOT use MeSH terms in this step.\n\n7. If a block contains usage constraints (e.g., “only when paired with X”),\n   enforce this by block-level AND logic, not by modifying individual terms.\n\n8. Output formatting:\n   - Clearly label each block’s query segment.\n   - Provide the final combined PubMed query in a single code block.\n   - Do NOT include explanatory text outside the required output format.\n\n### Output Format (must follow exactly):\n\n## PubMed Query Blocks\n\n### Block A Query\n(query text)\n\n### Block B Query\n(query text)\n\n(Repeat for each block)\n\n## Final Combined PubMed Query\n```text\n(full PubMed query)\n"}
{"ts": "2026-01-21T17:27:50.057419+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "## PubMed Query Blocks\n\n### Block A Query\n(\"brain-computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR BMI OR \"neural interface\"[Title/Abstract] OR \"neural prosthesis\"[Title/Abstract] OR \"neural prosthetic\"[Title/Abstract] OR \"cortical prosthesis\"[Title/Abstract] OR \"cortical prosthetic\"[Title/Abstract] OR \"neuroprosthesis\"[Title/Abstract] OR \"neuroprosthetic\"[Title/Abstract] OR \"direct neural interface\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"real-time\"[Title/Abstract])\n\n### Block B Query\n(ECoG OR \"electrocorticography\"[Title/Abstract] OR \"electrocorticogram\"[Title/Abstract] OR \"subdural grid\"[Title/Abstract] OR \"subdural grids\"[Title/Abstract] OR \"subdural strip\"[Title/Abstract] OR \"subdural strips\"[Title/Abstract] OR iEEG OR \"intracranial EEG\"[Title/Abstract] OR \"intracranial electroencephalography\"[Title/Abstract] OR \"intracranial electrophysiology\"[Title/Abstract] OR sEEG OR SEEG OR \"stereo-EEG\"[Title/Abstract] OR \"stereoelectroencephalography\"[Title/Abstract] OR \"depth electrode\"[Title/Abstract] OR \"depth electrodes\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"intracortical recording\"[Title/Abstract] OR \"intracortical recordings\"[Title/Abstract] OR \"single-unit\"[Title/Abstract] OR \"multiunit\"[Title/Abstract] OR \"spike\"[Title/Abstract] OR \"spiking activity\"[Title/Abstract] OR \"local field potential\"[Title/Abstract] OR LFP)\n\n### Block C Query\n(\"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"movement intention\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract] OR \"motor control\"[Title/Abstract] OR \"movement\"[Title/Abstract] OR \"voluntary movement\"[Title/Abstract] OR \"kinematics\"[Title/Abstract] OR \"trajectory\"[Title/Abstract] OR \"position\"[Title/Abstract] OR \"velocity\"[Title/Abstract] OR \"acceleration\"[Title/Abstract] OR \"force\"[Title/Abstract] OR \"grip force\"[Title/Abstract] OR \"reach\"[Title/Abstract] OR \"reaching\"[Title/Abstract] OR \"grasp\"[Title/Abstract] OR \"gripping\"[Title/Abstract] OR \"hand\"[Title/Abstract] OR \"arm\"[Title/Abstract] OR \"finger\"[Title/Abstract] OR \"cursor control\"[Title/Abstract] OR \"neural decoding\"[Title/Abstract] OR \"decode\"[Title/Abstract] OR \"decoder\"[Title/Abstract])\n\n## Final Combined PubMed Query\n```text\n((\"brain-computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR BMI OR \"neural interface\"[Title/Abstract] OR \"neural prosthesis\"[Title/Abstract] OR \"neural prosthetic\"[Title/Abstract] OR \"cortical prosthesis\"[Title/Abstract] OR \"cortical prosthetic\"[Title/Abstract] OR \"neuroprosthesis\"[Title/Abstract] OR \"neuroprosthetic\"[Title/Abstract] OR \"direct neural interface\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"real-time\"[Title/Abstract])\nAND\n(ECoG OR \"electrocorticography\"[Title/Abstract] OR \"electrocorticogram\"[Title/Abstract] OR \"subdural grid\"[Title/Abstract] OR \"subdural grids\"[Title/Abstract] OR \"subdural strip\"[Title/Abstract] OR \"subdural strips\"[Title/Abstract] OR iEEG OR \"intracranial EEG\"[Title/Abstract] OR \"intracranial electroencephalography\"[Title/Abstract] OR \"intracranial electrophysiology\"[Title/Abstract] OR sEEG OR SEEG OR \"stereo-EEG\"[Title/Abstract] OR \"stereoelectroencephalography\"[Title/Abstract] OR \"depth electrode\"[Title/Abstract] OR \"depth electrodes\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"intracortical recording\"[Title/Abstract] OR \"intracortical recordings\"[Title/Abstract] OR \"single-unit\"[Title/Abstract] OR \"multiunit\"[Title/Abstract] OR \"spike\"[Title/Abstract] OR \"spiking activity\"[Title/Abstract] OR \"local field potential\"[Title/Abstract] OR LFP)\nAND\n(\"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"movement intention\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract] OR \"motor control\"[Title/Abstract] OR \"movement\"[Title/Abstract] OR \"voluntary movement\"[Title/Abstract] OR \"kinematics\"[Title/Abstract] OR \"trajectory\"[Title/Abstract] OR \"position\"[Title/Abstract] OR \"velocity\"[Title/Abstract] OR \"acceleration\"[Title/Abstract] OR \"force\"[Title/Abstract] OR \"grip force\"[Title/Abstract] OR \"reach\"[Title/Abstract] OR \"reaching\"[Title/Abstract] OR \"grasp\"[Title/Abstract] OR \"gripping\"[Title/Abstract] OR \"hand\"[Title/Abstract] OR \"arm\"[Title/Abstract] OR \"finger\"[Title/Abstract] OR \"cursor control\"[Title/Abstract] OR \"neural decoding\"[Title/Abstract] OR \"decode\"[Title/Abstract] OR \"decoder\"[Title/Abstract]))\n```", "project_id": "6af7ac1b6254", "run_id": "4dbd2ac34e0f", "step": "query_build"}
{"ts": "2026-01-21T17:27:50.058693+00:00", "event": "phase1.query_build.response", "project_id": "6af7ac1b6254", "run_id": "4dbd2ac34e0f", "model": "gpt-5.2", "response": "## PubMed Query Blocks\n\n### Block A Query\n(\"brain-computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR BMI OR \"neural interface\"[Title/Abstract] OR \"neural prosthesis\"[Title/Abstract] OR \"neural prosthetic\"[Title/Abstract] OR \"cortical prosthesis\"[Title/Abstract] OR \"cortical prosthetic\"[Title/Abstract] OR \"neuroprosthesis\"[Title/Abstract] OR \"neuroprosthetic\"[Title/Abstract] OR \"direct neural interface\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"real-time\"[Title/Abstract])\n\n### Block B Query\n(ECoG OR \"electrocorticography\"[Title/Abstract] OR \"electrocorticogram\"[Title/Abstract] OR \"subdural grid\"[Title/Abstract] OR \"subdural grids\"[Title/Abstract] OR \"subdural strip\"[Title/Abstract] OR \"subdural strips\"[Title/Abstract] OR iEEG OR \"intracranial EEG\"[Title/Abstract] OR \"intracranial electroencephalography\"[Title/Abstract] OR \"intracranial electrophysiology\"[Title/Abstract] OR sEEG OR SEEG OR \"stereo-EEG\"[Title/Abstract] OR \"stereoelectroencephalography\"[Title/Abstract] OR \"depth electrode\"[Title/Abstract] OR \"depth electrodes\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"intracortical recording\"[Title/Abstract] OR \"intracortical recordings\"[Title/Abstract] OR \"single-unit\"[Title/Abstract] OR \"multiunit\"[Title/Abstract] OR \"spike\"[Title/Abstract] OR \"spiking activity\"[Title/Abstract] OR \"local field potential\"[Title/Abstract] OR LFP)\n\n### Block C Query\n(\"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"movement intention\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract] OR \"motor control\"[Title/Abstract] OR \"movement\"[Title/Abstract] OR \"voluntary movement\"[Title/Abstract] OR \"kinematics\"[Title/Abstract] OR \"trajectory\"[Title/Abstract] OR \"position\"[Title/Abstract] OR \"velocity\"[Title/Abstract] OR \"acceleration\"[Title/Abstract] OR \"force\"[Title/Abstract] OR \"grip force\"[Title/Abstract] OR \"reach\"[Title/Abstract] OR \"reaching\"[Title/Abstract] OR \"grasp\"[Title/Abstract] OR \"gripping\"[Title/Abstract] OR \"hand\"[Title/Abstract] OR \"arm\"[Title/Abstract] OR \"finger\"[Title/Abstract] OR \"cursor control\"[Title/Abstract] OR \"neural decoding\"[Title/Abstract] OR \"decode\"[Title/Abstract] OR \"decoder\"[Title/Abstract])\n\n## Final Combined PubMed Query\n```text\n((\"brain-computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR BMI OR \"neural interface\"[Title/Abstract] OR \"neural prosthesis\"[Title/Abstract] OR \"neural prosthetic\"[Title/Abstract] OR \"cortical prosthesis\"[Title/Abstract] OR \"cortical prosthetic\"[Title/Abstract] OR \"neuroprosthesis\"[Title/Abstract] OR \"neuroprosthetic\"[Title/Abstract] OR \"direct neural interface\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"real-time\"[Title/Abstract])\nAND\n(ECoG OR \"electrocorticography\"[Title/Abstract] OR \"electrocorticogram\"[Title/Abstract] OR \"subdural grid\"[Title/Abstract] OR \"subdural grids\"[Title/Abstract] OR \"subdural strip\"[Title/Abstract] OR \"subdural strips\"[Title/Abstract] OR iEEG OR \"intracranial EEG\"[Title/Abstract] OR \"intracranial electroencephalography\"[Title/Abstract] OR \"intracranial electrophysiology\"[Title/Abstract] OR sEEG OR SEEG OR \"stereo-EEG\"[Title/Abstract] OR \"stereoelectroencephalography\"[Title/Abstract] OR \"depth electrode\"[Title/Abstract] OR \"depth electrodes\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"intracortical recording\"[Title/Abstract] OR \"intracortical recordings\"[Title/Abstract] OR \"single-unit\"[Title/Abstract] OR \"multiunit\"[Title/Abstract] OR \"spike\"[Title/Abstract] OR \"spiking activity\"[Title/Abstract] OR \"local field potential\"[Title/Abstract] OR LFP)\nAND\n(\"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"movement intention\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract] OR \"motor control\"[Title/Abstract] OR \"movement\"[Title/Abstract] OR \"voluntary movement\"[Title/Abstract] OR \"kinematics\"[Title/Abstract] OR \"trajectory\"[Title/Abstract] OR \"position\"[Title/Abstract] OR \"velocity\"[Title/Abstract] OR \"acceleration\"[Title/Abstract] OR \"force\"[Title/Abstract] OR \"grip force\"[Title/Abstract] OR \"reach\"[Title/Abstract] OR \"reaching\"[Title/Abstract] OR \"grasp\"[Title/Abstract] OR \"gripping\"[Title/Abstract] OR \"hand\"[Title/Abstract] OR \"arm\"[Title/Abstract] OR \"finger\"[Title/Abstract] OR \"cursor control\"[Title/Abstract] OR \"neural decoding\"[Title/Abstract] OR \"decode\"[Title/Abstract] OR \"decoder\"[Title/Abstract]))\n```"}
{"ts": "2026-01-21T17:38:33.984709+00:00", "event": "phase2.affiliation_extraction.prompt", "batch_size": 20, "model": "gpt-5.2", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/affiliation_extraction.md", "full_prompt": "You are a geographic data extractor for academic affiliations.\n\nExtract the following from each affiliation string:\n- country: Full country name (e.g., \"United States\", \"United Kingdom\", \"China\")\n- city: City name (e.g., \"Boston\", \"London\", \"Beijing\")\n- institution: Primary institution name if present (e.g., \"Harvard Medical School\", \"MIT\")\n\n\nRules:\n1. Guess the missing info based on the available info. \n2. Use full country names, not abbreviations (USA → United States)\n3. confidence: \"high\" if all fields clear, \"medium\" if some unclear, \"low\" if very ambiguous\n\nIMPORTANT - Country and City extraction rules:\n- DO NOT extract US state abbreviations (MD, OH, WV, NY, CA, etc.) as cities\n- Only extract actual city names (e.g., \"Boston\", \"Albany\", \"San Francisco\", \"New York\" without state/abbreviations)\n- The guess should be valid and true. For example, \"Massachusetts Institute of Technology, Cambridge, MA 02139\" should be inferred as United States. It would be wrong if it is inferred as 'Cambridge, Morocco', even MA is the country code for Morocco.\n\n\nReturn a JSON array with one object per affiliation in the EXACT same order as input:\n[\n  {\"country\": \"United States\", \"city\": \"Boston\", \"institution\": \"Massachusetts General Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"China\", \"city\": \"Beijing\", \"institution\": null, \"confidence\": \"medium\"},\n  ...\n]\n\nAffiliations to process:\n1. Neuroscience and Neuroengineering Research Lab, Department of Biomedical Engineering, School of Electrical Engineering, Iran University of Science and Technology (IUST), Narmak, 16846-13114, Tehran, Iran.\n2. Neuroscience and Neuroengineering Research Lab, Department of Biomedical Engineering, School of Electrical Engineering, Iran University of Science and Technology (IUST), Narmak, 16846-13114, Tehran, Iran. daliri@iust.ac.ir.\n3. Neuroscience and Neuroengineering Research Lab, Biomedical Engineering Department, School of Electrical Engineering, Iran University of Science & Technology (IUST), Narmak, Tehran, 16846-13114, Iran.\n4. Control Engineering Department, School of Electrical Engineering, Iran University of Science & Technology (IUST), Tehran, Iran.\n5. Neuroscience and Neuroengineering Research Lab, Biomedical Engineering Department, School of Electrical Engineering, Iran University of Science & Technology (IUST), Narmak, Tehran, 16846-13114, Iran. daliri@iust.ac.ir.\n6. Neuroscience and Neuroengineering Research Lab, Biomedical Engineering Department, School of Electrical Engineering, Iran University of Science & Technology (IUST), Narmak, 16846-13114, Tehran, Iran.\n7. Neuroscience and Neuroengineering Research Lab, Biomedical Engineering Department, School of Electrical Engineering, Iran University of Science & Technology (IUST), Narmak, 16846-13114, Tehran, Iran. Electronic address: daliri@iust.ac.ir.\n8. Neuroscience and Neuroengineering Research Lab., Biomedical Engineering Department, School of Electrical Engineering, Iran University of Science and Technology (IUST), Tehran, Iran.\n9. Neuroscience and Neuroengineering Research Lab., Biomedical Engineering Department, School of Electrical Engineering, Iran University of Science and Technology (IUST), Tehran, Iran. daliri@iust.ac.ir.\n10. Department of Physiology, Faculty of Medical Sciences, Tarbiat Modares University, Tehran, Iran. Electronic address: raoufy@modares.ac.ir.\n11. Faculty of Electrical Engineering, K. N. Toosi University of Technology, Tehran, Iran.\n12. QUALIblood S.A., 5000 Namur, Belgium.\n13. 3Medtronic plc, Minneapolis, Minnesota; and.\n14. Department of Oncology, AgeCare, Academy of Geriatric Cancer Research, Odense University Hospital, Denmark.\n15. Neuroscience and Neuroengineering Research Lab, Biomedical Engineering Department, School of Electrical Engineering, Iran University of Science and Technology (IUST), Narmak, Tehran 16846-13114, Iran; Institute for Cognitive Science Studies (ICSS), Tehran, Pardis 16583-44575, Iran.\n16. Neuroscience and Neuroengineering Research Lab, Biomedical Engineering Department, School of Electrical Engineering, Iran University of Science and Technology (IUST), Narmak, Tehran 16846-13114, Iran.\n17. Neuroscience and Neuroengineering Research Lab, Biomedical Engineering Department, School of Electrical Engineering, Iran University of Science and Technology (IUST), Narmak, Tehran 16846-13114, Iran. Electronic address: shalchyan@iust.ac.ir.\n18. 4Department of Neurological Surgery, Henry Ford Medical Center, Detroit, Michigan; and.\n19. Medical student, Faculty of Medicine, Hashemite University, Jordan.\n20. Electrical, Computer and Biomedical Engineering, University of Rhode Island, Rhode Island, USA.\n\n"}
{"ts": "2026-01-21T17:38:39.328719+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "```json\n[\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Tarbiat Modares University\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"K. N. Toosi University of Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Belgium\", \"city\": \"Namur\", \"institution\": \"QUALIblood S.A.\", \"confidence\": \"high\"},\n  {\"country\": \"United States\", \"city\": \"Minneapolis\", \"institution\": \"Medtronic plc\", \"confidence\": \"high\"},\n  {\"country\": \"Denmark\", \"city\": \"Odense\", \"institution\": \"Odense University Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"medium\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"United States\", \"city\": \"Detroit\", \"institution\": \"Henry Ford Medical Center\", \"confidence\": \"high\"},\n  {\"country\": \"Jordan\", \"city\": \"Zarqa\", \"institution\": \"Hashemite University\", \"confidence\": \"medium\"},\n  {\"country\": \"United States\", \"city\": \"Kingston\", \"institution\": \"University of Rhode Island\", \"confidence\": \"medium\"}\n]\n```"}
{"ts": "2026-01-21T17:38:39.329986+00:00", "event": "phase2.affiliation_extraction.response", "batch_size": 20, "model": "gpt-5.2", "raw_json_response": "```json\n[\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Tarbiat Modares University\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"K. N. Toosi University of Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Belgium\", \"city\": \"Namur\", \"institution\": \"QUALIblood S.A.\", \"confidence\": \"high\"},\n  {\"country\": \"United States\", \"city\": \"Minneapolis\", \"institution\": \"Medtronic plc\", \"confidence\": \"high\"},\n  {\"country\": \"Denmark\", \"city\": \"Odense\", \"institution\": \"Odense University Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"medium\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"Iran\", \"city\": \"Tehran\", \"institution\": \"Iran University of Science and Technology\", \"confidence\": \"high\"},\n  {\"country\": \"United States\", \"city\": \"Detroit\", \"institution\": \"Henry Ford Medical Center\", \"confidence\": \"high\"},\n  {\"country\": \"Jordan\", \"city\": \"Zarqa\", \"institution\": \"Hashemite University\", \"confidence\": \"medium\"},\n  {\"country\": \"United States\", \"city\": \"Kingston\", \"institution\": \"University of Rhode Island\", \"confidence\": \"medium\"}\n]\n```"}
{"ts": "2026-01-21T17:38:43.474172+00:00", "event": "phase2.affiliation_extraction.prompt", "batch_size": 1, "model": "gpt-5.2", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/affiliation_extraction.md", "full_prompt": "You are a geographic data extractor for academic affiliations.\n\nExtract the following from each affiliation string:\n- country: Full country name (e.g., \"United States\", \"United Kingdom\", \"China\")\n- city: City name (e.g., \"Boston\", \"London\", \"Beijing\")\n- institution: Primary institution name if present (e.g., \"Harvard Medical School\", \"MIT\")\n\n\nRules:\n1. Guess the missing info based on the available info. \n2. Use full country names, not abbreviations (USA → United States)\n3. confidence: \"high\" if all fields clear, \"medium\" if some unclear, \"low\" if very ambiguous\n\nIMPORTANT - Country and City extraction rules:\n- DO NOT extract US state abbreviations (MD, OH, WV, NY, CA, etc.) as cities\n- Only extract actual city names (e.g., \"Boston\", \"Albany\", \"San Francisco\", \"New York\" without state/abbreviations)\n- The guess should be valid and true. For example, \"Massachusetts Institute of Technology, Cambridge, MA 02139\" should be inferred as United States. It would be wrong if it is inferred as 'Cambridge, Morocco', even MA is the country code for Morocco.\n\n\nReturn a JSON array with one object per affiliation in the EXACT same order as input:\n[\n  {\"country\": \"United States\", \"city\": \"Boston\", \"institution\": \"Massachusetts General Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"China\", \"city\": \"Beijing\", \"institution\": null, \"confidence\": \"medium\"},\n  ...\n]\n\nAffiliations to process:\n1. SK Hynix Inc., Icheon, Kyunggi-do, 17336, Republic of Korea.\n\n"}
{"ts": "2026-01-21T17:38:44.353257+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "[\n  {\n    \"country\": \"South Korea\",\n    \"city\": \"Icheon\",\n    \"institution\": \"SK Hynix Inc.\",\n    \"confidence\": \"high\"\n  }\n]"}
{"ts": "2026-01-21T17:38:44.354520+00:00", "event": "phase2.affiliation_extraction.response", "batch_size": 1, "model": "gpt-5.2", "raw_json_response": "[\n  {\n    \"country\": \"South Korea\",\n    \"city\": \"Icheon\",\n    \"institution\": \"SK Hynix Inc.\",\n    \"confidence\": \"high\"\n  }\n]"}
{"ts": "2026-01-21T17:46:28.918923+00:00", "event": "parse.stage1.prompt", "project_id": "6af7ac1b6254", "run_id": "9aa24ef17317", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage1_understanding.md", "prompt": "你是“研究描述理解与规范化”模块。输入是一段纯文本候选研究描述。你的目标是帮助用户把研究描述变得合理且清晰，便于后续生成文献检索查询。\n\n你必须完成：\n1) 判断这段描述是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true.\n2) 如果是研究描述,进行常识可行性判断（plausibility_level）：\n- A_impossible：明显荒诞/违背当前科技常识（无法形成合理检索任务）\n- B_plausible：合理可行\n3) 如果合理可行，给出你对该研究描述的“当前理解”（normalized_understanding），用规范化、聚焦、可检索的英语重写，\n4) 判断当前理解是否已经清晰到可以用于检索；若不清晰，列出你仍不确定的点（疑问清单），并提出最多3个澄清问题（问题必须具体可回答）。\n5) 输出结构化提要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n6) 只输出JSON，不输出任何额外文本。\n\n候选研究描述：\n\"\"\"I focus on motor brain-computer interface based on the invasive EEG signals.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n}\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - ncertainties/missing_fields/suggested_questions为空数组[];\n  - structured_summary为全null；\n- normalized_understanding：300-600个英文字符，必须是你对研究的“当前理解”，语言规范、聚焦、可检索；不要写“我认为/可能”等口水话，直接用陈述句组织。\n\n- 如果 是B_plausible，且 is_clear_for_search=true，则：\n  - is_research_description = true\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空数组或只保留0-1条轻微风险\n\n- 如果 是B_plausible，且 is_clear_for_search=false，则：\n  - is_research_description = true\n  - uncertainties 至少2条\n  - missing_fields 仅列出缺失项\n  - suggested_questions 为1-3条，必须与 uncertainties/missing_fields 对应\n\n- 如果 plausibility_level=A_impossible，则：\n  - is_clear_for_search=false\n  - suggested_questions 为空\n  - uncertainties <=200英文字符：给出impossible的原因。\n"}
{"ts": "2026-01-21T17:46:42.781108+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces (BCIs) that decode movement intention and control external devices using invasive electrophysiological recordings from the brain (e.g., intracranial EEG/ECoG). The work targets signal processing and machine-learning decoding pipelines for motor tasks, evaluating performance for real-time control, robustness, and user adaptation in human or animal subjects.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces; neuroengineering; neural signal processing\",\n    \"task\": \"Decode motor intention/movement parameters for device control\",\n    \"subject_system\": \"Invasive brain electrophysiology (intracranial EEG/ECoG) from motor-related cortical areas\",\n    \"methods\": \"Feature extraction and signal processing; machine-learning/decoding models; real-time BCI evaluation\",\n    \"scope\": \"Motor BCI using invasive recordings; unspecified subjects, paradigms, and controlled devices\",\n    \"intent\": \"Enable accurate and robust motor control via invasive neural signals\",\n    \"exclusions\": \"Non-invasive EEG-only BCIs; non-motor (e.g., P300/SSVEP) paradigms unless explicitly included\"\n  },\n  \"uncertainties\": [\n    \"The term 'invasive EEG' is ambiguous; it could mean ECoG, SEEG, or other intracranial recordings, which affects search terms.\",\n    \"The specific motor paradigm and output (e.g., cursor control, prosthetic limb, grasp classification, continuous kinematics) are not specified.\",\n    \"Target population and evaluation setting (human clinical implants vs animal models; offline decoding vs closed-loop online control) are unclear.\"\n  ],\n  \"missing_fields\": [\"subject_system\", \"scope\"],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Which invasive signal modality do you mean by 'invasive EEG' (ECoG, SEEG/sEEG, intracortical microelectrode arrays, or other)?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"What motor task/output is the BCI intended to decode and control (discrete movement class, continuous kinematics, cursor/prosthesis control, grasp, gait, etc.)?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Is the focus on offline decoding, real-time closed-loop control, or both, and in which subjects (human patients vs animal models)?\"\n    }\n  ]\n}", "project_id": "6af7ac1b6254", "run_id": "9aa24ef17317", "stage": "stage1"}
{"ts": "2026-01-21T17:46:42.781735+00:00", "event": "parse.stage1.response", "project_id": "6af7ac1b6254", "run_id": "9aa24ef17317", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces (BCIs) that decode movement intention and control external devices using invasive electrophysiological recordings from the brain (e.g., intracranial EEG/ECoG). The work targets signal processing and machine-learning decoding pipelines for motor tasks, evaluating performance for real-time control, robustness, and user adaptation in human or animal subjects.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces; neuroengineering; neural signal processing\",\n    \"task\": \"Decode motor intention/movement parameters for device control\",\n    \"subject_system\": \"Invasive brain electrophysiology (intracranial EEG/ECoG) from motor-related cortical areas\",\n    \"methods\": \"Feature extraction and signal processing; machine-learning/decoding models; real-time BCI evaluation\",\n    \"scope\": \"Motor BCI using invasive recordings; unspecified subjects, paradigms, and controlled devices\",\n    \"intent\": \"Enable accurate and robust motor control via invasive neural signals\",\n    \"exclusions\": \"Non-invasive EEG-only BCIs; non-motor (e.g., P300/SSVEP) paradigms unless explicitly included\"\n  },\n  \"uncertainties\": [\n    \"The term 'invasive EEG' is ambiguous; it could mean ECoG, SEEG, or other intracranial recordings, which affects search terms.\",\n    \"The specific motor paradigm and output (e.g., cursor control, prosthetic limb, grasp classification, continuous kinematics) are not specified.\",\n    \"Target population and evaluation setting (human clinical implants vs animal models; offline decoding vs closed-loop online control) are unclear.\"\n  ],\n  \"missing_fields\": [\"subject_system\", \"scope\"],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Which invasive signal modality do you mean by 'invasive EEG' (ECoG, SEEG/sEEG, intracortical microelectrode arrays, or other)?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"What motor task/output is the BCI intended to decode and control (discrete movement class, continuous kinematics, cursor/prosthesis control, grasp, gait, etc.)?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Is the focus on offline decoding, real-time closed-loop control, or both, and in which subjects (human patients vs animal models)?\"\n    }\n  ]\n}"}
{"ts": "2026-01-21T17:50:07.996454+00:00", "event": "parse.stage2.prompt", "project_id": "6af7ac1b6254", "run_id": "9aa24ef17317", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage2_converge.md", "prompt": "你是“研究描述自我收敛器”。你将收到三段文本：\n(1) 当前候选研究描述 current_description\n(2) 关于当前研究描述的问题question_for_user\n(3) 用户本轮补充信息 user_additional_info（可能回答了你上轮的问题，也可能没有）\n\n你的任务是：\n1) 判断当前候选研究描述和用户本轮补充信息是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true，并将两段文本融合，形成你对研究内容的“当前理解”，并判断更新后的研究内容是否合理：\n- A_impossible：明显荒诞/违背当前科技常识，无法形成合理检索任务\n- B_plausible：合理可行\n2) 如果A_impossible，给出简单的理由。如果新的理解是合理可行的，就用规范、聚焦、可检索的英文重写（300-600英文字符），这段重写用于帮助用户组织语言与规范表述。\n3) 判断本轮补充的信息是否对解答question_for_user有帮助。有帮助的话就返回 is_helpful=true。\n4) 如果在新增信息后仍不清晰：输出你仍不确定的点（uncertainties），并提出最多3个澄清问题（具体可回答，优先信息增益最大）。\n5) 如果已经清晰：不要再提问题；只输出你的理解与结构化摘要。\n6) 输出结构化摘要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n只输出JSON，不输出任何额外文字。\n\ncurrent_description：\n\"\"\"Research on motor brain–computer interfaces (BCIs) that decode movement intention and control external devices using invasive electrophysiological recordings from the brain (e.g., intracranial EEG/ECoG). The work targets signal processing and machine-learning decoding pipelines for motor tasks, evaluating performance for real-time control, robustness, and user adaptation in human or animal subjects.\"\"\"\n\nquestion_for_user：\n\"\"\"Which invasive signal modality do you mean by 'invasive EEG' (ECoG, SEEG/sEEG, intracortical microelectrode arrays, or other)?\nWhat motor task/output is the BCI intended to decode and control (discrete movement class, continuous kinematics, cursor/prosthesis control, grasp, gait, etc.)?\nIs the focus on offline decoding, real-time closed-loop control, or both, and in which subjects (human patients vs animal models)?\"\"\"\n\n\nuser_additional_info（用户本轮补充信息，可能为空）：\n\"\"\"I use ECoG, sEEG, MEA. No restriction on task, output. It could be both offline and real-time control. No restriction on the subjects.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"is_helpful\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n  }\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - 其他所有字段都为空。\n- normalized_understanding：300-600英文字符，必须是你融合两段文本后的“当前理解”，术语一致、范围聚焦。\n- 如果 plausibility_level=B_plausible且is_clear_for_search=true：\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空或最多1条轻微风险\n- 如果 plausibility_level=B_plausible且is_clear_for_search=false：\n  - uncertainties 至少2条\n  - suggested_questions 为1-3条，必须与uncertainties/missing_fields一致\n\n- 如果 plausibility_level=A_impossible：\n  - is_clear_for_search 必须为 false\n  - suggested_questions 必须为空数组\n  - uncertainties <=200英文字符：提示用户impossible的原因。\n"}
{"ts": "2026-01-21T17:50:20.848579+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces that decode movement intention from invasive electrophysiology, specifically ECoG, sEEG, and intracortical microelectrode arrays (MEA). The work develops and evaluates signal-processing and machine-learning decoding pipelines for both offline analysis and real-time closed-loop control of external devices, emphasizing performance, robustness, and user adaptation across human and/or animal subjects.\",\n  \"structured_summary\": {\n    \"domain\": \"Motor brain–computer interfaces (invasive electrophysiology)\",\n    \"task\": \"Decode movement intention and control external devices (offline decoding and real-time closed-loop control)\",\n    \"subject_system\": \"ECoG, sEEG, and intracortical MEA recordings in human and/or animal subjects\",\n    \"methods\": \"Signal processing and machine-learning decoding pipelines; evaluation of robustness and user adaptation\",\n    \"scope\": \"Broad motor tasks/outputs; both offline and online settings; cross-subject generality not specified\",\n    \"intent\": \"Improve decoding performance and practical controllability for motor BCI applications\",\n    \"exclusions\": \"Non-invasive modalities (e.g., scalp EEG/MEG/fNIRS) and non-motor BCI paradigms are not the focus\"\n  },\n  \"uncertainties\": [\n    \"Motor task/output is unconstrained (classification vs continuous kinematics vs cursor/prosthesis), making search terms too broad.\",\n    \"Primary methodological focus is unclear (e.g., deep learning vs state-space models vs feature engineering; adaptation/transfer learning vs robustness to nonstationarity).\",\n    \"Target application and evaluation setting are unspecified (clinical communication, prosthetic control, rehabilitation; benchmark datasets vs custom experiments).\"\n  ],\n  \"missing_fields\": [\n    \"task\",\n    \"methods\",\n    \"scope\",\n    \"intent\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"What specific motor output should the decoder target (e.g., discrete movement classes, continuous hand/arm kinematics, cursor velocity, grasp force), and what device is controlled?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"Which decoding approach is central (e.g., linear/LDA/Kalman, RNN/Transformer, neural state-space models), and are you focusing on adaptation/transfer learning or robustness to nonstationarity?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Do you want to emphasize a particular recording modality comparison (ECoG vs sEEG vs MEA) or a specific evaluation context (intra-session vs across days, within-subject vs cross-subject, clinical vs animal)?\"\n    }\n  ]\n}", "project_id": "6af7ac1b6254", "run_id": "9aa24ef17317", "stage": "stage2"}
{"ts": "2026-01-21T17:50:20.850156+00:00", "event": "parse.stage2.response", "project_id": "6af7ac1b6254", "run_id": "9aa24ef17317", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces that decode movement intention from invasive electrophysiology, specifically ECoG, sEEG, and intracortical microelectrode arrays (MEA). The work develops and evaluates signal-processing and machine-learning decoding pipelines for both offline analysis and real-time closed-loop control of external devices, emphasizing performance, robustness, and user adaptation across human and/or animal subjects.\",\n  \"structured_summary\": {\n    \"domain\": \"Motor brain–computer interfaces (invasive electrophysiology)\",\n    \"task\": \"Decode movement intention and control external devices (offline decoding and real-time closed-loop control)\",\n    \"subject_system\": \"ECoG, sEEG, and intracortical MEA recordings in human and/or animal subjects\",\n    \"methods\": \"Signal processing and machine-learning decoding pipelines; evaluation of robustness and user adaptation\",\n    \"scope\": \"Broad motor tasks/outputs; both offline and online settings; cross-subject generality not specified\",\n    \"intent\": \"Improve decoding performance and practical controllability for motor BCI applications\",\n    \"exclusions\": \"Non-invasive modalities (e.g., scalp EEG/MEG/fNIRS) and non-motor BCI paradigms are not the focus\"\n  },\n  \"uncertainties\": [\n    \"Motor task/output is unconstrained (classification vs continuous kinematics vs cursor/prosthesis), making search terms too broad.\",\n    \"Primary methodological focus is unclear (e.g., deep learning vs state-space models vs feature engineering; adaptation/transfer learning vs robustness to nonstationarity).\",\n    \"Target application and evaluation setting are unspecified (clinical communication, prosthetic control, rehabilitation; benchmark datasets vs custom experiments).\"\n  ],\n  \"missing_fields\": [\n    \"task\",\n    \"methods\",\n    \"scope\",\n    \"intent\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"What specific motor output should the decoder target (e.g., discrete movement classes, continuous hand/arm kinematics, cursor velocity, grasp force), and what device is controlled?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"Which decoding approach is central (e.g., linear/LDA/Kalman, RNN/Transformer, neural state-space models), and are you focusing on adaptation/transfer learning or robustness to nonstationarity?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Do you want to emphasize a particular recording modality comparison (ECoG vs sEEG vs MEA) or a specific evaluation context (intra-session vs across days, within-subject vs cross-subject, clinical vs animal)?\"\n    }\n  ]\n}"}
{"ts": "2026-01-21T17:50:26.190307+00:00", "event": "phase1.parse.prompt", "project_id": "6af7ac1b6254", "run_id": "9aa24ef17317", "model": "gpt-5.2", "reasoning_effort": "high", "prompt": "You are an expert academic search strategist specializing in exhaustive literature retrieval. \n\nBelow is a short research summary, your task is to take above research summary and directly produce a conceptual retrieval framework that can be used to systematically search for all relevant literature in that research field.\n\n-- research summary begin --\nResearch on motor brain–computer interfaces that decode movement intention from invasive electrophysiology, specifically ECoG, sEEG, and intracortical microelectrode arrays (MEA). The work develops and evaluates signal-processing and machine-learning decoding pipelines for both offline analysis and real-time closed-loop control of external devices, emphasizing performance, robustness, and user adaptation across human and/or animal subjects.\n-- research summary end --\n\nThis is NOT a query-generation task.\nThis is a concept-framework construction task.\n\nYou must follow these rules strictly:\n\n1. Base the framework ONLY on the content explicitly stated or clearly implied in the research summary.\n   - Do NOT introduce new research goals, populations, or application domains.\n   - Do NOT speculate beyond the summary.\n\n2. The output must define a SMALL NUMBER of concept blocks (typically 2–4).\n   - Each block represents a distinct and independently searchable conceptual dimension\nthat should not be merged with other dimensions if doing so would reduce recall.\n   - Examples include: research task, technical field/framing, data modality.\n   - All blocks together must uniquely define ONE narrow research field.\n\nIMPORTANT — Concept Block Separation Rule:\n\nWhen constructing concept blocks, prioritize retrieval independence over semantic compactness.\n\nIf two concepts frequently appear separately in relevant literature\n(e.g., one may be mentioned without the other in titles/abstracts),\nthey MUST be placed in separate concept blocks,\neven if they form a well-known combined phrase or subfield name.\n\nExample:\n- “speech” and “brain-computer interface” must be separate blocks,\n  because many relevant papers mention speech decoding without explicitly using “BCI”,\n  and others mention BCI without explicitly using “speech”.\n\n\n3. Each concept block must:\n   - Contain only terms that are conceptually equivalent within that block.\n   - Be expressed using terminology commonly found in academic databases.\n   - Include common synonyms, abbreviations, and canonical terms used in the literature.\n\n4. When the summary uses abstract or high-level language, normalize it into concrete, database-searchable concepts\n   ONLY when such normalization is standard practice in the field.\n   - Example: “invasive recordings” → ECoG, sEEG, intracortical recordings, MEA\n   - Do NOT introduce loosely related or adjacent techniques.\n\n5. All concept blocks must be REQUIRED.\n   - The framework should be designed for exhaustive retrieval within a specific field,\n     not for exploratory or cross-domain search.\n\n6. Do NOT generate executable Boolean queries.\n   - You MAY describe the logical relationship between blocks conceptually\n     (e.g., “documents must address all blocks simultaneously”),\n     but do not use database syntax.\n\n7. Explicitly prevent topic drift.\n   - The framework should clearly exclude adjacent but distinct research areas.\n\n### Output Format (must follow exactly):\n\n## Conceptual Retrieval Framework\n\n### Block A: [Concept Block Name]\n- Concept Role:\n- Normalized Search Terms:\n- Notes on Term Usage:\n\n### Block B: [Concept Block Name]\n- Concept Role:\n- Normalized Search Terms:\n- Notes on Term Usage:\n\n(Repeat blocks as needed)\n\n## Conceptual Combination Rule\nA single sentence explaining how all blocks jointly define the target literature set.\n\n## Scope Control\n- In-scope:\n- Out-of-scope:\n"}
{"ts": "2026-01-21T17:50:44.578833+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "## Conceptual Retrieval Framework\n\n### Block A: Motor brain–computer interface / neural decoding of movement intention\n- Concept Role: Ensures the literature is specifically about decoding intended movement for BCI-style control (not general electrophysiology or non-motor decoding).\n- Normalized Search Terms:\n  - “brain-computer interface” / “brain–computer interface” / BCI\n  - “brain-machine interface” / “brain–machine interface” / BMI\n  - “neural decoding” / “decoder” / “decoding”\n  - “movement intention” / “motor intention” / “intended movement”\n  - “motor decoding” / “movement decoding”\n  - “motor control” (when used in a BCI/decoding context)\n- Notes on Term Usage:\n  - Many relevant papers use “BMI” rather than “BCI,” or describe “neural decoding” without explicitly saying BCI; keep both.\n  - Anchor to *movement intention* / *motor* to avoid drift into cognitive, affective, or sensory decoding BCIs.\n\n### Block B: Invasive electrophysiology recording modality (ECoG, sEEG, intracortical/MEA)\n- Concept Role: Restricts retrieval to invasive neural recording sources explicitly named in the summary.\n- Normalized Search Terms:\n  - ECoG / “electrocorticography” / “electrocorticogram”\n  - sEEG / SEEG / “stereo-EEG” / “stereoelectroencephalography”\n  - “intracortical” / “intracortical recording”\n  - “microelectrode array” / MEA / “Utah array” (as a canonical MEA term)\n  - “intracortical microelectrode” / “intracortical electrodes”\n- Notes on Term Usage:\n  - Keep ECoG and sEEG separate within the same block because papers often mention only one modality.\n  - “Invasive” alone is not sufficiently specific; require explicit modality terms to prevent inclusion of unrelated invasive methods.\n\n### Block C: Decoding pipeline development/evaluation for offline analysis and real-time closed-loop control\n- Concept Role: Captures the methodological focus on signal-processing + machine-learning pipelines and their evaluation in offline and/or online closed-loop settings.\n- Normalized Search Terms:\n  - “signal processing” / “feature extraction” / “spectral features” (as generic pipeline language)\n  - “machine learning” / “classification” / “regression” / “deep learning” (as decoding-method language)\n  - “offline” / “offline analysis” / “offline decoding”\n  - “real-time” / “online” / “closed-loop” / “closed loop”\n  - “decoder performance” / “robustness” / “adaptation” / “user adaptation”\n- Notes on Term Usage:\n  - Some papers emphasize “closed-loop” without saying “real-time,” and others say “online” without “closed-loop”; include all.\n  - “Adaptation” should be interpreted in the BCI/decoder/user sense (not biological adaptation broadly).\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously address (A) motor/movement-intention neural decoding in a BCI/BMI context, (B) using ECoG and/or sEEG and/or intracortical microelectrode arrays, and (C) developing and/or evaluating decoding pipelines in offline and/or real-time closed-loop settings with attention to performance/robustness/adaptation.\n\n## Scope Control\n- In-scope:\n  - Motor BCIs/BMIs decoding intended movement from ECoG, sEEG, or intracortical MEA recordings.\n  - Studies describing signal-processing and machine-learning decoding pipelines, evaluated offline and/or in real-time closed-loop control of external devices.\n  - Human and/or animal subject studies (as applicable to the above).\n- Out-of-scope:\n  - Non-invasive modalities (e.g., scalp EEG, MEG, fNIRS) and non-specified “invasive” work without ECoG/sEEG/intracortical/MEA terms.\n  - BCIs not centered on movement intention (e.g., purely sensory, cognitive, affective, or language decoding) unless explicitly tied to motor intention decoding.\n  - General electrophysiology, neuroscience motor physiology, or device engineering papers that do not include a decoding/BCI pipeline component (offline and/or closed-loop evaluation).", "project_id": "6af7ac1b6254", "run_id": "9aa24ef17317", "step": "parse"}
{"ts": "2026-01-21T17:50:44.580172+00:00", "event": "phase1.parse.response", "project_id": "6af7ac1b6254", "run_id": "9aa24ef17317", "model": "gpt-5.2", "response": "## Conceptual Retrieval Framework\n\n### Block A: Motor brain–computer interface / neural decoding of movement intention\n- Concept Role: Ensures the literature is specifically about decoding intended movement for BCI-style control (not general electrophysiology or non-motor decoding).\n- Normalized Search Terms:\n  - “brain-computer interface” / “brain–computer interface” / BCI\n  - “brain-machine interface” / “brain–machine interface” / BMI\n  - “neural decoding” / “decoder” / “decoding”\n  - “movement intention” / “motor intention” / “intended movement”\n  - “motor decoding” / “movement decoding”\n  - “motor control” (when used in a BCI/decoding context)\n- Notes on Term Usage:\n  - Many relevant papers use “BMI” rather than “BCI,” or describe “neural decoding” without explicitly saying BCI; keep both.\n  - Anchor to *movement intention* / *motor* to avoid drift into cognitive, affective, or sensory decoding BCIs.\n\n### Block B: Invasive electrophysiology recording modality (ECoG, sEEG, intracortical/MEA)\n- Concept Role: Restricts retrieval to invasive neural recording sources explicitly named in the summary.\n- Normalized Search Terms:\n  - ECoG / “electrocorticography” / “electrocorticogram”\n  - sEEG / SEEG / “stereo-EEG” / “stereoelectroencephalography”\n  - “intracortical” / “intracortical recording”\n  - “microelectrode array” / MEA / “Utah array” (as a canonical MEA term)\n  - “intracortical microelectrode” / “intracortical electrodes”\n- Notes on Term Usage:\n  - Keep ECoG and sEEG separate within the same block because papers often mention only one modality.\n  - “Invasive” alone is not sufficiently specific; require explicit modality terms to prevent inclusion of unrelated invasive methods.\n\n### Block C: Decoding pipeline development/evaluation for offline analysis and real-time closed-loop control\n- Concept Role: Captures the methodological focus on signal-processing + machine-learning pipelines and their evaluation in offline and/or online closed-loop settings.\n- Normalized Search Terms:\n  - “signal processing” / “feature extraction” / “spectral features” (as generic pipeline language)\n  - “machine learning” / “classification” / “regression” / “deep learning” (as decoding-method language)\n  - “offline” / “offline analysis” / “offline decoding”\n  - “real-time” / “online” / “closed-loop” / “closed loop”\n  - “decoder performance” / “robustness” / “adaptation” / “user adaptation”\n- Notes on Term Usage:\n  - Some papers emphasize “closed-loop” without saying “real-time,” and others say “online” without “closed-loop”; include all.\n  - “Adaptation” should be interpreted in the BCI/decoder/user sense (not biological adaptation broadly).\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously address (A) motor/movement-intention neural decoding in a BCI/BMI context, (B) using ECoG and/or sEEG and/or intracortical microelectrode arrays, and (C) developing and/or evaluating decoding pipelines in offline and/or real-time closed-loop settings with attention to performance/robustness/adaptation.\n\n## Scope Control\n- In-scope:\n  - Motor BCIs/BMIs decoding intended movement from ECoG, sEEG, or intracortical MEA recordings.\n  - Studies describing signal-processing and machine-learning decoding pipelines, evaluated offline and/or in real-time closed-loop control of external devices.\n  - Human and/or animal subject studies (as applicable to the above).\n- Out-of-scope:\n  - Non-invasive modalities (e.g., scalp EEG, MEG, fNIRS) and non-specified “invasive” work without ECoG/sEEG/intracortical/MEA terms.\n  - BCIs not centered on movement intention (e.g., purely sensory, cognitive, affective, or language decoding) unless explicitly tied to motor intention decoding.\n  - General electrophysiology, neuroscience motor physiology, or device engineering papers that do not include a decoding/BCI pipeline component (offline and/or closed-loop evaluation)."}
{"ts": "2026-01-21T17:51:00.472603+00:00", "event": "phase1.query_build.prompt", "project_id": "6af7ac1b6254", "run_id": "9aa24ef17317", "model": "gpt-5.2", "reasoning_effort": "high", "prompt": "You are an expert biomedical information retrieval engineer specializing in PubMed search strategies.\n\nBelow is a Conceptual Retrieval Framework, your task is to convert the framework into one or more executable PubMed search queries.\n\n-- Conceptual Retrieval Framework begin --\n## Conceptual Retrieval Framework\n\n### Block A: Motor brain–computer interface / neural decoding of movement intention\n- Concept Role: Ensures the literature is specifically about decoding intended movement for BCI-style control (not general electrophysiology or non-motor decoding).\n- Normalized Search Terms:\n  - “brain-computer interface” / “brain–computer interface” / BCI\n  - “brain-machine interface” / “brain–machine interface” / BMI\n  - “neural decoding” / “decoder” / “decoding”\n  - “movement intention” / “motor intention” / “intended movement”\n  - “motor decoding” / “movement decoding”\n  - “motor control” (when used in a BCI/decoding context)\n- Notes on Term Usage:\n  - Many relevant papers use “BMI” rather than “BCI,” or describe “neural decoding” without explicitly saying BCI; keep both.\n  - Anchor to *movement intention* / *motor* to avoid drift into cognitive, affective, or sensory decoding BCIs.\n\n### Block B: Invasive electrophysiology recording modality (ECoG, sEEG, intracortical/MEA)\n- Concept Role: Restricts retrieval to invasive neural recording sources explicitly named in the summary.\n- Normalized Search Terms:\n  - ECoG / “electrocorticography” / “electrocorticogram”\n  - sEEG / SEEG / “stereo-EEG” / “stereoelectroencephalography”\n  - “intracortical” / “intracortical recording”\n  - “microelectrode array” / MEA / “Utah array” (as a canonical MEA term)\n  - “intracortical microelectrode” / “intracortical electrodes”\n- Notes on Term Usage:\n  - Keep ECoG and sEEG separate within the same block because papers often mention only one modality.\n  - “Invasive” alone is not sufficiently specific; require explicit modality terms to prevent inclusion of unrelated invasive methods.\n\n### Block C: Decoding pipeline development/evaluation for offline analysis and real-time closed-loop control\n- Concept Role: Captures the methodological focus on signal-processing + machine-learning pipelines and their evaluation in offline and/or online closed-loop settings.\n- Normalized Search Terms:\n  - “signal processing” / “feature extraction” / “spectral features” (as generic pipeline language)\n  - “machine learning” / “classification” / “regression” / “deep learning” (as decoding-method language)\n  - “offline” / “offline analysis” / “offline decoding”\n  - “real-time” / “online” / “closed-loop” / “closed loop”\n  - “decoder performance” / “robustness” / “adaptation” / “user adaptation”\n- Notes on Term Usage:\n  - Some papers emphasize “closed-loop” without saying “real-time,” and others say “online” without “closed-loop”; include all.\n  - “Adaptation” should be interpreted in the BCI/decoder/user sense (not biological adaptation broadly).\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously address (A) motor/movement-intention neural decoding in a BCI/BMI context, (B) using ECoG and/or sEEG and/or intracortical microelectrode arrays, and (C) developing and/or evaluating decoding pipelines in offline and/or real-time closed-loop settings with attention to performance/robustness/adaptation.\n\n## Scope Control\n- In-scope:\n  - Motor BCIs/BMIs decoding intended movement from ECoG, sEEG, or intracortical MEA recordings.\n  - Studies describing signal-processing and machine-learning decoding pipelines, evaluated offline and/or in real-time closed-loop control of external devices.\n  - Human and/or animal subject studies (as applicable to the above).\n- Out-of-scope:\n  - Non-invasive modalities (e.g., scalp EEG, MEG, fNIRS) and non-specified “invasive” work without ECoG/sEEG/intracortical/MEA terms.\n  - BCIs not centered on movement intention (e.g., purely sensory, cognitive, affective, or language decoding) unless explicitly tied to motor intention decoding.\n  - General electrophysiology, neuroscience motor physiology, or device engineering papers that do not include a decoding/BCI pipeline component (offline and/or closed-loop evaluation).\n-- Conceptual Retrieval Framework end --\n\n\nYou must follow these rules strictly:\n\n1. Do NOT reinterpret, merge, or split any concept blocks.\n   - Treat each concept block as an independent retrieval dimension.\n   - Preserve the block structure exactly as given.\n\n2. For each concept block:\n   - Combine all normalized search terms within that block using OR.\n   - Apply PubMed field tags consistently, using Title/Abstract fields\n     unless a term is a standard abbreviation or acronym.\n\n3. Across concept blocks:\n   - Combine blocks using AND.\n   - The final query must require that all blocks are satisfied simultaneously.\n\n4. Do NOT introduce new search terms, synonyms, or expansions.\n   - Use ONLY the terms explicitly listed in the framework.\n\n5. Phrase handling:\n   - Multi-word terms must be enclosed in double quotation marks.\n   - Singular/plural variations should be preserved as given; do not infer new ones.\n\n6. PubMed field usage:\n   - Use [Title/Abstract] for most terms.\n   - Acronyms (e.g., BCI, ECoG, iEEG) may be used without field tags\n     only if they are standard and unambiguous.\n   - Do NOT use MeSH terms in this step.\n\n7. If a block contains usage constraints (e.g., “only when paired with X”),\n   enforce this by block-level AND logic, not by modifying individual terms.\n\n8. Output formatting:\n   - Clearly label each block’s query segment.\n   - Provide the final combined PubMed query in a single code block.\n   - Do NOT include explanatory text outside the required output format.\n\n### Output Format (must follow exactly):\n\n## PubMed Query Blocks\n\n### Block A Query\n(query text)\n\n### Block B Query\n(query text)\n\n(Repeat for each block)\n\n## Final Combined PubMed Query\n```text\n(full PubMed query)\n"}
{"ts": "2026-01-21T17:51:08.978307+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "## PubMed Query Blocks\n\n### Block A Query\n(\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR \"brain–machine interface\"[Title/Abstract] OR BMI OR \"neural decoding\"[Title/Abstract] OR \"decoder\"[Title/Abstract] OR \"decoding\"[Title/Abstract] OR \"movement intention\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"motor control\"[Title/Abstract])\n\n### Block B Query\n(ECoG OR \"electrocorticography\"[Title/Abstract] OR \"electrocorticogram\"[Title/Abstract] OR sEEG OR SEEG OR \"stereo-EEG\"[Title/Abstract] OR \"stereoelectroencephalography\"[Title/Abstract] OR \"intracortical\"[Title/Abstract] OR \"intracortical recording\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"Utah array\"[Title/Abstract] OR \"intracortical microelectrode\"[Title/Abstract] OR \"intracortical electrodes\"[Title/Abstract])\n\n### Block C Query\n(\"signal processing\"[Title/Abstract] OR \"feature extraction\"[Title/Abstract] OR \"spectral features\"[Title/Abstract] OR \"machine learning\"[Title/Abstract] OR \"classification\"[Title/Abstract] OR \"regression\"[Title/Abstract] OR \"deep learning\"[Title/Abstract] OR \"offline\"[Title/Abstract] OR \"offline analysis\"[Title/Abstract] OR \"offline decoding\"[Title/Abstract] OR \"real-time\"[Title/Abstract] OR \"online\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"closed loop\"[Title/Abstract] OR \"decoder performance\"[Title/Abstract] OR \"robustness\"[Title/Abstract] OR \"adaptation\"[Title/Abstract] OR \"user adaptation\"[Title/Abstract])\n\n## Final Combined PubMed Query\n```text\n((\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR \"brain–machine interface\"[Title/Abstract] OR BMI OR \"neural decoding\"[Title/Abstract] OR \"decoder\"[Title/Abstract] OR \"decoding\"[Title/Abstract] OR \"movement intention\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"motor control\"[Title/Abstract])\nAND\n(ECoG OR \"electrocorticography\"[Title/Abstract] OR \"electrocorticogram\"[Title/Abstract] OR sEEG OR SEEG OR \"stereo-EEG\"[Title/Abstract] OR \"stereoelectroencephalography\"[Title/Abstract] OR \"intracortical\"[Title/Abstract] OR \"intracortical recording\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"Utah array\"[Title/Abstract] OR \"intracortical microelectrode\"[Title/Abstract] OR \"intracortical electrodes\"[Title/Abstract])\nAND\n(\"signal processing\"[Title/Abstract] OR \"feature extraction\"[Title/Abstract] OR \"spectral features\"[Title/Abstract] OR \"machine learning\"[Title/Abstract] OR \"classification\"[Title/Abstract] OR \"regression\"[Title/Abstract] OR \"deep learning\"[Title/Abstract] OR \"offline\"[Title/Abstract] OR \"offline analysis\"[Title/Abstract] OR \"offline decoding\"[Title/Abstract] OR \"real-time\"[Title/Abstract] OR \"online\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"closed loop\"[Title/Abstract] OR \"decoder performance\"[Title/Abstract] OR \"robustness\"[Title/Abstract] OR \"adaptation\"[Title/Abstract] OR \"user adaptation\"[Title/Abstract]))\n```", "project_id": "6af7ac1b6254", "run_id": "9aa24ef17317", "step": "query_build"}
{"ts": "2026-01-21T17:51:08.979327+00:00", "event": "phase1.query_build.response", "project_id": "6af7ac1b6254", "run_id": "9aa24ef17317", "model": "gpt-5.2", "response": "## PubMed Query Blocks\n\n### Block A Query\n(\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR \"brain–machine interface\"[Title/Abstract] OR BMI OR \"neural decoding\"[Title/Abstract] OR \"decoder\"[Title/Abstract] OR \"decoding\"[Title/Abstract] OR \"movement intention\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"motor control\"[Title/Abstract])\n\n### Block B Query\n(ECoG OR \"electrocorticography\"[Title/Abstract] OR \"electrocorticogram\"[Title/Abstract] OR sEEG OR SEEG OR \"stereo-EEG\"[Title/Abstract] OR \"stereoelectroencephalography\"[Title/Abstract] OR \"intracortical\"[Title/Abstract] OR \"intracortical recording\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"Utah array\"[Title/Abstract] OR \"intracortical microelectrode\"[Title/Abstract] OR \"intracortical electrodes\"[Title/Abstract])\n\n### Block C Query\n(\"signal processing\"[Title/Abstract] OR \"feature extraction\"[Title/Abstract] OR \"spectral features\"[Title/Abstract] OR \"machine learning\"[Title/Abstract] OR \"classification\"[Title/Abstract] OR \"regression\"[Title/Abstract] OR \"deep learning\"[Title/Abstract] OR \"offline\"[Title/Abstract] OR \"offline analysis\"[Title/Abstract] OR \"offline decoding\"[Title/Abstract] OR \"real-time\"[Title/Abstract] OR \"online\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"closed loop\"[Title/Abstract] OR \"decoder performance\"[Title/Abstract] OR \"robustness\"[Title/Abstract] OR \"adaptation\"[Title/Abstract] OR \"user adaptation\"[Title/Abstract])\n\n## Final Combined PubMed Query\n```text\n((\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR \"brain–machine interface\"[Title/Abstract] OR BMI OR \"neural decoding\"[Title/Abstract] OR \"decoder\"[Title/Abstract] OR \"decoding\"[Title/Abstract] OR \"movement intention\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"motor control\"[Title/Abstract])\nAND\n(ECoG OR \"electrocorticography\"[Title/Abstract] OR \"electrocorticogram\"[Title/Abstract] OR sEEG OR SEEG OR \"stereo-EEG\"[Title/Abstract] OR \"stereoelectroencephalography\"[Title/Abstract] OR \"intracortical\"[Title/Abstract] OR \"intracortical recording\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA OR \"Utah array\"[Title/Abstract] OR \"intracortical microelectrode\"[Title/Abstract] OR \"intracortical electrodes\"[Title/Abstract])\nAND\n(\"signal processing\"[Title/Abstract] OR \"feature extraction\"[Title/Abstract] OR \"spectral features\"[Title/Abstract] OR \"machine learning\"[Title/Abstract] OR \"classification\"[Title/Abstract] OR \"regression\"[Title/Abstract] OR \"deep learning\"[Title/Abstract] OR \"offline\"[Title/Abstract] OR \"offline analysis\"[Title/Abstract] OR \"offline decoding\"[Title/Abstract] OR \"real-time\"[Title/Abstract] OR \"online\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"closed loop\"[Title/Abstract] OR \"decoder performance\"[Title/Abstract] OR \"robustness\"[Title/Abstract] OR \"adaptation\"[Title/Abstract] OR \"user adaptation\"[Title/Abstract]))\n```"}
{"ts": "2026-01-21T17:55:55.694762+00:00", "event": "phase2.affiliation_extraction.prompt", "batch_size": 8, "model": "gpt-5.2", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/affiliation_extraction.md", "full_prompt": "You are a geographic data extractor for academic affiliations.\n\nExtract the following from each affiliation string:\n- country: Full country name (e.g., \"United States\", \"United Kingdom\", \"China\")\n- city: City name (e.g., \"Boston\", \"London\", \"Beijing\")\n- institution: Primary institution name if present (e.g., \"Harvard Medical School\", \"MIT\")\n\n\nRules:\n1. Guess the missing info based on the available info. \n2. Use full country names, not abbreviations (USA → United States)\n3. confidence: \"high\" if all fields clear, \"medium\" if some unclear, \"low\" if very ambiguous\n\nIMPORTANT - Country and City extraction rules:\n- DO NOT extract US state abbreviations (MD, OH, WV, NY, CA, etc.) as cities\n- Only extract actual city names (e.g., \"Boston\", \"Albany\", \"San Francisco\", \"New York\" without state/abbreviations)\n- The guess should be valid and true. For example, \"Massachusetts Institute of Technology, Cambridge, MA 02139\" should be inferred as United States. It would be wrong if it is inferred as 'Cambridge, Morocco', even MA is the country code for Morocco.\n\n\nReturn a JSON array with one object per affiliation in the EXACT same order as input:\n[\n  {\"country\": \"United States\", \"city\": \"Boston\", \"institution\": \"Massachusetts General Hospital\", \"confidence\": \"high\"},\n  {\"country\": \"China\", \"city\": \"Beijing\", \"institution\": null, \"confidence\": \"medium\"},\n  ...\n]\n\nAffiliations to process:\n1. FPGA Laboratory, Faculty of Electrical Engineering, K.N. Toosi University of Technology, Tehran, Iran.\n2. FPGA Laboratory, Faculty of Electrical Engineering, K.N. Toosi University of Technology, Tehran, Iran. hosseini_nezhad@kntu.ac.ir.\n3. Neurological Surgery, University of Washington; and.\n4. University Claude Bernard Lyon 1, Inter-University Laboratory of Human Movement Biology, 27-29 Boulevard du 11 Novembre 1918, F-69622, Villeurbanne cedex, France.\n5. Neuroscience and Neuroengineering Research Lab., Biomedical Engineering Department, School of Electrical Engineering, Iran University of Science & Technology (IUST), Narmak, 16846-13114 Tehran, Iran. E-mail: daliri@iust.ac.ir.\n6. Faculty of Electrical Engineering, Automatic Control and Informatics, Opole University of Technology, 45-758 Opole, Poland.\n7. Laboratory for Soft Bioelectronic Interfaces, Neuro-X Institute, ‌Ecole Polytechnique Fédérale de Lausanne (EPFL), 1202 Geneva, Switzerland.\n8. Radiation Catheterization Room of Ningxia Medical University General Hospital, Yinchuan, Ningxiax, China.\n\n"}
{"ts": "2026-01-21T17:55:59.861176+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "```json\n[\n  {\n    \"country\": \"Iran\",\n    \"city\": \"Tehran\",\n    \"institution\": \"K.N. Toosi University of Technology\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"Iran\",\n    \"city\": \"Tehran\",\n    \"institution\": \"K.N. Toosi University of Technology\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"United States\",\n    \"city\": \"Seattle\",\n    \"institution\": \"University of Washington\",\n    \"confidence\": \"medium\"\n  },\n  {\n    \"country\": \"France\",\n    \"city\": \"Villeurbanne\",\n    \"institution\": \"University Claude Bernard Lyon 1\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"Iran\",\n    \"city\": \"Tehran\",\n    \"institution\": \"Iran University of Science & Technology\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"Poland\",\n    \"city\": \"Opole\",\n    \"institution\": \"Opole University of Technology\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"Switzerland\",\n    \"city\": \"Geneva\",\n    \"institution\": \"Ecole Polytechnique Fédérale de Lausanne (EPFL)\",\n    \"confidence\": \"medium\"\n  },\n  {\n    \"country\": \"China\",\n    \"city\": \"Yinchuan\",\n    \"institution\": \"Ningxia Medical University General Hospital\",\n    \"confidence\": \"high\"\n  }\n]\n```"}
{"ts": "2026-01-21T17:55:59.862433+00:00", "event": "phase2.affiliation_extraction.response", "batch_size": 8, "model": "gpt-5.2", "raw_json_response": "```json\n[\n  {\n    \"country\": \"Iran\",\n    \"city\": \"Tehran\",\n    \"institution\": \"K.N. Toosi University of Technology\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"Iran\",\n    \"city\": \"Tehran\",\n    \"institution\": \"K.N. Toosi University of Technology\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"United States\",\n    \"city\": \"Seattle\",\n    \"institution\": \"University of Washington\",\n    \"confidence\": \"medium\"\n  },\n  {\n    \"country\": \"France\",\n    \"city\": \"Villeurbanne\",\n    \"institution\": \"University Claude Bernard Lyon 1\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"Iran\",\n    \"city\": \"Tehran\",\n    \"institution\": \"Iran University of Science & Technology\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"Poland\",\n    \"city\": \"Opole\",\n    \"institution\": \"Opole University of Technology\",\n    \"confidence\": \"high\"\n  },\n  {\n    \"country\": \"Switzerland\",\n    \"city\": \"Geneva\",\n    \"institution\": \"Ecole Polytechnique Fédérale de Lausanne (EPFL)\",\n    \"confidence\": \"medium\"\n  },\n  {\n    \"country\": \"China\",\n    \"city\": \"Yinchuan\",\n    \"institution\": \"Ningxia Medical University General Hospital\",\n    \"confidence\": \"high\"\n  }\n]\n```"}
{"ts": "2026-01-21T17:59:41.371658+00:00", "event": "parse.stage1.prompt", "project_id": "6af7ac1b6254", "run_id": "5e3c4ea76491", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage1_understanding.md", "prompt": "你是“研究描述理解与规范化”模块。输入是一段纯文本候选研究描述。你的目标是帮助用户把研究描述变得合理且清晰，便于后续生成文献检索查询。\n\n你必须完成：\n1) 判断这段描述是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true.\n2) 如果是研究描述,进行常识可行性判断（plausibility_level）：\n- A_impossible：明显荒诞/违背当前科技常识（无法形成合理检索任务）\n- B_plausible：合理可行\n3) 如果合理可行，给出你对该研究描述的“当前理解”（normalized_understanding），用规范化、聚焦、可检索的英语重写，\n4) 判断当前理解是否已经清晰到可以用于检索；若不清晰，列出你仍不确定的点（疑问清单），并提出最多3个澄清问题（问题必须具体可回答）。\n5) 输出结构化提要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n6) 只输出JSON，不输出任何额外文本。\n\n候选研究描述：\n\"\"\"I focus on motor brain-computer interface based on the invasive EEG signals.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n}\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - ncertainties/missing_fields/suggested_questions为空数组[];\n  - structured_summary为全null；\n- normalized_understanding：300-600个英文字符，必须是你对研究的“当前理解”，语言规范、聚焦、可检索；不要写“我认为/可能”等口水话，直接用陈述句组织。\n\n- 如果 是B_plausible，且 is_clear_for_search=true，则：\n  - is_research_description = true\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空数组或只保留0-1条轻微风险\n\n- 如果 是B_plausible，且 is_clear_for_search=false，则：\n  - is_research_description = true\n  - uncertainties 至少2条\n  - missing_fields 仅列出缺失项\n  - suggested_questions 为1-3条，必须与 uncertainties/missing_fields 对应\n\n- 如果 plausibility_level=A_impossible，则：\n  - is_clear_for_search=false\n  - suggested_questions 为空\n  - uncertainties <=200英文字符：给出impossible的原因。\n"}
{"ts": "2026-01-21T17:59:53.056965+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces (BCIs) that decode movement intention or motor imagery from invasively recorded electrophysiological brain signals (e.g., intracranial EEG/ECoG) to control external devices such as cursors, robotic limbs, or functional electrical stimulation. Emphasis includes signal acquisition, preprocessing, feature extraction, decoding algorithms, and real-time closed-loop performance evaluation in human or animal subjects.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces; neuroengineering; neural signal processing\",\n    \"task\": \"Decode motor intention/motor imagery and translate it into control commands for external devices\",\n    \"subject_system\": \"Invasive electrophysiological recordings (intracranial EEG / ECoG) from motor-related cortex in humans or animals\",\n    \"methods\": \"Neural signal preprocessing, feature extraction, machine learning/decoding models, real-time closed-loop BCI evaluation\",\n    \"scope\": \"Motor BCI using invasive recordings; online or offline decoding; device control applications\",\n    \"intent\": \"Improve accuracy, robustness, and usability of motor BCIs based on invasive brain signals\",\n    \"exclusions\": \"Non-motor BCIs; non-invasive EEG-only studies unless explicitly included; purely clinical implantation studies without decoding\"\n  },\n  \"uncertainties\": [\n    \"The phrase 'invasive EEG' is ambiguous: it could mean intracranial EEG (iEEG) or ECoG, which affects search terms and inclusion criteria.\",\n    \"The specific motor task and output modality are unspecified (e.g., cursor control, robotic arm, FES, speech-related motor control), limiting query focus.\",\n    \"Target population and evaluation setting are unclear (human clinical participants vs animal models; online closed-loop vs offline decoding).\"\n  ],\n  \"missing_fields\": [\"subject_system\", \"scope\", \"exclusions\"],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Do you mean intracranial EEG (stereo-EEG/depth electrodes) or electrocorticography (ECoG) when you say 'invasive EEG'?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which motor BCI application is the focus: cursor/typing, robotic limb control, functional electrical stimulation for movement restoration, or another output?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Are you interested in online closed-loop BCI control studies, offline decoding benchmarks, or both, and in humans, animals, or both?\"\n    }\n  ]\n}", "project_id": "6af7ac1b6254", "run_id": "5e3c4ea76491", "stage": "stage1"}
{"ts": "2026-01-21T17:59:53.057599+00:00", "event": "parse.stage1.response", "project_id": "6af7ac1b6254", "run_id": "5e3c4ea76491", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces (BCIs) that decode movement intention or motor imagery from invasively recorded electrophysiological brain signals (e.g., intracranial EEG/ECoG) to control external devices such as cursors, robotic limbs, or functional electrical stimulation. Emphasis includes signal acquisition, preprocessing, feature extraction, decoding algorithms, and real-time closed-loop performance evaluation in human or animal subjects.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces; neuroengineering; neural signal processing\",\n    \"task\": \"Decode motor intention/motor imagery and translate it into control commands for external devices\",\n    \"subject_system\": \"Invasive electrophysiological recordings (intracranial EEG / ECoG) from motor-related cortex in humans or animals\",\n    \"methods\": \"Neural signal preprocessing, feature extraction, machine learning/decoding models, real-time closed-loop BCI evaluation\",\n    \"scope\": \"Motor BCI using invasive recordings; online or offline decoding; device control applications\",\n    \"intent\": \"Improve accuracy, robustness, and usability of motor BCIs based on invasive brain signals\",\n    \"exclusions\": \"Non-motor BCIs; non-invasive EEG-only studies unless explicitly included; purely clinical implantation studies without decoding\"\n  },\n  \"uncertainties\": [\n    \"The phrase 'invasive EEG' is ambiguous: it could mean intracranial EEG (iEEG) or ECoG, which affects search terms and inclusion criteria.\",\n    \"The specific motor task and output modality are unspecified (e.g., cursor control, robotic arm, FES, speech-related motor control), limiting query focus.\",\n    \"Target population and evaluation setting are unclear (human clinical participants vs animal models; online closed-loop vs offline decoding).\"\n  ],\n  \"missing_fields\": [\"subject_system\", \"scope\", \"exclusions\"],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Do you mean intracranial EEG (stereo-EEG/depth electrodes) or electrocorticography (ECoG) when you say 'invasive EEG'?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which motor BCI application is the focus: cursor/typing, robotic limb control, functional electrical stimulation for movement restoration, or another output?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Are you interested in online closed-loop BCI control studies, offline decoding benchmarks, or both, and in humans, animals, or both?\"\n    }\n  ]\n}"}
{"ts": "2026-01-21T18:01:09.284370+00:00", "event": "parse.stage2.prompt", "project_id": "6af7ac1b6254", "run_id": "5e3c4ea76491", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage2_converge.md", "prompt": "你是“研究描述自我收敛器”。你将收到三段文本：\n(1) 当前候选研究描述 current_description\n(2) 关于当前研究描述的问题question_for_user\n(3) 用户本轮补充信息 user_additional_info（可能回答了你上轮的问题，也可能没有）\n\n你的任务是：\n1) 判断当前候选研究描述和用户本轮补充信息是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true，并将两段文本融合，形成你对研究内容的“当前理解”，并判断更新后的研究内容是否合理：\n- A_impossible：明显荒诞/违背当前科技常识，无法形成合理检索任务\n- B_plausible：合理可行\n2) 如果A_impossible，给出简单的理由。如果新的理解是合理可行的，就用规范、聚焦、可检索的英文重写（300-600英文字符），这段重写用于帮助用户组织语言与规范表述。\n3) 判断本轮补充的信息是否对解答question_for_user有帮助。有帮助的话就返回 is_helpful=true。\n4) 如果在新增信息后仍不清晰：输出你仍不确定的点（uncertainties），并提出最多3个澄清问题（具体可回答，优先信息增益最大）。\n5) 如果已经清晰：不要再提问题；只输出你的理解与结构化摘要。\n6) 输出结构化摘要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n只输出JSON，不输出任何额外文字。\n\ncurrent_description：\n\"\"\"Research on motor brain–computer interfaces (BCIs) that decode movement intention or motor imagery from invasively recorded electrophysiological brain signals (e.g., intracranial EEG/ECoG) to control external devices such as cursors, robotic limbs, or functional electrical stimulation. Emphasis includes signal acquisition, preprocessing, feature extraction, decoding algorithms, and real-time closed-loop performance evaluation in human or animal subjects.\"\"\"\n\nquestion_for_user：\n\"\"\"Do you mean intracranial EEG (stereo-EEG/depth electrodes) or electrocorticography (ECoG) when you say 'invasive EEG'?\nWhich motor BCI application is the focus: cursor/typing, robotic limb control, functional electrical stimulation for movement restoration, or another output?\nAre you interested in online closed-loop BCI control studies, offline decoding benchmarks, or both, and in humans, animals, or both?\"\"\"\n\n\nuser_additional_info（用户本轮补充信息，可能为空）：\n\"\"\"I mean ECoG, sEEG, and MEA. There is no restriction on the application, as long as it is about motor. I am interested in both online and offline, human and animal.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"is_helpful\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n  }\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - 其他所有字段都为空。\n- normalized_understanding：300-600英文字符，必须是你融合两段文本后的“当前理解”，术语一致、范围聚焦。\n- 如果 plausibility_level=B_plausible且is_clear_for_search=true：\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空或最多1条轻微风险\n- 如果 plausibility_level=B_plausible且is_clear_for_search=false：\n  - uncertainties 至少2条\n  - suggested_questions 为1-3条，必须与uncertainties/missing_fields一致\n\n- 如果 plausibility_level=A_impossible：\n  - is_clear_for_search 必须为 false\n  - suggested_questions 必须为空数组\n  - uncertainties <=200英文字符：提示用户impossible的原因。\n"}
{"ts": "2026-01-21T18:01:17.974601+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": true,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces that decode movement intention or motor imagery from invasive electrophysiology, specifically ECoG, stereo-EEG (sEEG), and microelectrode arrays (MEA). The goal is to translate neural activity into control signals for motor-related outputs (e.g., cursor/typing, robotic limbs, or functional electrical stimulation), covering the full pipeline from acquisition and preprocessing to feature extraction, decoding models, and evaluation in both offline benchmarks and real-time closed-loop settings, in human and animal studies.\",\n  \"structured_summary\": {\n    \"domain\": \"Motor brain–computer interfaces (invasive neural decoding)\",\n    \"task\": \"Decode movement intention/motor imagery from invasive brain signals to control external effectors; evaluate offline and closed-loop performance\",\n    \"subject_system\": \"Humans and animals with implanted ECoG grids/strips, sEEG depth electrodes, or MEA recordings\",\n    \"methods\": \"Signal acquisition and preprocessing; feature extraction (time/frequency, spatial patterns); machine learning/deep learning decoders; real-time closed-loop control and offline decoding benchmarks\",\n    \"scope\": \"Motor-related applications without restriction (cursor/typing, robotic limb control, FES, etc.); invasive modalities limited to ECoG, sEEG, MEA\",\n    \"intent\": \"Develop and assess decoding algorithms and systems for reliable motor BCI control across modalities and study types\",\n    \"exclusions\": \"Non-motor BCIs; non-invasive-only modalities (e.g., scalp EEG/MEG) unless used as comparison; purely theoretical work without decoding/evaluation\"\n  },\n  \"uncertainties\": [\n    \"Specific motor paradigm and target metrics (e.g., classification accuracy vs. continuous kinematics, bitrate, time-to-target) are not specified.\"\n  ],\n  \"missing_fields\": [],\n  \"suggested_questions\": []\n}", "project_id": "6af7ac1b6254", "run_id": "5e3c4ea76491", "stage": "stage2"}
{"ts": "2026-01-21T18:01:17.975319+00:00", "event": "parse.stage2.response", "project_id": "6af7ac1b6254", "run_id": "5e3c4ea76491", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": true,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces that decode movement intention or motor imagery from invasive electrophysiology, specifically ECoG, stereo-EEG (sEEG), and microelectrode arrays (MEA). The goal is to translate neural activity into control signals for motor-related outputs (e.g., cursor/typing, robotic limbs, or functional electrical stimulation), covering the full pipeline from acquisition and preprocessing to feature extraction, decoding models, and evaluation in both offline benchmarks and real-time closed-loop settings, in human and animal studies.\",\n  \"structured_summary\": {\n    \"domain\": \"Motor brain–computer interfaces (invasive neural decoding)\",\n    \"task\": \"Decode movement intention/motor imagery from invasive brain signals to control external effectors; evaluate offline and closed-loop performance\",\n    \"subject_system\": \"Humans and animals with implanted ECoG grids/strips, sEEG depth electrodes, or MEA recordings\",\n    \"methods\": \"Signal acquisition and preprocessing; feature extraction (time/frequency, spatial patterns); machine learning/deep learning decoders; real-time closed-loop control and offline decoding benchmarks\",\n    \"scope\": \"Motor-related applications without restriction (cursor/typing, robotic limb control, FES, etc.); invasive modalities limited to ECoG, sEEG, MEA\",\n    \"intent\": \"Develop and assess decoding algorithms and systems for reliable motor BCI control across modalities and study types\",\n    \"exclusions\": \"Non-motor BCIs; non-invasive-only modalities (e.g., scalp EEG/MEG) unless used as comparison; purely theoretical work without decoding/evaluation\"\n  },\n  \"uncertainties\": [\n    \"Specific motor paradigm and target metrics (e.g., classification accuracy vs. continuous kinematics, bitrate, time-to-target) are not specified.\"\n  ],\n  \"missing_fields\": [],\n  \"suggested_questions\": []\n}"}
{"ts": "2026-01-21T18:10:57.998424+00:00", "event": "parse.stage1.prompt", "project_id": "6af7ac1b6254", "run_id": "a494c4a00bf1", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage1_understanding.md", "prompt": "你是“研究描述理解与规范化”模块。输入是一段纯文本候选研究描述。你的目标是帮助用户把研究描述变得合理且清晰，便于后续生成文献检索查询。\n\n你必须完成：\n1) 判断这段描述是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true.\n2) 如果是研究描述,进行常识可行性判断（plausibility_level）：\n- A_impossible：明显荒诞/违背当前科技常识（无法形成合理检索任务）\n- B_plausible：合理可行\n3) 如果合理可行，给出你对该研究描述的“当前理解”（normalized_understanding），用规范化、聚焦、可检索的英语重写，\n4) 判断当前理解是否已经清晰到可以用于检索；若不清晰，列出你仍不确定的点（疑问清单），并提出最多3个澄清问题（问题必须具体可回答）。\n5) 输出结构化提要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n6) 只输出JSON，不输出任何额外文本。\n\n候选研究描述：\n\"\"\"I focus on motor Brain-computer interface based on the invasive EEG signals.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n}\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - ncertainties/missing_fields/suggested_questions为空数组[];\n  - structured_summary为全null；\n- normalized_understanding：300-600个英文字符，必须是你对研究的“当前理解”，语言规范、聚焦、可检索；不要写“我认为/可能”等口水话，直接用陈述句组织。\n\n- 如果 是B_plausible，且 is_clear_for_search=true，则：\n  - is_research_description = true\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空数组或只保留0-1条轻微风险\n\n- 如果 是B_plausible，且 is_clear_for_search=false，则：\n  - is_research_description = true\n  - uncertainties 至少2条\n  - missing_fields 仅列出缺失项\n  - suggested_questions 为1-3条，必须与 uncertainties/missing_fields 对应\n\n- 如果 plausibility_level=A_impossible，则：\n  - is_clear_for_search=false\n  - suggested_questions 为空\n  - uncertainties <=200英文字符：给出impossible的原因。\n"}
{"ts": "2026-01-21T18:11:09.246851+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces (BCIs) that decode movement intention or motor imagery from invasive electrophysiological recordings (intracranial EEG/ECoG). The work targets signal processing and machine-learning decoding pipelines for translating neural activity into control commands for external devices or neuroprostheses, emphasizing invasive EEG feature extraction, classification/regression, and real-time performance evaluation.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces; neural engineering; neuroprosthetics\",\n    \"task\": \"Decode motor intention/motor imagery and generate control commands\",\n    \"subject_system\": \"Human or animal motor cortex recordings using invasive EEG (intracranial EEG/ECoG)\",\n    \"methods\": \"Signal preprocessing, feature extraction (time–frequency, band power), machine learning/deep learning decoding, real-time BCI evaluation\",\n    \"scope\": \"Motor BCI using invasive electrophysiology; online or offline decoding; specific paradigms and devices not specified\",\n    \"intent\": \"Improve accuracy, robustness, and usability of motor BCIs based on invasive EEG signals\",\n    \"exclusions\": \"Non-motor BCIs; non-invasive EEG-only studies unless used for comparison\"\n  },\n  \"uncertainties\": [\n    \"The term 'invasive EEG' is ambiguous (intracranial EEG vs ECoG vs depth electrodes) and affects search keywords.\",\n    \"The motor paradigm is unspecified (motor imagery, attempted movement, executed movement; upper limb vs gait).\",\n    \"Target application and evaluation setting are unclear (online closed-loop control vs offline decoding; prosthetic, cursor, FES).\"\n  ],\n  \"missing_fields\": [],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Which invasive recording modality do you mean: ECoG, stereotactic EEG (sEEG), or other intracranial EEG, and in humans or animals?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"What motor task/paradigm is the focus (motor imagery, attempted movement, executed movement; which body part)?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"Is the goal offline decoding accuracy, or online/closed-loop BCI control (e.g., cursor, robotic arm, neuroprosthesis), and what performance metrics matter most?\"\n    }\n  ]\n}", "project_id": "6af7ac1b6254", "run_id": "a494c4a00bf1", "stage": "stage1"}
{"ts": "2026-01-21T18:11:09.248007+00:00", "event": "parse.stage1.response", "project_id": "6af7ac1b6254", "run_id": "a494c4a00bf1", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces (BCIs) that decode movement intention or motor imagery from invasive electrophysiological recordings (intracranial EEG/ECoG). The work targets signal processing and machine-learning decoding pipelines for translating neural activity into control commands for external devices or neuroprostheses, emphasizing invasive EEG feature extraction, classification/regression, and real-time performance evaluation.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces; neural engineering; neuroprosthetics\",\n    \"task\": \"Decode motor intention/motor imagery and generate control commands\",\n    \"subject_system\": \"Human or animal motor cortex recordings using invasive EEG (intracranial EEG/ECoG)\",\n    \"methods\": \"Signal preprocessing, feature extraction (time–frequency, band power), machine learning/deep learning decoding, real-time BCI evaluation\",\n    \"scope\": \"Motor BCI using invasive electrophysiology; online or offline decoding; specific paradigms and devices not specified\",\n    \"intent\": \"Improve accuracy, robustness, and usability of motor BCIs based on invasive EEG signals\",\n    \"exclusions\": \"Non-motor BCIs; non-invasive EEG-only studies unless used for comparison\"\n  },\n  \"uncertainties\": [\n    \"The term 'invasive EEG' is ambiguous (intracranial EEG vs ECoG vs depth electrodes) and affects search keywords.\",\n    \"The motor paradigm is unspecified (motor imagery, attempted movement, executed movement; upper limb vs gait).\",\n    \"Target application and evaluation setting are unclear (online closed-loop control vs offline decoding; prosthetic, cursor, FES).\"\n  ],\n  \"missing_fields\": [],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Which invasive recording modality do you mean: ECoG, stereotactic EEG (sEEG), or other intracranial EEG, and in humans or animals?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"What motor task/paradigm is the focus (motor imagery, attempted movement, executed movement; which body part)?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"Is the goal offline decoding accuracy, or online/closed-loop BCI control (e.g., cursor, robotic arm, neuroprosthesis), and what performance metrics matter most?\"\n    }\n  ]\n}"}
{"ts": "2026-01-21T18:13:37.214220+00:00", "event": "parse.stage2.prompt", "project_id": "6af7ac1b6254", "run_id": "a494c4a00bf1", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage2_converge.md", "prompt": "你是“研究描述自我收敛器”。你将收到三段文本：\n(1) 当前候选研究描述 current_description\n(2) 关于当前研究描述的问题question_for_user\n(3) 用户本轮补充信息 user_additional_info（可能回答了你上轮的问题，也可能没有）\n\n你的任务是：\n1) 判断当前候选研究描述和用户本轮补充信息是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true，并将两段文本融合，形成你对研究内容的“当前理解”，并判断更新后的研究内容是否合理：\n- A_impossible：明显荒诞/违背当前科技常识，无法形成合理检索任务\n- B_plausible：合理可行\n2) 如果A_impossible，给出简单的理由。如果新的理解是合理可行的，就用规范、聚焦、可检索的英文重写（300-600英文字符），这段重写用于帮助用户组织语言与规范表述。\n3) 判断本轮补充的信息是否对解答question_for_user有帮助。有帮助的话就返回 is_helpful=true。\n4) 如果在新增信息后仍不清晰：输出你仍不确定的点（uncertainties），并提出最多3个澄清问题（具体可回答，优先信息增益最大）。\n5) 如果已经清晰：不要再提问题；只输出你的理解与结构化摘要。\n6) 输出结构化摘要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n只输出JSON，不输出任何额外文字。\n\ncurrent_description：\n\"\"\"Research on motor brain–computer interfaces (BCIs) that decode movement intention or motor imagery from invasive electrophysiological recordings (intracranial EEG/ECoG). The work targets signal processing and machine-learning decoding pipelines for translating neural activity into control commands for external devices or neuroprostheses, emphasizing invasive EEG feature extraction, classification/regression, and real-time performance evaluation.\"\"\"\n\nquestion_for_user：\n\"\"\"Which invasive recording modality do you mean: ECoG, stereotactic EEG (sEEG), or other intracranial EEG, and in humans or animals?\nWhat motor task/paradigm is the focus (motor imagery, attempted movement, executed movement; which body part)?\nIs the goal offline decoding accuracy, or online/closed-loop BCI control (e.g., cursor, robotic arm, neuroprosthesis), and what performance metrics matter most?\"\"\"\n\n\nuser_additional_info（用户本轮补充信息，可能为空）：\n\"\"\"I use ECoG, sEEG and MEA. No restriction on the paradigm, or performance metrics. I do both offline and online.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"is_helpful\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n  }\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - 其他所有字段都为空。\n- normalized_understanding：300-600英文字符，必须是你融合两段文本后的“当前理解”，术语一致、范围聚焦。\n- 如果 plausibility_level=B_plausible且is_clear_for_search=true：\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空或最多1条轻微风险\n- 如果 plausibility_level=B_plausible且is_clear_for_search=false：\n  - uncertainties 至少2条\n  - suggested_questions 为1-3条，必须与uncertainties/missing_fields一致\n\n- 如果 plausibility_level=A_impossible：\n  - is_clear_for_search 必须为 false\n  - suggested_questions 必须为空数组\n  - uncertainties <=200英文字符：提示用户impossible的原因。\n"}
{"ts": "2026-01-21T18:13:48.194766+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces that decode movement intention, attempted/executed movement, or motor imagery from invasive electrophysiology, including ECoG, sEEG, and microelectrode arrays (MEA). The focus is on signal processing and machine-learning pipelines for feature extraction and classification/regression to generate control commands for external devices or neuroprostheses, evaluated in both offline decoding and online/closed-loop real-time BCI settings.\",\n  \"structured_summary\": {\n    \"domain\": \"Motor brain–computer interfaces (invasive electrophysiology)\",\n    \"task\": \"Decode motor intention/kinematics or motor imagery into control commands; offline decoding and online closed-loop control\",\n    \"subject_system\": \"Intracranial recordings: ECoG, sEEG, and MEA (species/participant type unspecified)\",\n    \"methods\": \"Neural signal processing, feature extraction, ML decoding (classification/regression), real-time/closed-loop evaluation\",\n    \"scope\": \"Broad across paradigms and metrics; invasive modalities spanning field potentials to single-/multi-unit activity\",\n    \"intent\": \"Enable reliable control of external devices/neuroprostheses from invasive neural activity\",\n    \"exclusions\": \"Non-invasive EEG/MEG/fNIRS; purely cognitive/affective decoding not tied to motor control\"\n  },\n  \"uncertainties\": [\n    \"Target population and dataset context are unspecified (human clinical ECoG/sEEG vs animal MEA), which affects search terms and evaluation conventions.\",\n    \"The controlled effector/application is not specified (cursor, robotic arm, FES, speech/hand), making the task space too broad for precise retrieval.\",\n    \"No primary performance metrics are prioritized (e.g., bitrate, success rate, latency, trajectory error), limiting focused benchmarking queries.\"\n  ],\n  \"missing_fields\": [],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Are you primarily targeting human clinical recordings (ECoG/sEEG) or animal MEA experiments, or do you want a cross-species review?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What is the main control target/effector for the BCI (e.g., 2D cursor, robotic arm reach/grasp, FES for hand, wheelchair), and which body part is decoded?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which evaluation setting should be emphasized for search: offline decoding benchmarks, online closed-loop control studies, or both equally?\"\n    }\n  ]\n}", "project_id": "6af7ac1b6254", "run_id": "a494c4a00bf1", "stage": "stage2"}
{"ts": "2026-01-21T18:13:48.198169+00:00", "event": "parse.stage2.response", "project_id": "6af7ac1b6254", "run_id": "a494c4a00bf1", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces that decode movement intention, attempted/executed movement, or motor imagery from invasive electrophysiology, including ECoG, sEEG, and microelectrode arrays (MEA). The focus is on signal processing and machine-learning pipelines for feature extraction and classification/regression to generate control commands for external devices or neuroprostheses, evaluated in both offline decoding and online/closed-loop real-time BCI settings.\",\n  \"structured_summary\": {\n    \"domain\": \"Motor brain–computer interfaces (invasive electrophysiology)\",\n    \"task\": \"Decode motor intention/kinematics or motor imagery into control commands; offline decoding and online closed-loop control\",\n    \"subject_system\": \"Intracranial recordings: ECoG, sEEG, and MEA (species/participant type unspecified)\",\n    \"methods\": \"Neural signal processing, feature extraction, ML decoding (classification/regression), real-time/closed-loop evaluation\",\n    \"scope\": \"Broad across paradigms and metrics; invasive modalities spanning field potentials to single-/multi-unit activity\",\n    \"intent\": \"Enable reliable control of external devices/neuroprostheses from invasive neural activity\",\n    \"exclusions\": \"Non-invasive EEG/MEG/fNIRS; purely cognitive/affective decoding not tied to motor control\"\n  },\n  \"uncertainties\": [\n    \"Target population and dataset context are unspecified (human clinical ECoG/sEEG vs animal MEA), which affects search terms and evaluation conventions.\",\n    \"The controlled effector/application is not specified (cursor, robotic arm, FES, speech/hand), making the task space too broad for precise retrieval.\",\n    \"No primary performance metrics are prioritized (e.g., bitrate, success rate, latency, trajectory error), limiting focused benchmarking queries.\"\n  ],\n  \"missing_fields\": [],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Are you primarily targeting human clinical recordings (ECoG/sEEG) or animal MEA experiments, or do you want a cross-species review?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What is the main control target/effector for the BCI (e.g., 2D cursor, robotic arm reach/grasp, FES for hand, wheelchair), and which body part is decoded?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which evaluation setting should be emphasized for search: offline decoding benchmarks, online closed-loop control studies, or both equally?\"\n    }\n  ]\n}"}
{"ts": "2026-01-21T18:20:20.530769+00:00", "event": "parse.stage1.prompt", "project_id": "6af7ac1b6254", "run_id": "789b6c199ada", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage1_understanding.md", "prompt": "你是“研究描述理解与规范化”模块。输入是一段纯文本候选研究描述。你的目标是帮助用户把研究描述变得合理且清晰，便于后续生成文献检索查询。\n\n你必须完成：\n1) 判断这段描述是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true.\n2) 如果是研究描述,进行常识可行性判断（plausibility_level）：\n- A_impossible：明显荒诞/违背当前科技常识（无法形成合理检索任务）\n- B_plausible：合理可行\n3) 如果合理可行，给出你对该研究描述的“当前理解”（normalized_understanding），用规范化、聚焦、可检索的英语重写，\n4) 判断当前理解是否已经清晰到可以用于检索；若不清晰，列出你仍不确定的点（疑问清单），并提出最多3个澄清问题（问题必须具体可回答）。\n5) 输出结构化提要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n6) 只输出JSON，不输出任何额外文本。\n\n候选研究描述：\n\"\"\"I focus on motor brain-computer interface based on the invasive EEG signals.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n}\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - ncertainties/missing_fields/suggested_questions为空数组[];\n  - structured_summary为全null；\n- normalized_understanding：300-600个英文字符，必须是你对研究的“当前理解”，语言规范、聚焦、可检索；不要写“我认为/可能”等口水话，直接用陈述句组织。\n\n- 如果 是B_plausible，且 is_clear_for_search=true，则：\n  - is_research_description = true\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空数组或只保留0-1条轻微风险\n\n- 如果 是B_plausible，且 is_clear_for_search=false，则：\n  - is_research_description = true\n  - uncertainties 至少2条\n  - missing_fields 仅列出缺失项\n  - suggested_questions 为1-3条，必须与 uncertainties/missing_fields 对应\n\n- 如果 plausibility_level=A_impossible，则：\n  - is_clear_for_search=false\n  - suggested_questions 为空\n  - uncertainties <=200英文字符：给出impossible的原因。\n"}
{"ts": "2026-01-21T18:20:33.301222+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces (BCIs) that decode movement intention and/or control signals from invasively recorded electrophysiological brain activity (e.g., intracranial EEG/ECoG). The work targets signal processing and machine-learning decoding pipelines for motor tasks, aiming to improve accuracy, robustness, and real-time control performance for assistive or neuroprosthetic applications.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces; neuroengineering; neural signal processing\",\n    \"task\": \"Decode motor intention/kinematics for BCI control from invasive electrophysiological recordings\",\n    \"subject_system\": \"Human or animal motor cortex recordings using intracranial EEG/ECoG (invasive EEG)\",\n    \"methods\": \"Feature extraction (time–frequency, ERD/ERS, high-gamma), machine learning/deep learning classifiers/regressors, real-time decoding\",\n    \"scope\": \"Motor BCI using invasive recordings; offline and/or online control; specific motor tasks not specified\",\n    \"intent\": \"Improve decoding performance and enable reliable motor control for assistive/neuroprosthetic use\",\n    \"exclusions\": \"Non-invasive EEG-only BCIs; non-motor cognitive BCIs; purely clinical outcome studies without decoding methods\"\n  },\n  \"uncertainties\": [\n    \"The term 'invasive EEG' is ambiguous; it could mean ECoG, sEEG, or other intracranial recordings.\",\n    \"The target motor paradigm is unspecified (e.g., imagined vs executed movement, discrete classification vs continuous kinematics).\",\n    \"The intended evaluation setting is unclear (offline decoding vs closed-loop real-time BCI control, and which performance metrics).\"\n  ],\n  \"missing_fields\": [\"subject_system\", \"scope\", \"methods\"],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"What specific invasive recording modality do you mean by 'invasive EEG' (ECoG, sEEG/SEEG, intracortical microelectrodes), and in which species (human/animal)?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which motor task and output are you targeting: discrete movement class (e.g., left/right hand) or continuous variables (e.g., kinematics/force), and is it imagined or executed movement?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"Are you focusing on particular decoding approaches (e.g., CSP + LDA/SVM, RNN/CNN/transformers, Kalman filters) and is the goal offline analysis or closed-loop real-time control?\"\n    }\n  ]\n}", "project_id": "6af7ac1b6254", "run_id": "789b6c199ada", "stage": "stage1"}
{"ts": "2026-01-21T18:20:33.301754+00:00", "event": "parse.stage1.response", "project_id": "6af7ac1b6254", "run_id": "789b6c199ada", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces (BCIs) that decode movement intention and/or control signals from invasively recorded electrophysiological brain activity (e.g., intracranial EEG/ECoG). The work targets signal processing and machine-learning decoding pipelines for motor tasks, aiming to improve accuracy, robustness, and real-time control performance for assistive or neuroprosthetic applications.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces; neuroengineering; neural signal processing\",\n    \"task\": \"Decode motor intention/kinematics for BCI control from invasive electrophysiological recordings\",\n    \"subject_system\": \"Human or animal motor cortex recordings using intracranial EEG/ECoG (invasive EEG)\",\n    \"methods\": \"Feature extraction (time–frequency, ERD/ERS, high-gamma), machine learning/deep learning classifiers/regressors, real-time decoding\",\n    \"scope\": \"Motor BCI using invasive recordings; offline and/or online control; specific motor tasks not specified\",\n    \"intent\": \"Improve decoding performance and enable reliable motor control for assistive/neuroprosthetic use\",\n    \"exclusions\": \"Non-invasive EEG-only BCIs; non-motor cognitive BCIs; purely clinical outcome studies without decoding methods\"\n  },\n  \"uncertainties\": [\n    \"The term 'invasive EEG' is ambiguous; it could mean ECoG, sEEG, or other intracranial recordings.\",\n    \"The target motor paradigm is unspecified (e.g., imagined vs executed movement, discrete classification vs continuous kinematics).\",\n    \"The intended evaluation setting is unclear (offline decoding vs closed-loop real-time BCI control, and which performance metrics).\"\n  ],\n  \"missing_fields\": [\"subject_system\", \"scope\", \"methods\"],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"What specific invasive recording modality do you mean by 'invasive EEG' (ECoG, sEEG/SEEG, intracortical microelectrodes), and in which species (human/animal)?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which motor task and output are you targeting: discrete movement class (e.g., left/right hand) or continuous variables (e.g., kinematics/force), and is it imagined or executed movement?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"Are you focusing on particular decoding approaches (e.g., CSP + LDA/SVM, RNN/CNN/transformers, Kalman filters) and is the goal offline analysis or closed-loop real-time control?\"\n    }\n  ]\n}"}
{"ts": "2026-01-21T18:22:03.380032+00:00", "event": "parse.stage2.prompt", "project_id": "6af7ac1b6254", "run_id": "789b6c199ada", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage2_converge.md", "prompt": "你是“研究描述自我收敛器”。你将收到三段文本：\n(1) 当前候选研究描述 current_description\n(2) 关于当前研究描述的问题question_for_user\n(3) 用户本轮补充信息 user_additional_info（可能回答了你上轮的问题，也可能没有）\n\n你的任务是：\n1) 判断当前候选研究描述和用户本轮补充信息是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true，并将两段文本融合，形成你对研究内容的“当前理解”，并判断更新后的研究内容是否合理：\n- A_impossible：明显荒诞/违背当前科技常识，无法形成合理检索任务\n- B_plausible：合理可行\n2) 如果A_impossible，给出简单的理由。如果新的理解是合理可行的，就用规范、聚焦、可检索的英文重写（300-600英文字符），这段重写用于帮助用户组织语言与规范表述。\n3) 判断本轮补充的信息是否对解答question_for_user有帮助。有帮助的话就返回 is_helpful=true。\n4) 如果在新增信息后仍不清晰：输出你仍不确定的点（uncertainties），并提出最多3个澄清问题（具体可回答，优先信息增益最大）。\n5) 如果已经清晰：不要再提问题；只输出你的理解与结构化摘要。\n6) 输出结构化摘要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n只输出JSON，不输出任何额外文字。\n\ncurrent_description：\n\"\"\"I focus on motor brain-computer interface based on the invasive EEG signals.\"\"\"\n\nquestion_for_user：\n\"\"\"What specific invasive recording modality do you mean by 'invasive EEG' (ECoG, sEEG/SEEG, intracortical microelectrodes), and in which species (human/animal)?\nWhich motor task and output are you targeting: discrete movement class (e.g., left/right hand) or continuous variables (e.g., kinematics/force), and is it imagined or executed movement?\nAre you focusing on particular decoding approaches (e.g., CSP + LDA/SVM, RNN/CNN/transformers, Kalman filters) and is the goal offline analysis or closed-loop real-time control?\"\"\"\n\n\nuser_additional_info（用户本轮补充信息，可能为空）：\n\"\"\"I use ECoG, sEEG, MEA. No restriction on the population, species, task/output, decoding approach. I do both offline and online.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"is_helpful\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n  }\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - 其他所有字段都为空。\n- normalized_understanding：300-600英文字符，必须是你融合两段文本后的“当前理解”，术语一致、范围聚焦。\n- 如果 plausibility_level=B_plausible且is_clear_for_search=true：\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空或最多1条轻微风险\n- 如果 plausibility_level=B_plausible且is_clear_for_search=false：\n  - uncertainties 至少2条\n  - suggested_questions 为1-3条，必须与uncertainties/missing_fields一致\n\n- 如果 plausibility_level=A_impossible：\n  - is_clear_for_search 必须为 false\n  - suggested_questions 必须为空数组\n  - uncertainties <=200英文字符：提示用户impossible的原因。\n"}
{"ts": "2026-01-21T18:22:16.513591+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"My research centers on motor brain–computer interfaces using invasive electrophysiology, specifically ECoG, sEEG/SEEG, and intracortical microelectrode arrays (MEA). I develop and evaluate neural decoding pipelines for motor intention and movement-related variables, considering both offline analyses and online/closed-loop control. The work is modality-agnostic and does not currently restrict species/population, motor task paradigms, output type (discrete vs continuous), or decoding model family.\",\n  \"structured_summary\": {\n    \"domain\": \"Motor brain–computer interfaces (invasive electrophysiology)\",\n    \"task\": \"Decode motor intention/movement variables for BCI control (offline and online/closed-loop)\",\n    \"subject_system\": \"ECoG, sEEG/SEEG, and intracortical microelectrode arrays; species/population unspecified\",\n    \"methods\": \"Neural signal processing and decoding models (unspecified; modality-agnostic)\",\n    \"scope\": \"Broad across species, tasks, outputs, and model classes; includes offline analysis and real-time control\",\n    \"intent\": \"Build and assess invasive-signal motor decoding for BCI applications\",\n    \"exclusions\": \"None specified\"\n  },\n  \"uncertainties\": [\n    \"The scope is too unconstrained (species, task paradigm, output variables, and model family), making the description hard to search and position.\",\n    \"It is unclear whether the primary contribution is algorithmic decoding, closed-loop control design, neural feature discovery, or comparative evaluation across modalities.\"\n  ],\n  \"missing_fields\": [\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"What 1–2 representative motor paradigms and outputs best characterize your work (e.g., executed vs imagined; reach/grasp; discrete classes vs continuous kinematics/force)?\"\n    },\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Which subject population(s) are most central (human clinical ECoG/sEEG, non-human primate MEA, rodent), and are recordings acute or chronic?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What is your main technical focus: feature engineering (e.g., bandpower/HG), deep learning (CNN/RNN/transformer), state-space/Kalman decoding, or closed-loop adaptation/learning?\"\n    }\n  ]\n}", "project_id": "6af7ac1b6254", "run_id": "789b6c199ada", "stage": "stage2"}
{"ts": "2026-01-21T18:22:16.515040+00:00", "event": "parse.stage2.response", "project_id": "6af7ac1b6254", "run_id": "789b6c199ada", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"My research centers on motor brain–computer interfaces using invasive electrophysiology, specifically ECoG, sEEG/SEEG, and intracortical microelectrode arrays (MEA). I develop and evaluate neural decoding pipelines for motor intention and movement-related variables, considering both offline analyses and online/closed-loop control. The work is modality-agnostic and does not currently restrict species/population, motor task paradigms, output type (discrete vs continuous), or decoding model family.\",\n  \"structured_summary\": {\n    \"domain\": \"Motor brain–computer interfaces (invasive electrophysiology)\",\n    \"task\": \"Decode motor intention/movement variables for BCI control (offline and online/closed-loop)\",\n    \"subject_system\": \"ECoG, sEEG/SEEG, and intracortical microelectrode arrays; species/population unspecified\",\n    \"methods\": \"Neural signal processing and decoding models (unspecified; modality-agnostic)\",\n    \"scope\": \"Broad across species, tasks, outputs, and model classes; includes offline analysis and real-time control\",\n    \"intent\": \"Build and assess invasive-signal motor decoding for BCI applications\",\n    \"exclusions\": \"None specified\"\n  },\n  \"uncertainties\": [\n    \"The scope is too unconstrained (species, task paradigm, output variables, and model family), making the description hard to search and position.\",\n    \"It is unclear whether the primary contribution is algorithmic decoding, closed-loop control design, neural feature discovery, or comparative evaluation across modalities.\"\n  ],\n  \"missing_fields\": [\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"What 1–2 representative motor paradigms and outputs best characterize your work (e.g., executed vs imagined; reach/grasp; discrete classes vs continuous kinematics/force)?\"\n    },\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Which subject population(s) are most central (human clinical ECoG/sEEG, non-human primate MEA, rodent), and are recordings acute or chronic?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What is your main technical focus: feature engineering (e.g., bandpower/HG), deep learning (CNN/RNN/transformer), state-space/Kalman decoding, or closed-loop adaptation/learning?\"\n    }\n  ]\n}"}
{"ts": "2026-01-21T18:29:27.247752+00:00", "event": "parse.stage1.prompt", "project_id": "6af7ac1b6254", "run_id": "a0ed3ea2b2ed", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage1_understanding.md", "prompt": "你是“研究描述理解与规范化”模块。输入是一段纯文本候选研究描述。你的目标是帮助用户把研究描述变得合理且清晰，便于后续生成文献检索查询。\n\n你必须完成：\n1) 判断这段描述是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true.\n2) 如果是研究描述,进行常识可行性判断（plausibility_level）：\n- A_impossible：明显荒诞/违背当前科技常识（无法形成合理检索任务）\n- B_plausible：合理可行\n3) 如果合理可行，给出你对该研究描述的“当前理解”（normalized_understanding），用规范化、聚焦、可检索的英语重写，\n4) 判断当前理解是否已经清晰到可以用于检索；若不清晰，列出你仍不确定的点（疑问清单），并提出最多3个澄清问题（问题必须具体可回答）。\n5) 输出结构化提要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n6) 只输出JSON，不输出任何额外文本。\n\n候选研究描述：\n\"\"\"I focus on motor brain-computer interface based on the invasive EEG signals.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n}\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - ncertainties/missing_fields/suggested_questions为空数组[];\n  - structured_summary为全null；\n- normalized_understanding：300-600个英文字符，必须是你对研究的“当前理解”，语言规范、聚焦、可检索；不要写“我认为/可能”等口水话，直接用陈述句组织。\n\n- 如果 是B_plausible，且 is_clear_for_search=true，则：\n  - is_research_description = true\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空数组或只保留0-1条轻微风险\n\n- 如果 是B_plausible，且 is_clear_for_search=false，则：\n  - is_research_description = true\n  - uncertainties 至少2条\n  - missing_fields 仅列出缺失项\n  - suggested_questions 为1-3条，必须与 uncertainties/missing_fields 对应\n\n- 如果 plausibility_level=A_impossible，则：\n  - is_clear_for_search=false\n  - suggested_questions 为空\n  - uncertainties <=200英文字符：给出impossible的原因。\n"}
{"ts": "2026-01-21T18:29:39.757134+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces (BCIs) that decode movement intention and control external devices using invasive electrophysiological recordings from the brain (e.g., intracranial EEG/ECoG). The work targets signal acquisition, preprocessing, feature extraction, and machine-learning decoding of motor-related neural activity for real-time cursor, prosthetic, or robotic control, with evaluation on human or animal datasets.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces; neural engineering; motor neuroprosthetics\",\n    \"task\": \"Decode motor intention/kinematics from invasive brain signals for device control\",\n    \"subject_system\": \"Invasive intracranial recordings (iEEG/ECoG) from motor cortex in humans or animals\",\n    \"methods\": \"Signal processing and machine-learning decoding (feature extraction, classification/regression, real-time control)\",\n    \"scope\": \"Motor BCI using invasive electrophysiology; online or offline decoding; application to cursor/prosthesis/robot control\",\n    \"intent\": \"Enable reliable motor control via invasive BCI and improve decoding performance/robustness\",\n    \"exclusions\": \"Non-invasive EEG-only BCIs; non-motor (e.g., P300/SSVEP) paradigms unless explicitly included\"\n  },\n  \"uncertainties\": [\n    \"The phrase 'invasive EEG' is ambiguous; it may mean iEEG/ECoG rather than scalp EEG.\",\n    \"The specific motor task and output (classification of movement intention vs continuous kinematics) are not specified.\",\n    \"Target population and experimental setting (human clinical implants vs animal models; online closed-loop vs offline analysis) are unclear.\"\n  ],\n  \"missing_fields\": [\"task\", \"subject_system\", \"methods\", \"scope\"],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Do you mean intracranial EEG (iEEG) or electrocorticography (ECoG), and which brain areas (e.g., M1, premotor, SMA) are recorded?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What motor decoding target is primary: discrete movement intention/class labels, or continuous kinematics/force trajectories?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Is the focus on real-time closed-loop BCI control (cursor/prosthesis/robot) or offline decoding performance on recorded datasets?\"\n    }\n  ]\n}", "project_id": "6af7ac1b6254", "run_id": "a0ed3ea2b2ed", "stage": "stage1"}
{"ts": "2026-01-21T18:29:39.758527+00:00", "event": "parse.stage1.response", "project_id": "6af7ac1b6254", "run_id": "a0ed3ea2b2ed", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces (BCIs) that decode movement intention and control external devices using invasive electrophysiological recordings from the brain (e.g., intracranial EEG/ECoG). The work targets signal acquisition, preprocessing, feature extraction, and machine-learning decoding of motor-related neural activity for real-time cursor, prosthetic, or robotic control, with evaluation on human or animal datasets.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces; neural engineering; motor neuroprosthetics\",\n    \"task\": \"Decode motor intention/kinematics from invasive brain signals for device control\",\n    \"subject_system\": \"Invasive intracranial recordings (iEEG/ECoG) from motor cortex in humans or animals\",\n    \"methods\": \"Signal processing and machine-learning decoding (feature extraction, classification/regression, real-time control)\",\n    \"scope\": \"Motor BCI using invasive electrophysiology; online or offline decoding; application to cursor/prosthesis/robot control\",\n    \"intent\": \"Enable reliable motor control via invasive BCI and improve decoding performance/robustness\",\n    \"exclusions\": \"Non-invasive EEG-only BCIs; non-motor (e.g., P300/SSVEP) paradigms unless explicitly included\"\n  },\n  \"uncertainties\": [\n    \"The phrase 'invasive EEG' is ambiguous; it may mean iEEG/ECoG rather than scalp EEG.\",\n    \"The specific motor task and output (classification of movement intention vs continuous kinematics) are not specified.\",\n    \"Target population and experimental setting (human clinical implants vs animal models; online closed-loop vs offline analysis) are unclear.\"\n  ],\n  \"missing_fields\": [\"task\", \"subject_system\", \"methods\", \"scope\"],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Do you mean intracranial EEG (iEEG) or electrocorticography (ECoG), and which brain areas (e.g., M1, premotor, SMA) are recorded?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What motor decoding target is primary: discrete movement intention/class labels, or continuous kinematics/force trajectories?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Is the focus on real-time closed-loop BCI control (cursor/prosthesis/robot) or offline decoding performance on recorded datasets?\"\n    }\n  ]\n}"}
{"ts": "2026-01-21T18:30:39.316720+00:00", "event": "parse.stage2.prompt", "project_id": "6af7ac1b6254", "run_id": "a0ed3ea2b2ed", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage2_converge.md", "prompt": "你是“研究描述自我收敛器”。你将收到三段文本：\n(1) 当前候选研究描述 current_description\n(2) 关于当前研究描述的问题question_for_user\n(3) 用户本轮补充信息 user_additional_info（可能回答了你上轮的问题，也可能没有）\n\n你的任务是：\n1) 判断当前候选研究描述和用户本轮补充信息是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true，并将两段文本融合，形成你对研究内容的“当前理解”，并判断更新后的研究内容是否合理：\n- A_impossible：明显荒诞/违背当前科技常识，无法形成合理检索任务\n- B_plausible：合理可行\n2) 如果A_impossible，给出简单的理由。如果新的理解是合理可行的，就用规范、聚焦、可检索的英文重写（300-600英文字符），这段重写用于帮助用户组织语言与规范表述。\n3) 判断本轮补充的信息是否对解答question_for_user有帮助。有帮助的话就返回 is_helpful=true。\n4) 如果在新增信息后仍不清晰：输出你仍不确定的点（uncertainties），并提出最多3个澄清问题（具体可回答，优先信息增益最大）。\n5) 如果已经清晰：不要再提问题；只输出你的理解与结构化摘要。\n6) 输出结构化摘要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n只输出JSON，不输出任何额外文字。\n\ncurrent_description：\n\"\"\"Research on motor brain–computer interfaces (BCIs) that decode movement intention and control external devices using invasive electrophysiological recordings from the brain (e.g., intracranial EEG/ECoG). The work targets signal acquisition, preprocessing, feature extraction, and machine-learning decoding of motor-related neural activity for real-time cursor, prosthetic, or robotic control, with evaluation on human or animal datasets.\"\"\"\n\nquestion_for_user：\n\"\"\"Do you mean intracranial EEG (iEEG) or electrocorticography (ECoG), and which brain areas (e.g., M1, premotor, SMA) are recorded?\nWhat motor decoding target is primary: discrete movement intention/class labels, or continuous kinematics/force trajectories?\nIs the focus on real-time closed-loop BCI control (cursor/prosthesis/robot) or offline decoding performance on recorded datasets?\"\"\"\n\n\nuser_additional_info（用户本轮补充信息，可能为空）：\n\"\"\"I mean ECoG, sEEG and MEA. No restriction on the brain area, decoding target. I do both real-time and offline.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"is_helpful\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n  }\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - 其他所有字段都为空。\n- normalized_understanding：300-600英文字符，必须是你融合两段文本后的“当前理解”，术语一致、范围聚焦。\n- 如果 plausibility_level=B_plausible且is_clear_for_search=true：\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空或最多1条轻微风险\n- 如果 plausibility_level=B_plausible且is_clear_for_search=false：\n  - uncertainties 至少2条\n  - suggested_questions 为1-3条，必须与uncertainties/missing_fields一致\n\n- 如果 plausibility_level=A_impossible：\n  - is_clear_for_search 必须为 false\n  - suggested_questions 必须为空数组\n  - uncertainties <=200英文字符：提示用户impossible的原因。\n"}
{"ts": "2026-01-21T18:30:51.959540+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces using invasive electrophysiology—ECoG, sEEG, and microelectrode arrays (MEA)—to decode movement intention and control external devices. The work spans signal acquisition and preprocessing, feature extraction, and machine-learning/neural decoding of motor-related activity, evaluated both offline on recorded human/animal datasets and in real-time closed-loop control (e.g., cursor, prosthesis, robotic systems).\",\n  \"structured_summary\": {\n    \"domain\": \"Motor brain–computer interfaces (invasive electrophysiology)\",\n    \"task\": \"Decode motor intention/kinematics from neural signals for device control; evaluate offline and closed-loop performance\",\n    \"subject_system\": \"Human or animal brain recordings via ECoG, sEEG, and MEA; external effectors such as cursor/prosthesis/robot\",\n    \"methods\": \"Signal acquisition, preprocessing, feature extraction, ML/deep learning decoding; real-time closed-loop control algorithms and offline benchmarking\",\n    \"scope\": \"No restriction on recorded brain areas or decoding targets; includes discrete and continuous decoding; both offline and real-time settings\",\n    \"intent\": \"Enable accurate, robust motor decoding and practical control of external devices using invasive neural recordings\",\n    \"exclusions\": \"Non-invasive modalities (e.g., scalp EEG/MEG) and purely clinical/diagnostic electrophysiology without BCI decoding/control\"\n  },\n  \"uncertainties\": [\n    \"The scope is very broad (no constraints on brain areas, targets, or paradigms), which may reduce search precision.\",\n    \"Primary contribution is unclear: decoding algorithms, signal features, hardware/recording, adaptation/robustness, or closed-loop control design.\",\n    \"Target application and evaluation metrics are unspecified (e.g., cursor vs prosthesis vs robot; accuracy vs bitrate vs latency).\"\n  ],\n  \"missing_fields\": [],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"What is the primary decoding objective you want to emphasize for search: discrete intention/classification, continuous kinematics/force regression, or both with a specific benchmark task?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"Which methodological focus best represents your contribution: feature engineering (e.g., HFA), deep learning architectures, domain adaptation/transfer, online adaptation, or closed-loop control policies?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which application and evaluation setting should be prioritized: cursor control, prosthetic limb control, or robotic control; and which key metrics (accuracy, bitrate, latency, stability over days) matter most?\"\n    }\n  ]\n}", "project_id": "6af7ac1b6254", "run_id": "a0ed3ea2b2ed", "stage": "stage2"}
{"ts": "2026-01-21T18:30:51.960545+00:00", "event": "parse.stage2.response", "project_id": "6af7ac1b6254", "run_id": "a0ed3ea2b2ed", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": true,\n  \"normalized_understanding\": \"Research on motor brain–computer interfaces using invasive electrophysiology—ECoG, sEEG, and microelectrode arrays (MEA)—to decode movement intention and control external devices. The work spans signal acquisition and preprocessing, feature extraction, and machine-learning/neural decoding of motor-related activity, evaluated both offline on recorded human/animal datasets and in real-time closed-loop control (e.g., cursor, prosthesis, robotic systems).\",\n  \"structured_summary\": {\n    \"domain\": \"Motor brain–computer interfaces (invasive electrophysiology)\",\n    \"task\": \"Decode motor intention/kinematics from neural signals for device control; evaluate offline and closed-loop performance\",\n    \"subject_system\": \"Human or animal brain recordings via ECoG, sEEG, and MEA; external effectors such as cursor/prosthesis/robot\",\n    \"methods\": \"Signal acquisition, preprocessing, feature extraction, ML/deep learning decoding; real-time closed-loop control algorithms and offline benchmarking\",\n    \"scope\": \"No restriction on recorded brain areas or decoding targets; includes discrete and continuous decoding; both offline and real-time settings\",\n    \"intent\": \"Enable accurate, robust motor decoding and practical control of external devices using invasive neural recordings\",\n    \"exclusions\": \"Non-invasive modalities (e.g., scalp EEG/MEG) and purely clinical/diagnostic electrophysiology without BCI decoding/control\"\n  },\n  \"uncertainties\": [\n    \"The scope is very broad (no constraints on brain areas, targets, or paradigms), which may reduce search precision.\",\n    \"Primary contribution is unclear: decoding algorithms, signal features, hardware/recording, adaptation/robustness, or closed-loop control design.\",\n    \"Target application and evaluation metrics are unspecified (e.g., cursor vs prosthesis vs robot; accuracy vs bitrate vs latency).\"\n  ],\n  \"missing_fields\": [],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"What is the primary decoding objective you want to emphasize for search: discrete intention/classification, continuous kinematics/force regression, or both with a specific benchmark task?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"Which methodological focus best represents your contribution: feature engineering (e.g., HFA), deep learning architectures, domain adaptation/transfer, online adaptation, or closed-loop control policies?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which application and evaluation setting should be prioritized: cursor control, prosthetic limb control, or robotic control; and which key metrics (accuracy, bitrate, latency, stability over days) matter most?\"\n    }\n  ]\n}"}
{"ts": "2026-01-21T20:42:09.023491+00:00", "event": "phase1.parse.prompt", "project_id": "6af7ac1b6254", "run_id": "a0ed3ea2b2ed", "model": "gpt-5.2", "reasoning_effort": "high", "prompt": "You are an expert academic search strategist specializing in exhaustive literature retrieval. \n\nBelow is a short research summary, your task is to take above research summary and directly produce a conceptual retrieval framework that can be used to systematically search for all relevant literature in that research field.\n\n-- research summary begin --\nResearch on motor brain–computer interfaces (BCIs) that decode movement intention and control external devices using invasive electrophysiological recordings from the brain (e.g., intracranial EEG/ECoG). The work targets signal acquisition, preprocessing, feature extraction, and machine-learning decoding of motor-related neural activity for real-time cursor, prosthetic, or robotic control, with evaluation on human or animal datasets.\n-- research summary end --\n\nThis is NOT a query-generation task.\nThis is a concept-framework construction task.\n\nYou must follow these rules strictly:\n\n1. Base the framework ONLY on the content explicitly stated or clearly implied in the research summary.\n   - Do NOT introduce new research goals, populations, or application domains.\n   - Do NOT speculate beyond the summary.\n\n2. The output must define a SMALL NUMBER of concept blocks (typically 2–4).\n   - Each block represents a distinct and independently searchable conceptual dimension\nthat should not be merged with other dimensions if doing so would reduce recall.\n   - Examples include: research task, technical field/framing, data modality.\n   - All blocks together must uniquely define ONE narrow research field.\n\nIMPORTANT — Concept Block Separation Rule:\n\nWhen constructing concept blocks, prioritize retrieval independence over semantic compactness.\n\nIf two concepts frequently appear separately in relevant literature\n(e.g., one may be mentioned without the other in titles/abstracts),\nthey MUST be placed in separate concept blocks,\neven if they form a well-known combined phrase or subfield name.\n\nExample:\n- “speech” and “brain-computer interface” must be separate blocks,\n  because many relevant papers mention speech decoding without explicitly using “BCI”,\n  and others mention BCI without explicitly using “speech”.\n\n\n3. Each concept block must:\n   - Contain only terms that are conceptually equivalent within that block.\n   - Be expressed using terminology commonly found in academic databases.\n   - Include common synonyms, abbreviations, and canonical terms used in the literature.\n\n4. When the summary uses abstract or high-level language, normalize it into concrete, database-searchable concepts\n   ONLY when such normalization is standard practice in the field.\n   - Example: “invasive recordings” → ECoG, sEEG, intracortical recordings, MEA\n   - Do NOT introduce loosely related or adjacent techniques.\n\n5. All concept blocks must be REQUIRED.\n   - The framework should be designed for exhaustive retrieval within a specific field,\n     not for exploratory or cross-domain search.\n\n6. Do NOT generate executable Boolean queries.\n   - You MAY describe the logical relationship between blocks conceptually\n     (e.g., “documents must address all blocks simultaneously”),\n     but do not use database syntax.\n\n7. Explicitly prevent topic drift.\n   - The framework should clearly exclude adjacent but distinct research areas.\n\n### Output Format (must follow exactly):\n\n## Conceptual Retrieval Framework\n\n### Block A: [Concept Block Name]\n- Concept Role:\n- Normalized Search Terms:\n- Notes on Term Usage:\n\n### Block B: [Concept Block Name]\n- Concept Role:\n- Normalized Search Terms:\n- Notes on Term Usage:\n\n(Repeat blocks as needed)\n\n## Conceptual Combination Rule\nA single sentence explaining how all blocks jointly define the target literature set.\n\n## Scope Control\n- In-scope:\n- Out-of-scope:\n"}
{"ts": "2026-01-21T20:42:35.592788+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "## Conceptual Retrieval Framework\n\n### Block A: Motor brain–computer interface / neural prosthetic control (motor intention → device control)\n- Concept Role: Anchors the literature to BCI/neural interface systems specifically aimed at motor intention decoding for controlling an external effector (cursor/prosthesis/robot) rather than general neuroscience decoding.\n- Normalized Search Terms:\n  - “brain-computer interface” / “brain–computer interface” / BCI\n  - “brain-machine interface” / “brain–machine interface” / BMI\n  - “neural prosthesis” / “neuroprosthesis” / “neural prosthetic”\n  - “neural interface” (in the context of control/BCI)\n  - “cursor control”\n  - “prosthetic control” / “prosthesis control”\n  - “robotic control” / “robot control” (as BCI output)\n  - “closed-loop” (when used to describe BCI control)\n  - “real-time” (when used to describe online BCI control)\n- Notes on Term Usage:\n  - Many relevant papers use BMI instead of BCI; others foreground “neural prosthesis” or “cursor control” without saying BCI explicitly—keep these as equivalents within this block.\n  - “Closed-loop” and “real-time” are often used as descriptors of BCI operation; include them only as supporting terms, not as a substitute for BCI/BMI/prosthesis-control framing.\n\n### Block B: Motor intention / movement-related decoding target\n- Concept Role: Ensures the decoded content is motor-related (movement intention/kinematics/motor commands) rather than other cognitive or sensory targets.\n- Normalized Search Terms:\n  - “movement intention” / “motor intention” / “intended movement”\n  - “motor decoding” / “movement decoding”\n  - “motor imagery” (when used as a control signal for motor BCI)\n  - “reach” / “reaching” (as a decoded/controlled movement)\n  - “grasp” / “hand movement” / “arm movement”\n  - “kinematics” / “trajectory” (as decoded variables)\n  - “motor-related neural activity” / “motor cortical activity”\n- Notes on Term Usage:\n  - Some studies describe the target as kinematics/trajectory rather than “intention”; both should be treated as motor-decoding targets.\n  - Keep this block separate from the BCI block because some papers emphasize “motor decoding” without explicitly labeling the system as a BCI, and vice versa.\n\n### Block C: Invasive intracranial electrophysiological recording modality\n- Concept Role: Restricts retrieval to invasive brain recordings (intracranial electrophysiology) rather than noninvasive EEG/MEG/fNIRS.\n- Normalized Search Terms:\n  - “electrocorticography” / ECoG\n  - “intracranial EEG” / iEEG / “intracranial electroencephalography”\n  - “stereoelectroencephalography” / sEEG / SEEG\n  - “intracranial recording*” / “invasive recording*”\n  - “local field potential*” / LFP (when explicitly intracranial)\n  - “intracortical recording*” / “microelectrode array” / MEA (if described as invasive electrophysiology)\n- Notes on Term Usage:\n  - The summary explicitly mentions intracranial EEG/ECoG; include closely aligned intracranial electrophysiology labels commonly used in databases (iEEG, sEEG, LFP, intracortical/MEA) as modality synonyms.\n  - This block is required to prevent drift into noninvasive motor-BCI EEG literature.\n\n### Block D: Decoding pipeline / machine-learning-based signal processing for control\n- Concept Role: Captures the methodological focus on acquisition → preprocessing → feature extraction → decoding/ML for (often online) control, distinguishing from purely descriptive motor physiology.\n- Normalized Search Terms:\n  - “signal acquisition” (in BCI context)\n  - preprocessing / “artifact removal” / “filtering”\n  - “feature extraction” / “feature selection”\n  - “machine learning” / “classification” / “regression”\n  - “decoder” / “decoding algorithm” / “neural decoding”\n  - “real-time decoding” / “online decoding”\n- Notes on Term Usage:\n  - Many relevant papers emphasize “decoder” or “neural decoding” without listing pipeline steps; include both pipeline-step terms and generic decoding/ML terms.\n  - Keep this block separate from the BCI block to retain papers that present decoding methods for motor control signals from intracranial recordings even if “BCI” is not foregrounded in title/abstract.\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously address (A) motor BCI/neural prosthetic control, (B) motor intention/movement decoding targets, (C) invasive intracranial electrophysiological recordings (e.g., ECoG/iEEG), and (D) decoding/ML signal-processing methods enabling (often real-time) control.\n\n## Scope Control\n- In-scope:\n  - Motor BCIs/BMIs using invasive intracranial electrophysiology (ECoG/iEEG/sEEG and closely aligned intracranial electrophysiology) to decode movement intention/kinematics for real-time/online control of cursors, prostheses, or robots, including work on preprocessing, feature extraction, and ML decoding.\n  - Human or animal datasets used to evaluate such invasive motor-decoding BCI systems.\n- Out-of-scope:\n  - Noninvasive motor BCIs (scalp EEG, MEG, fNIRS) without intracranial recordings.\n  - BCIs not centered on motor intention/movement (e.g., communication/spelling, sensory decoding, affect/cognition) even if invasive.\n  - Pure motor neurophysiology studies using intracranial recordings that do not involve decoding/ML for control (i.e., no BCI/neural prosthesis control framing and no decoder development/evaluation).\n  - Non-electrophysiological invasive modalities (e.g., fMRI-based control) and non-brain signals (e.g., EMG-only control).", "project_id": "6af7ac1b6254", "run_id": "a0ed3ea2b2ed", "step": "parse"}
{"ts": "2026-01-21T20:42:35.593636+00:00", "event": "phase1.parse.response", "project_id": "6af7ac1b6254", "run_id": "a0ed3ea2b2ed", "model": "gpt-5.2", "response": "## Conceptual Retrieval Framework\n\n### Block A: Motor brain–computer interface / neural prosthetic control (motor intention → device control)\n- Concept Role: Anchors the literature to BCI/neural interface systems specifically aimed at motor intention decoding for controlling an external effector (cursor/prosthesis/robot) rather than general neuroscience decoding.\n- Normalized Search Terms:\n  - “brain-computer interface” / “brain–computer interface” / BCI\n  - “brain-machine interface” / “brain–machine interface” / BMI\n  - “neural prosthesis” / “neuroprosthesis” / “neural prosthetic”\n  - “neural interface” (in the context of control/BCI)\n  - “cursor control”\n  - “prosthetic control” / “prosthesis control”\n  - “robotic control” / “robot control” (as BCI output)\n  - “closed-loop” (when used to describe BCI control)\n  - “real-time” (when used to describe online BCI control)\n- Notes on Term Usage:\n  - Many relevant papers use BMI instead of BCI; others foreground “neural prosthesis” or “cursor control” without saying BCI explicitly—keep these as equivalents within this block.\n  - “Closed-loop” and “real-time” are often used as descriptors of BCI operation; include them only as supporting terms, not as a substitute for BCI/BMI/prosthesis-control framing.\n\n### Block B: Motor intention / movement-related decoding target\n- Concept Role: Ensures the decoded content is motor-related (movement intention/kinematics/motor commands) rather than other cognitive or sensory targets.\n- Normalized Search Terms:\n  - “movement intention” / “motor intention” / “intended movement”\n  - “motor decoding” / “movement decoding”\n  - “motor imagery” (when used as a control signal for motor BCI)\n  - “reach” / “reaching” (as a decoded/controlled movement)\n  - “grasp” / “hand movement” / “arm movement”\n  - “kinematics” / “trajectory” (as decoded variables)\n  - “motor-related neural activity” / “motor cortical activity”\n- Notes on Term Usage:\n  - Some studies describe the target as kinematics/trajectory rather than “intention”; both should be treated as motor-decoding targets.\n  - Keep this block separate from the BCI block because some papers emphasize “motor decoding” without explicitly labeling the system as a BCI, and vice versa.\n\n### Block C: Invasive intracranial electrophysiological recording modality\n- Concept Role: Restricts retrieval to invasive brain recordings (intracranial electrophysiology) rather than noninvasive EEG/MEG/fNIRS.\n- Normalized Search Terms:\n  - “electrocorticography” / ECoG\n  - “intracranial EEG” / iEEG / “intracranial electroencephalography”\n  - “stereoelectroencephalography” / sEEG / SEEG\n  - “intracranial recording*” / “invasive recording*”\n  - “local field potential*” / LFP (when explicitly intracranial)\n  - “intracortical recording*” / “microelectrode array” / MEA (if described as invasive electrophysiology)\n- Notes on Term Usage:\n  - The summary explicitly mentions intracranial EEG/ECoG; include closely aligned intracranial electrophysiology labels commonly used in databases (iEEG, sEEG, LFP, intracortical/MEA) as modality synonyms.\n  - This block is required to prevent drift into noninvasive motor-BCI EEG literature.\n\n### Block D: Decoding pipeline / machine-learning-based signal processing for control\n- Concept Role: Captures the methodological focus on acquisition → preprocessing → feature extraction → decoding/ML for (often online) control, distinguishing from purely descriptive motor physiology.\n- Normalized Search Terms:\n  - “signal acquisition” (in BCI context)\n  - preprocessing / “artifact removal” / “filtering”\n  - “feature extraction” / “feature selection”\n  - “machine learning” / “classification” / “regression”\n  - “decoder” / “decoding algorithm” / “neural decoding”\n  - “real-time decoding” / “online decoding”\n- Notes on Term Usage:\n  - Many relevant papers emphasize “decoder” or “neural decoding” without listing pipeline steps; include both pipeline-step terms and generic decoding/ML terms.\n  - Keep this block separate from the BCI block to retain papers that present decoding methods for motor control signals from intracranial recordings even if “BCI” is not foregrounded in title/abstract.\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously address (A) motor BCI/neural prosthetic control, (B) motor intention/movement decoding targets, (C) invasive intracranial electrophysiological recordings (e.g., ECoG/iEEG), and (D) decoding/ML signal-processing methods enabling (often real-time) control.\n\n## Scope Control\n- In-scope:\n  - Motor BCIs/BMIs using invasive intracranial electrophysiology (ECoG/iEEG/sEEG and closely aligned intracranial electrophysiology) to decode movement intention/kinematics for real-time/online control of cursors, prostheses, or robots, including work on preprocessing, feature extraction, and ML decoding.\n  - Human or animal datasets used to evaluate such invasive motor-decoding BCI systems.\n- Out-of-scope:\n  - Noninvasive motor BCIs (scalp EEG, MEG, fNIRS) without intracranial recordings.\n  - BCIs not centered on motor intention/movement (e.g., communication/spelling, sensory decoding, affect/cognition) even if invasive.\n  - Pure motor neurophysiology studies using intracranial recordings that do not involve decoding/ML for control (i.e., no BCI/neural prosthesis control framing and no decoder development/evaluation).\n  - Non-electrophysiological invasive modalities (e.g., fMRI-based control) and non-brain signals (e.g., EMG-only control)."}
{"ts": "2026-01-21T22:59:20.459351+00:00", "event": "phase1.adjust_framework.prompt", "project_id": "6af7ac1b6254", "run_id": "a0ed3ea2b2ed", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/retrival_framework_stage2.md", "prompt": "You are an expert academic search strategist specializing in exhaustive literature retrieval. \n\nYou will receive:\n(1) The current Conceptual Retrieval Framework\n(2) User's adjustment request (user_additional_info) - may contain clarifications, modifications, or additional requirements\n\nYour task is to integrate the user's input with the current framework and produce an updated Conceptual Retrieval Framework that reflects the user's adjustments while maintaining the framework's integrity and searchability.\n\n-- current framework begin --\n## Conceptual Retrieval Framework\n\n### Block A: Motor brain–computer interface / neural prosthetic control (motor intention → device control)\n- Concept Role: Anchors the literature to BCI/neural interface systems specifically aimed at motor intention decoding for controlling an external effector (cursor/prosthesis/robot) rather than general neuroscience decoding.\n- Normalized Search Terms:\n  - “brain-computer interface” / “brain–computer interface” / BCI\n  - “brain-machine interface” / “brain–machine interface” / BMI\n  - “neural prosthesis” / “neuroprosthesis” / “neural prosthetic”\n  - “neural interface” (in the context of control/BCI)\n  - “cursor control”\n  - “prosthetic control” / “prosthesis control”\n  - “robotic control” / “robot control” (as BCI output)\n  - “closed-loop” (when used to describe BCI control)\n  - “real-time” (when used to describe online BCI control)\n- Notes on Term Usage:\n  - Many relevant papers use BMI instead of BCI; others foreground “neural prosthesis” or “cursor control” without saying BCI explicitly—keep these as equivalents within this block.\n  - “Closed-loop” and “real-time” are often used as descriptors of BCI operation; include them only as supporting terms, not as a substitute for BCI/BMI/prosthesis-control framing.\n\n### Block B: Motor intention / movement-related decoding target\n- Concept Role: Ensures the decoded content is motor-related (movement intention/kinematics/motor commands) rather than other cognitive or sensory targets.\n- Normalized Search Terms:\n  - “movement intention” / “motor intention” / “intended movement”\n  - “motor decoding” / “movement decoding”\n  - “motor imagery” (when used as a control signal for motor BCI)\n  - “reach” / “reaching” (as a decoded/controlled movement)\n  - “grasp” / “hand movement” / “arm movement”\n  - “kinematics” / “trajectory” (as decoded variables)\n  - “motor-related neural activity” / “motor cortical activity”\n- Notes on Term Usage:\n  - Some studies describe the target as kinematics/trajectory rather than “intention”; both should be treated as motor-decoding targets.\n  - Keep this block separate from the BCI block because some papers emphasize “motor decoding” without explicitly labeling the system as a BCI, and vice versa.\n\n### Block C: Invasive intracranial electrophysiological recording modality\n- Concept Role: Restricts retrieval to invasive brain recordings (intracranial electrophysiology) rather than noninvasive EEG/MEG/fNIRS.\n- Normalized Search Terms:\n  - “electrocorticography” / ECoG\n  - “intracranial EEG” / iEEG / “intracranial electroencephalography”\n  - “stereoelectroencephalography” / sEEG / SEEG\n  - “intracranial recording*” / “invasive recording*”\n  - “local field potential*” / LFP (when explicitly intracranial)\n  - “intracortical recording*” / “microelectrode array” / MEA (if described as invasive electrophysiology)\n- Notes on Term Usage:\n  - The summary explicitly mentions intracranial EEG/ECoG; include closely aligned intracranial electrophysiology labels commonly used in databases (iEEG, sEEG, LFP, intracortical/MEA) as modality synonyms.\n  - This block is required to prevent drift into noninvasive motor-BCI EEG literature.\n\n### Block D: Decoding pipeline / machine-learning-based signal processing for control\n- Concept Role: Captures the methodological focus on acquisition → preprocessing → feature extraction → decoding/ML for (often online) control, distinguishing from purely descriptive motor physiology.\n- Normalized Search Terms:\n  - “signal acquisition” (in BCI context)\n  - preprocessing / “artifact removal” / “filtering”\n  - “feature extraction” / “feature selection”\n  - “machine learning” / “classification” / “regression”\n  - “decoder” / “decoding algorithm” / “neural decoding”\n  - “real-time decoding” / “online decoding”\n- Notes on Term Usage:\n  - Many relevant papers emphasize “decoder” or “neural decoding” without listing pipeline steps; include both pipeline-step terms and generic decoding/ML terms.\n  - Keep this block separate from the BCI block to retain papers that present decoding methods for motor control signals from intracranial recordings even if “BCI” is not foregrounded in title/abstract.\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously address (A) motor BCI/neural prosthetic control, (B) motor intention/movement decoding targets, (C) invasive intracranial electrophysiological recordings (e.g., ECoG/iEEG), and (D) decoding/ML signal-processing methods enabling (often real-time) control.\n\n## Scope Control\n- In-scope:\n  - Motor BCIs/BMIs using invasive intracranial electrophysiology (ECoG/iEEG/sEEG and closely aligned intracranial electrophysiology) to decode movement intention/kinematics for real-time/online control of cursors, prostheses, or robots, including work on preprocessing, feature extraction, and ML decoding.\n  - Human or animal datasets used to evaluate such invasive motor-decoding BCI systems.\n- Out-of-scope:\n  - Noninvasive motor BCIs (scalp EEG, MEG, fNIRS) without intracranial recordings.\n  - BCIs not centered on motor intention/movement (e.g., communication/spelling, sensory decoding, affect/cognition) even if invasive.\n  - Pure motor neurophysiology studies using intracranial recordings that do not involve decoding/ML for control (i.e., no BCI/neural prosthesis control framing and no decoder development/evaluation).\n  - Non-electrophysiological invasive modalities (e.g., fMRI-based control) and non-brain signals (e.g., EMG-only control).\n-- current framework end --\n\nuser_additional_info (user's adjustment request):\n\"\"\"Remove the term 'cursor control' from block A.\"\"\"\n\nYou must follow these rules strictly:\n\n1. Base the updated framework on BOTH the current framework AND the user's adjustment request.\n   - Preserve valid parts of the current framework that are not contradicted by the user's input.\n   - Incorporate the user's adjustments, clarifications, or modifications.\n   - Do NOT introduce entirely new research goals or domains that are not mentioned in either the current framework or user input.\n\n2. The output must define a SMALL NUMBER of concept blocks (typically 2–4).\n   - Each block represents a distinct and independently searchable conceptual dimension\n     that should not be merged with other dimensions if doing so would reduce recall.\n   - Examples include: research task, technical field/framing, data modality.\n   - All blocks together must uniquely define ONE narrow research field.\n\nIMPORTANT — Concept Block Separation Rule:\n\nWhen constructing concept blocks, prioritize retrieval independence over semantic compactness.\n\nIf two concepts frequently appear separately in relevant literature\n(e.g., one may be mentioned without the other in titles/abstracts),\nthey MUST be placed in separate concept blocks,\neven if they form a well-known combined phrase or subfield name.\n\nExample:\n- \"speech\" and \"brain-computer interface\" must be separate blocks,\n  because many relevant papers mention speech decoding without explicitly using \"BCI\",\n  and others mention BCI without explicitly using \"speech\".\n\n3. Each concept block must:\n   - Contain only terms that are conceptually equivalent within that block.\n   - Be expressed using terminology commonly found in academic databases.\n   - Include common synonyms, abbreviations, and canonical terms used in the literature.\n\n4. When the user input or current framework uses abstract or high-level language, normalize it into concrete, database-searchable concepts\n   ONLY when such normalization is standard practice in the field.\n   - Example: \"invasive recordings\" → ECoG, sEEG, intracortical recordings, MEA\n   - Do NOT introduce loosely related or adjacent techniques.\n\n5. All concept blocks must be REQUIRED.\n   - The framework should be designed for exhaustive retrieval within a specific field,\n     not for exploratory or cross-domain search.\n\n6. Do NOT generate executable Boolean queries.\n   - You MAY describe the logical relationship between blocks conceptually\n     (e.g., \"documents must address all blocks simultaneously\"),\n     but do not use database syntax.\n\n7. Explicitly prevent topic drift.\n   - The framework should clearly exclude adjacent but distinct research areas.\n\n### Output Format (must follow exactly):\n\n## Conceptual Retrieval Framework\n\n### Block A: [Concept Block Name]\n- Concept Role:\n- Normalized Search Terms:\n- Notes on Term Usage:\n\n### Block B: [Concept Block Name]\n- Concept Role:\n- Normalized Search Terms:\n- Notes on Term Usage:\n\n(Repeat blocks as needed)\n\n## Conceptual Combination Rule\nA single sentence explaining how all blocks jointly define the target literature set.\n\n## Scope Control\n- In-scope:\n- Out-of-scope:\n\n"}
{"ts": "2026-01-21T22:59:33.001821+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "## Conceptual Retrieval Framework\n\n### Block A: Motor brain–computer interface / neural prosthetic control (motor intention → device control)\n- Concept Role: Anchors retrieval to BCI/neural interface systems aimed at motor intention decoding for controlling an external effector (prosthesis/robot) rather than general neuroscience decoding.\n- Normalized Search Terms:\n  - “brain-computer interface” / “brain–computer interface” / BCI\n  - “brain-machine interface” / “brain–machine interface” / BMI\n  - “neural prosthesis” / “neuroprosthesis” / “neural prosthetic”\n  - “neural interface” (in the context of control/BCI)\n  - “prosthetic control” / “prosthesis control”\n  - “robotic control” / “robot control” (as BCI output)\n  - “closed-loop” (when used to describe BCI control)\n  - “real-time” (when used to describe online BCI control)\n- Notes on Term Usage:\n  - Many relevant papers use BMI instead of BCI; others foreground “neural prosthesis” or prosthesis/robot control without saying BCI explicitly—treat these as equivalents within this block.\n  - “Closed-loop” and “real-time” are often descriptors of BCI operation; include them only as supporting terms, not as a substitute for BCI/BMI/prosthesis-control framing.\n  - Per user adjustment: remove “cursor control” from this block.\n\n### Block B: Motor intention / movement-related decoding target\n- Concept Role: Ensures the decoded content is motor-related (movement intention/kinematics/motor commands) rather than other cognitive or sensory targets.\n- Normalized Search Terms:\n  - “movement intention” / “motor intention” / “intended movement”\n  - “motor decoding” / “movement decoding”\n  - “motor imagery” (when used as a control signal for motor BCI)\n  - “reach” / “reaching” (as a decoded/controlled movement)\n  - “grasp” / “hand movement” / “arm movement”\n  - “kinematics” / “trajectory” (as decoded variables)\n  - “motor-related neural activity” / “motor cortical activity”\n- Notes on Term Usage:\n  - Some studies describe the target as kinematics/trajectory rather than “intention”; both should be treated as motor-decoding targets.\n  - Keep separate from the BCI block because some papers emphasize “motor decoding” without explicitly labeling the system as a BCI, and vice versa.\n\n### Block C: Invasive intracranial electrophysiological recording modality\n- Concept Role: Restricts retrieval to invasive brain recordings (intracranial electrophysiology) rather than noninvasive EEG/MEG/fNIRS.\n- Normalized Search Terms:\n  - “electrocorticography” / ECoG\n  - “intracranial EEG” / iEEG / “intracranial electroencephalography”\n  - “stereoelectroencephalography” / sEEG / SEEG\n  - “intracranial recording*” / “invasive recording*”\n  - “local field potential*” / LFP (when explicitly intracranial)\n  - “intracortical recording*” / “microelectrode array” / MEA (if described as invasive electrophysiology)\n- Notes on Term Usage:\n  - Include closely aligned intracranial electrophysiology labels commonly used in databases (iEEG, sEEG, LFP, intracortical/MEA) as modality synonyms.\n  - This block is required to prevent drift into noninvasive motor-BCI EEG literature.\n\n### Block D: Decoding pipeline / machine-learning-based signal processing for control\n- Concept Role: Captures the methodological focus on preprocessing → feature extraction → decoding/ML enabling (often online) control, distinguishing from purely descriptive motor physiology.\n- Normalized Search Terms:\n  - preprocessing / “artifact removal” / “filtering”\n  - “feature extraction” / “feature selection”\n  - “machine learning” / “classification” / “regression”\n  - “decoder” / “decoding algorithm” / “neural decoding”\n  - “real-time decoding” / “online decoding”\n- Notes on Term Usage:\n  - Many relevant papers emphasize “decoder” or “neural decoding” without listing pipeline steps; include both pipeline-step terms and generic decoding/ML terms.\n  - Keep separate from the BCI block to retain papers that present decoding methods for motor control signals from intracranial recordings even if “BCI” is not foregrounded in title/abstract.\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously address motor BCI/neural prosthetic control, motor intention/movement decoding targets, invasive intracranial electrophysiological recordings, and decoding/ML signal-processing methods enabling control.\n\n## Scope Control\n- In-scope:\n  - Motor BCIs/BMIs using invasive intracranial electrophysiology (ECoG/iEEG/sEEG and closely aligned intracranial electrophysiology) to decode movement intention/kinematics for real-time/online control of prostheses or robots, including work on preprocessing, feature extraction, and ML decoding.\n  - Human or animal datasets used to evaluate such invasive motor-decoding BCI systems.\n- Out-of-scope:\n  - Noninvasive motor BCIs (scalp EEG, MEG, fNIRS) without intracranial recordings.\n  - BCIs not centered on motor intention/movement (e.g., communication/spelling, sensory decoding, affect/cognition) even if invasive.\n  - Pure motor neurophysiology studies using intracranial recordings that do not involve decoding/ML for control (i.e., no BCI/neural prosthesis control framing and no decoder development/evaluation).\n  - Non-electrophysiological invasive modalities (e.g., fMRI-based control) and non-brain signals (e.g., EMG-only control).", "project_id": "6af7ac1b6254", "run_id": "a0ed3ea2b2ed", "step": "adjust_framework"}
{"ts": "2026-01-21T22:59:33.002436+00:00", "event": "phase1.adjust_framework.response", "project_id": "6af7ac1b6254", "run_id": "a0ed3ea2b2ed", "model": "gpt-5.2", "response": "## Conceptual Retrieval Framework\n\n### Block A: Motor brain–computer interface / neural prosthetic control (motor intention → device control)\n- Concept Role: Anchors retrieval to BCI/neural interface systems aimed at motor intention decoding for controlling an external effector (prosthesis/robot) rather than general neuroscience decoding.\n- Normalized Search Terms:\n  - “brain-computer interface” / “brain–computer interface” / BCI\n  - “brain-machine interface” / “brain–machine interface” / BMI\n  - “neural prosthesis” / “neuroprosthesis” / “neural prosthetic”\n  - “neural interface” (in the context of control/BCI)\n  - “prosthetic control” / “prosthesis control”\n  - “robotic control” / “robot control” (as BCI output)\n  - “closed-loop” (when used to describe BCI control)\n  - “real-time” (when used to describe online BCI control)\n- Notes on Term Usage:\n  - Many relevant papers use BMI instead of BCI; others foreground “neural prosthesis” or prosthesis/robot control without saying BCI explicitly—treat these as equivalents within this block.\n  - “Closed-loop” and “real-time” are often descriptors of BCI operation; include them only as supporting terms, not as a substitute for BCI/BMI/prosthesis-control framing.\n  - Per user adjustment: remove “cursor control” from this block.\n\n### Block B: Motor intention / movement-related decoding target\n- Concept Role: Ensures the decoded content is motor-related (movement intention/kinematics/motor commands) rather than other cognitive or sensory targets.\n- Normalized Search Terms:\n  - “movement intention” / “motor intention” / “intended movement”\n  - “motor decoding” / “movement decoding”\n  - “motor imagery” (when used as a control signal for motor BCI)\n  - “reach” / “reaching” (as a decoded/controlled movement)\n  - “grasp” / “hand movement” / “arm movement”\n  - “kinematics” / “trajectory” (as decoded variables)\n  - “motor-related neural activity” / “motor cortical activity”\n- Notes on Term Usage:\n  - Some studies describe the target as kinematics/trajectory rather than “intention”; both should be treated as motor-decoding targets.\n  - Keep separate from the BCI block because some papers emphasize “motor decoding” without explicitly labeling the system as a BCI, and vice versa.\n\n### Block C: Invasive intracranial electrophysiological recording modality\n- Concept Role: Restricts retrieval to invasive brain recordings (intracranial electrophysiology) rather than noninvasive EEG/MEG/fNIRS.\n- Normalized Search Terms:\n  - “electrocorticography” / ECoG\n  - “intracranial EEG” / iEEG / “intracranial electroencephalography”\n  - “stereoelectroencephalography” / sEEG / SEEG\n  - “intracranial recording*” / “invasive recording*”\n  - “local field potential*” / LFP (when explicitly intracranial)\n  - “intracortical recording*” / “microelectrode array” / MEA (if described as invasive electrophysiology)\n- Notes on Term Usage:\n  - Include closely aligned intracranial electrophysiology labels commonly used in databases (iEEG, sEEG, LFP, intracortical/MEA) as modality synonyms.\n  - This block is required to prevent drift into noninvasive motor-BCI EEG literature.\n\n### Block D: Decoding pipeline / machine-learning-based signal processing for control\n- Concept Role: Captures the methodological focus on preprocessing → feature extraction → decoding/ML enabling (often online) control, distinguishing from purely descriptive motor physiology.\n- Normalized Search Terms:\n  - preprocessing / “artifact removal” / “filtering”\n  - “feature extraction” / “feature selection”\n  - “machine learning” / “classification” / “regression”\n  - “decoder” / “decoding algorithm” / “neural decoding”\n  - “real-time decoding” / “online decoding”\n- Notes on Term Usage:\n  - Many relevant papers emphasize “decoder” or “neural decoding” without listing pipeline steps; include both pipeline-step terms and generic decoding/ML terms.\n  - Keep separate from the BCI block to retain papers that present decoding methods for motor control signals from intracranial recordings even if “BCI” is not foregrounded in title/abstract.\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously address motor BCI/neural prosthetic control, motor intention/movement decoding targets, invasive intracranial electrophysiological recordings, and decoding/ML signal-processing methods enabling control.\n\n## Scope Control\n- In-scope:\n  - Motor BCIs/BMIs using invasive intracranial electrophysiology (ECoG/iEEG/sEEG and closely aligned intracranial electrophysiology) to decode movement intention/kinematics for real-time/online control of prostheses or robots, including work on preprocessing, feature extraction, and ML decoding.\n  - Human or animal datasets used to evaluate such invasive motor-decoding BCI systems.\n- Out-of-scope:\n  - Noninvasive motor BCIs (scalp EEG, MEG, fNIRS) without intracranial recordings.\n  - BCIs not centered on motor intention/movement (e.g., communication/spelling, sensory decoding, affect/cognition) even if invasive.\n  - Pure motor neurophysiology studies using intracranial recordings that do not involve decoding/ML for control (i.e., no BCI/neural prosthesis control framing and no decoder development/evaluation).\n  - Non-electrophysiological invasive modalities (e.g., fMRI-based control) and non-brain signals (e.g., EMG-only control)."}
{"ts": "2026-01-21T23:02:48.907583+00:00", "event": "phase1.query_build.prompt", "project_id": "6af7ac1b6254", "run_id": "a0ed3ea2b2ed", "model": "gpt-5.2", "reasoning_effort": "high", "prompt": "You are an expert biomedical information retrieval engineer specializing in PubMed search strategies.\n\nBelow is a Conceptual Retrieval Framework, your task is to convert the framework into one or more executable PubMed search queries.\n\n-- Conceptual Retrieval Framework begin --\n## Conceptual Retrieval Framework\n\n### Block A: Motor brain–computer interface / neural prosthetic control (motor intention → device control)\n- Concept Role: Anchors retrieval to BCI/neural interface systems aimed at motor intention decoding for controlling an external effector (prosthesis/robot) rather than general neuroscience decoding.\n- Normalized Search Terms:\n  - “brain-computer interface” / “brain–computer interface” / BCI\n  - “brain-machine interface” / “brain–machine interface” / BMI\n  - “neural prosthesis” / “neuroprosthesis” / “neural prosthetic”\n  - “neural interface” (in the context of control/BCI)\n  - “prosthetic control” / “prosthesis control”\n  - “robotic control” / “robot control” (as BCI output)\n  - “closed-loop” (when used to describe BCI control)\n  - “real-time” (when used to describe online BCI control)\n- Notes on Term Usage:\n  - Many relevant papers use BMI instead of BCI; others foreground “neural prosthesis” or prosthesis/robot control without saying BCI explicitly—treat these as equivalents within this block.\n  - “Closed-loop” and “real-time” are often descriptors of BCI operation; include them only as supporting terms, not as a substitute for BCI/BMI/prosthesis-control framing.\n  - Per user adjustment: remove “cursor control” from this block.\n\n### Block B: Motor intention / movement-related decoding target\n- Concept Role: Ensures the decoded content is motor-related (movement intention/kinematics/motor commands) rather than other cognitive or sensory targets.\n- Normalized Search Terms:\n  - “movement intention” / “motor intention” / “intended movement”\n  - “motor decoding” / “movement decoding”\n  - “motor imagery” (when used as a control signal for motor BCI)\n  - “reach” / “reaching” (as a decoded/controlled movement)\n  - “grasp” / “hand movement” / “arm movement”\n  - “kinematics” / “trajectory” (as decoded variables)\n  - “motor-related neural activity” / “motor cortical activity”\n- Notes on Term Usage:\n  - Some studies describe the target as kinematics/trajectory rather than “intention”; both should be treated as motor-decoding targets.\n  - Keep separate from the BCI block because some papers emphasize “motor decoding” without explicitly labeling the system as a BCI, and vice versa.\n\n### Block C: Invasive intracranial electrophysiological recording modality\n- Concept Role: Restricts retrieval to invasive brain recordings (intracranial electrophysiology) rather than noninvasive EEG/MEG/fNIRS.\n- Normalized Search Terms:\n  - “electrocorticography” / ECoG\n  - “intracranial EEG” / iEEG / “intracranial electroencephalography”\n  - “stereoelectroencephalography” / sEEG / SEEG\n  - “intracranial recording*” / “invasive recording*”\n  - “local field potential*” / LFP (when explicitly intracranial)\n  - “intracortical recording*” / “microelectrode array” / MEA (if described as invasive electrophysiology)\n- Notes on Term Usage:\n  - Include closely aligned intracranial electrophysiology labels commonly used in databases (iEEG, sEEG, LFP, intracortical/MEA) as modality synonyms.\n  - This block is required to prevent drift into noninvasive motor-BCI EEG literature.\n\n### Block D: Decoding pipeline / machine-learning-based signal processing for control\n- Concept Role: Captures the methodological focus on preprocessing → feature extraction → decoding/ML enabling (often online) control, distinguishing from purely descriptive motor physiology.\n- Normalized Search Terms:\n  - preprocessing / “artifact removal” / “filtering”\n  - “feature extraction” / “feature selection”\n  - “machine learning” / “classification” / “regression”\n  - “decoder” / “decoding algorithm” / “neural decoding”\n  - “real-time decoding” / “online decoding”\n- Notes on Term Usage:\n  - Many relevant papers emphasize “decoder” or “neural decoding” without listing pipeline steps; include both pipeline-step terms and generic decoding/ML terms.\n  - Keep separate from the BCI block to retain papers that present decoding methods for motor control signals from intracranial recordings even if “BCI” is not foregrounded in title/abstract.\n\n## Conceptual Combination Rule\nRetrieve documents that simultaneously address motor BCI/neural prosthetic control, motor intention/movement decoding targets, invasive intracranial electrophysiological recordings, and decoding/ML signal-processing methods enabling control.\n\n## Scope Control\n- In-scope:\n  - Motor BCIs/BMIs using invasive intracranial electrophysiology (ECoG/iEEG/sEEG and closely aligned intracranial electrophysiology) to decode movement intention/kinematics for real-time/online control of prostheses or robots, including work on preprocessing, feature extraction, and ML decoding.\n  - Human or animal datasets used to evaluate such invasive motor-decoding BCI systems.\n- Out-of-scope:\n  - Noninvasive motor BCIs (scalp EEG, MEG, fNIRS) without intracranial recordings.\n  - BCIs not centered on motor intention/movement (e.g., communication/spelling, sensory decoding, affect/cognition) even if invasive.\n  - Pure motor neurophysiology studies using intracranial recordings that do not involve decoding/ML for control (i.e., no BCI/neural prosthesis control framing and no decoder development/evaluation).\n  - Non-electrophysiological invasive modalities (e.g., fMRI-based control) and non-brain signals (e.g., EMG-only control).\n-- Conceptual Retrieval Framework end --\n\n\nYou must follow these rules strictly:\n\n1. Do NOT reinterpret, merge, or split any concept blocks.\n   - Treat each concept block as an independent retrieval dimension.\n   - Preserve the block structure exactly as given.\n\n2. For each concept block:\n   - Combine all normalized search terms within that block using OR.\n   - Apply PubMed field tags consistently, using Title/Abstract fields\n     unless a term is a standard abbreviation or acronym.\n\n3. Across concept blocks:\n   - Combine blocks using AND.\n   - The final query must require that all blocks are satisfied simultaneously.\n\n4. Do NOT introduce new search terms, synonyms, or expansions.\n   - Use ONLY the terms explicitly listed in the framework.\n\n5. Phrase handling:\n   - Multi-word terms must be enclosed in double quotation marks.\n   - Singular/plural variations should be preserved as given; do not infer new ones.\n\n6. PubMed field usage:\n   - Use [Title/Abstract] for most terms.\n   - Acronyms (e.g., BCI, ECoG, iEEG) may be used without field tags\n     only if they are standard and unambiguous.\n   - Do NOT use MeSH terms in this step.\n\n7. If a block contains usage constraints (e.g., “only when paired with X”),\n   enforce this by block-level AND logic, not by modifying individual terms.\n\n8. Output formatting:\n   - Clearly label each block’s query segment.\n   - Provide the final combined PubMed query in a single code block.\n   - Do NOT include explanatory text outside the required output format.\n\n### Output Format (must follow exactly):\n\n## PubMed Query Blocks\n\n### Block A Query\n(query text)\n\n### Block B Query\n(query text)\n\n(Repeat for each block)\n\n## Final Combined PubMed Query\n```text\n(full PubMed query)\n"}
{"ts": "2026-01-21T23:03:04.511671+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "## PubMed Query Blocks\n\n### Block A Query\n(\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR \"brain–machine interface\"[Title/Abstract] OR BMI OR \"neural prosthesis\"[Title/Abstract] OR \"neuroprosthesis\"[Title/Abstract] OR \"neural prosthetic\"[Title/Abstract] OR \"neural interface\"[Title/Abstract] OR \"prosthetic control\"[Title/Abstract] OR \"prosthesis control\"[Title/Abstract] OR \"robotic control\"[Title/Abstract] OR \"robot control\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"real-time\"[Title/Abstract])\n\n### Block B Query\n(\"movement intention\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract] OR \"reach\"[Title/Abstract] OR \"reaching\"[Title/Abstract] OR \"grasp\"[Title/Abstract] OR \"hand movement\"[Title/Abstract] OR \"arm movement\"[Title/Abstract] OR \"kinematics\"[Title/Abstract] OR \"trajectory\"[Title/Abstract] OR \"motor-related neural activity\"[Title/Abstract] OR \"motor cortical activity\"[Title/Abstract])\n\n### Block C Query\n(\"electrocorticography\"[Title/Abstract] OR ECoG OR \"intracranial EEG\"[Title/Abstract] OR iEEG OR \"intracranial electroencephalography\"[Title/Abstract] OR \"stereoelectroencephalography\"[Title/Abstract] OR sEEG OR SEEG OR \"intracranial recording*\"[Title/Abstract] OR \"invasive recording*\"[Title/Abstract] OR \"local field potential*\"[Title/Abstract] OR LFP OR \"intracortical recording*\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA)\n\n### Block D Query\n(preprocessing[Title/Abstract] OR \"artifact removal\"[Title/Abstract] OR \"filtering\"[Title/Abstract] OR \"feature extraction\"[Title/Abstract] OR \"feature selection\"[Title/Abstract] OR \"machine learning\"[Title/Abstract] OR \"classification\"[Title/Abstract] OR \"regression\"[Title/Abstract] OR \"decoder\"[Title/Abstract] OR \"decoding algorithm\"[Title/Abstract] OR \"neural decoding\"[Title/Abstract] OR \"real-time decoding\"[Title/Abstract] OR \"online decoding\"[Title/Abstract])\n\n## Final Combined PubMed Query\n```text\n((\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR \"brain–machine interface\"[Title/Abstract] OR BMI OR \"neural prosthesis\"[Title/Abstract] OR \"neuroprosthesis\"[Title/Abstract] OR \"neural prosthetic\"[Title/Abstract] OR \"neural interface\"[Title/Abstract] OR \"prosthetic control\"[Title/Abstract] OR \"prosthesis control\"[Title/Abstract] OR \"robotic control\"[Title/Abstract] OR \"robot control\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"real-time\"[Title/Abstract])\nAND\n(\"movement intention\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract] OR \"reach\"[Title/Abstract] OR \"reaching\"[Title/Abstract] OR \"grasp\"[Title/Abstract] OR \"hand movement\"[Title/Abstract] OR \"arm movement\"[Title/Abstract] OR \"kinematics\"[Title/Abstract] OR \"trajectory\"[Title/Abstract] OR \"motor-related neural activity\"[Title/Abstract] OR \"motor cortical activity\"[Title/Abstract])\nAND\n(\"electrocorticography\"[Title/Abstract] OR ECoG OR \"intracranial EEG\"[Title/Abstract] OR iEEG OR \"intracranial electroencephalography\"[Title/Abstract] OR \"stereoelectroencephalography\"[Title/Abstract] OR sEEG OR SEEG OR \"intracranial recording*\"[Title/Abstract] OR \"invasive recording*\"[Title/Abstract] OR \"local field potential*\"[Title/Abstract] OR LFP OR \"intracortical recording*\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA)\nAND\n(preprocessing[Title/Abstract] OR \"artifact removal\"[Title/Abstract] OR \"filtering\"[Title/Abstract] OR \"feature extraction\"[Title/Abstract] OR \"feature selection\"[Title/Abstract] OR \"machine learning\"[Title/Abstract] OR \"classification\"[Title/Abstract] OR \"regression\"[Title/Abstract] OR \"decoder\"[Title/Abstract] OR \"decoding algorithm\"[Title/Abstract] OR \"neural decoding\"[Title/Abstract] OR \"real-time decoding\"[Title/Abstract] OR \"online decoding\"[Title/Abstract]))\n```", "project_id": "6af7ac1b6254", "run_id": "a0ed3ea2b2ed", "step": "query_build"}
{"ts": "2026-01-21T23:03:04.512000+00:00", "event": "phase1.query_build.response", "project_id": "6af7ac1b6254", "run_id": "a0ed3ea2b2ed", "model": "gpt-5.2", "response": "## PubMed Query Blocks\n\n### Block A Query\n(\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR \"brain–machine interface\"[Title/Abstract] OR BMI OR \"neural prosthesis\"[Title/Abstract] OR \"neuroprosthesis\"[Title/Abstract] OR \"neural prosthetic\"[Title/Abstract] OR \"neural interface\"[Title/Abstract] OR \"prosthetic control\"[Title/Abstract] OR \"prosthesis control\"[Title/Abstract] OR \"robotic control\"[Title/Abstract] OR \"robot control\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"real-time\"[Title/Abstract])\n\n### Block B Query\n(\"movement intention\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract] OR \"reach\"[Title/Abstract] OR \"reaching\"[Title/Abstract] OR \"grasp\"[Title/Abstract] OR \"hand movement\"[Title/Abstract] OR \"arm movement\"[Title/Abstract] OR \"kinematics\"[Title/Abstract] OR \"trajectory\"[Title/Abstract] OR \"motor-related neural activity\"[Title/Abstract] OR \"motor cortical activity\"[Title/Abstract])\n\n### Block C Query\n(\"electrocorticography\"[Title/Abstract] OR ECoG OR \"intracranial EEG\"[Title/Abstract] OR iEEG OR \"intracranial electroencephalography\"[Title/Abstract] OR \"stereoelectroencephalography\"[Title/Abstract] OR sEEG OR SEEG OR \"intracranial recording*\"[Title/Abstract] OR \"invasive recording*\"[Title/Abstract] OR \"local field potential*\"[Title/Abstract] OR LFP OR \"intracortical recording*\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA)\n\n### Block D Query\n(preprocessing[Title/Abstract] OR \"artifact removal\"[Title/Abstract] OR \"filtering\"[Title/Abstract] OR \"feature extraction\"[Title/Abstract] OR \"feature selection\"[Title/Abstract] OR \"machine learning\"[Title/Abstract] OR \"classification\"[Title/Abstract] OR \"regression\"[Title/Abstract] OR \"decoder\"[Title/Abstract] OR \"decoding algorithm\"[Title/Abstract] OR \"neural decoding\"[Title/Abstract] OR \"real-time decoding\"[Title/Abstract] OR \"online decoding\"[Title/Abstract])\n\n## Final Combined PubMed Query\n```text\n((\"brain-computer interface\"[Title/Abstract] OR \"brain–computer interface\"[Title/Abstract] OR BCI OR \"brain-machine interface\"[Title/Abstract] OR \"brain–machine interface\"[Title/Abstract] OR BMI OR \"neural prosthesis\"[Title/Abstract] OR \"neuroprosthesis\"[Title/Abstract] OR \"neural prosthetic\"[Title/Abstract] OR \"neural interface\"[Title/Abstract] OR \"prosthetic control\"[Title/Abstract] OR \"prosthesis control\"[Title/Abstract] OR \"robotic control\"[Title/Abstract] OR \"robot control\"[Title/Abstract] OR \"closed-loop\"[Title/Abstract] OR \"real-time\"[Title/Abstract])\nAND\n(\"movement intention\"[Title/Abstract] OR \"motor intention\"[Title/Abstract] OR \"intended movement\"[Title/Abstract] OR \"motor decoding\"[Title/Abstract] OR \"movement decoding\"[Title/Abstract] OR \"motor imagery\"[Title/Abstract] OR \"reach\"[Title/Abstract] OR \"reaching\"[Title/Abstract] OR \"grasp\"[Title/Abstract] OR \"hand movement\"[Title/Abstract] OR \"arm movement\"[Title/Abstract] OR \"kinematics\"[Title/Abstract] OR \"trajectory\"[Title/Abstract] OR \"motor-related neural activity\"[Title/Abstract] OR \"motor cortical activity\"[Title/Abstract])\nAND\n(\"electrocorticography\"[Title/Abstract] OR ECoG OR \"intracranial EEG\"[Title/Abstract] OR iEEG OR \"intracranial electroencephalography\"[Title/Abstract] OR \"stereoelectroencephalography\"[Title/Abstract] OR sEEG OR SEEG OR \"intracranial recording*\"[Title/Abstract] OR \"invasive recording*\"[Title/Abstract] OR \"local field potential*\"[Title/Abstract] OR LFP OR \"intracortical recording*\"[Title/Abstract] OR \"microelectrode array\"[Title/Abstract] OR MEA)\nAND\n(preprocessing[Title/Abstract] OR \"artifact removal\"[Title/Abstract] OR \"filtering\"[Title/Abstract] OR \"feature extraction\"[Title/Abstract] OR \"feature selection\"[Title/Abstract] OR \"machine learning\"[Title/Abstract] OR \"classification\"[Title/Abstract] OR \"regression\"[Title/Abstract] OR \"decoder\"[Title/Abstract] OR \"decoding algorithm\"[Title/Abstract] OR \"neural decoding\"[Title/Abstract] OR \"real-time decoding\"[Title/Abstract] OR \"online decoding\"[Title/Abstract]))\n```"}
{"ts": "2026-01-22T21:42:12.258896+00:00", "event": "parse.stage1.prompt", "project_id": "3b9280a68d3d", "run_id": "7b46881b0439", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage1_understanding.md", "prompt": "你是“研究描述理解与规范化”模块。输入是一段纯文本候选研究描述。你的目标是帮助用户把研究描述变得合理且清晰，便于后续生成文献检索查询。\n\n你必须完成：\n1) 判断这段描述是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true.\n2) 如果是研究描述,进行常识可行性判断（plausibility_level）：\n- A_impossible：明显荒诞/违背当前科技常识（无法形成合理检索任务）\n- B_plausible：合理可行\n3) 如果合理可行，给出你对该研究描述的“当前理解”（normalized_understanding），用规范化、聚焦、可检索的英语重写，\n4) 判断当前理解是否已经清晰到可以用于检索；若不清晰，列出你仍不确定的点（疑问清单），并提出最多3个澄清问题（问题必须具体可回答）。\n5) 输出结构化提要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n6) 只输出JSON，不输出任何额外文本。\n\n候选研究描述：\n\"\"\"I focus on the brain-computer interface.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n}\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - ncertainties/missing_fields/suggested_questions为空数组[];\n  - structured_summary为全null；\n- normalized_understanding：300-600个英文字符，必须是你对研究的“当前理解”，语言规范、聚焦、可检索；不要写“我认为/可能”等口水话，直接用陈述句组织。\n\n- 如果 是B_plausible，且 is_clear_for_search=true，则：\n  - is_research_description = true\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空数组或只保留0-1条轻微风险\n\n- 如果 是B_plausible，且 is_clear_for_search=false，则：\n  - is_research_description = true\n  - uncertainties 至少2条\n  - missing_fields 仅列出缺失项\n  - suggested_questions 为1-3条，必须与 uncertainties/missing_fields 对应\n\n- 如果 plausibility_level=A_impossible，则：\n  - is_clear_for_search=false\n  - suggested_questions 为空\n  - uncertainties <=200英文字符：给出impossible的原因。\n"}
{"ts": "2026-01-22T21:42:22.506484+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"The research concerns brain–computer interfaces (BCIs), i.e., systems that acquire neural signals and translate them into commands for external devices or provide feedback to the brain. It includes BCI signal acquisition (EEG/ECoG/implants), signal processing and decoding, real-time closed-loop control, and evaluation in human or animal users for communication, motor restoration, or neurorehabilitation applications.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces / neuroengineering\",\n    \"task\": \"Neural signal decoding and real-time control/communication via BCI\",\n    \"subject_system\": \"Humans or animals using EEG/ECoG/intracortical recordings with external devices\",\n    \"methods\": \"Neural signal acquisition, preprocessing, feature extraction, machine learning decoding, closed-loop control, user evaluation\",\n    \"scope\": \"General BCI research; modality and application not specified\",\n    \"intent\": \"Enable device control/communication or therapeutic feedback using neural activity\",\n    \"exclusions\": null\n  },\n  \"uncertainties\": [\n    \"BCI modality is unspecified (noninvasive EEG vs invasive ECoG/intracortical), which strongly affects keywords and venues.\",\n    \"Target application and output device are unclear (communication speller, prosthetic control, rehabilitation, gaming), limiting query focus.\",\n    \"Methodological emphasis is not stated (deep learning decoding, adaptive/transfer learning, stimulation/closed-loop neuromodulation, usability/ethics).\"\n  ],\n  \"missing_fields\": [\n    \"scope\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which BCI modality is your focus: noninvasive (EEG/MEG/fNIRS) or invasive (ECoG/intracortical), and in what setting (lab vs clinical)?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"What is the primary application/output: communication (P300/SSVEP speller), motor/prosthetic control, neurorehabilitation, or closed-loop neuromodulation?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What methods are central to your work: signal processing features, classical ML, deep learning, adaptive/transfer learning, or human factors/usability evaluation?\"\n    }\n  ]\n}", "project_id": "3b9280a68d3d", "run_id": "7b46881b0439", "stage": "stage1"}
{"ts": "2026-01-22T21:42:22.507291+00:00", "event": "parse.stage1.response", "project_id": "3b9280a68d3d", "run_id": "7b46881b0439", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"The research concerns brain–computer interfaces (BCIs), i.e., systems that acquire neural signals and translate them into commands for external devices or provide feedback to the brain. It includes BCI signal acquisition (EEG/ECoG/implants), signal processing and decoding, real-time closed-loop control, and evaluation in human or animal users for communication, motor restoration, or neurorehabilitation applications.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces / neuroengineering\",\n    \"task\": \"Neural signal decoding and real-time control/communication via BCI\",\n    \"subject_system\": \"Humans or animals using EEG/ECoG/intracortical recordings with external devices\",\n    \"methods\": \"Neural signal acquisition, preprocessing, feature extraction, machine learning decoding, closed-loop control, user evaluation\",\n    \"scope\": \"General BCI research; modality and application not specified\",\n    \"intent\": \"Enable device control/communication or therapeutic feedback using neural activity\",\n    \"exclusions\": null\n  },\n  \"uncertainties\": [\n    \"BCI modality is unspecified (noninvasive EEG vs invasive ECoG/intracortical), which strongly affects keywords and venues.\",\n    \"Target application and output device are unclear (communication speller, prosthetic control, rehabilitation, gaming), limiting query focus.\",\n    \"Methodological emphasis is not stated (deep learning decoding, adaptive/transfer learning, stimulation/closed-loop neuromodulation, usability/ethics).\"\n  ],\n  \"missing_fields\": [\n    \"scope\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which BCI modality is your focus: noninvasive (EEG/MEG/fNIRS) or invasive (ECoG/intracortical), and in what setting (lab vs clinical)?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"What is the primary application/output: communication (P300/SSVEP speller), motor/prosthetic control, neurorehabilitation, or closed-loop neuromodulation?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What methods are central to your work: signal processing features, classical ML, deep learning, adaptive/transfer learning, or human factors/usability evaluation?\"\n    }\n  ]\n}"}
{"ts": "2026-01-22T21:44:43.960758+00:00", "event": "parse.stage2.prompt", "project_id": "3b9280a68d3d", "run_id": "7b46881b0439", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage2_converge.md", "prompt": "你是“研究描述自我收敛器”。你将收到三段文本：\n(1) 当前候选研究描述 current_description\n(2) 关于当前研究描述的问题question_for_user\n(3) 用户本轮补充信息 user_additional_info（可能回答了你上轮的问题，也可能没有）\n\n你的任务是：\n1) 判断当前候选研究描述和用户本轮补充信息是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true，并将两段文本融合，形成你对研究内容的“当前理解”，并判断更新后的研究内容是否合理：\n- A_impossible：明显荒诞/违背当前科技常识，无法形成合理检索任务\n- B_plausible：合理可行\n2) 如果A_impossible，给出简单的理由。如果新的理解是合理可行的，就用规范、聚焦、可检索的英文重写（300-600英文字符），这段重写用于帮助用户组织语言与规范表述。\n3) 判断本轮补充的信息是否对解答question_for_user有帮助。有帮助的话就返回 is_helpful=true。\n4) 如果在新增信息后仍不清晰：输出你仍不确定的点（uncertainties），并提出最多3个澄清问题（具体可回答，优先信息增益最大）。\n5) 如果已经清晰：不要再提问题；只输出你的理解与结构化摘要。\n6) 输出结构化摘要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n只输出JSON，不输出任何额外文字。\n\ncurrent_description：\n\"\"\"I focus on the brain-computer interface.\"\"\"\n\nquestion_for_user：\n\"\"\"Which BCI modality is your focus: noninvasive (EEG/MEG/fNIRS) or invasive (ECoG/intracortical), and in what setting (lab vs clinical)?\nWhat is the primary application/output: communication (P300/SSVEP speller), motor/prosthetic control, neurorehabilitation, or closed-loop neuromodulation?\nWhat methods are central to your work: signal processing features, classical ML, deep learning, adaptive/transfer learning, or human factors/usability evaluation?\"\"\"\n\n\nuser_additional_info（用户本轮补充信息，可能为空）：\n\"\"\"There is no restriction on the modality, target application, output, or method.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"is_helpful\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n  }\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - 其他所有字段都为空。\n- normalized_understanding：300-600英文字符，必须是你融合两段文本后的“当前理解”，术语一致、范围聚焦。\n- 如果 plausibility_level=B_plausible且is_clear_for_search=true：\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空或最多1条轻微风险\n- 如果 plausibility_level=B_plausible且is_clear_for_search=false：\n  - uncertainties 至少2条\n  - suggested_questions 为1-3条，必须与uncertainties/missing_fields一致\n\n- 如果 plausibility_level=A_impossible：\n  - is_clear_for_search 必须为 false\n  - suggested_questions 必须为空数组\n  - uncertainties <=200英文字符：提示用户impossible的原因。\n"}
{"ts": "2026-01-22T21:44:52.262524+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": false,\n  \"normalized_understanding\": \"The research concerns brain–computer interfaces (BCIs) in a broad, modality-agnostic way, without committing to a specific recording approach (noninvasive or invasive), experimental setting (lab or clinical), target application (communication, motor control, rehabilitation, or closed-loop neuromodulation), or core methodology (signal processing, classical ML, deep learning, transfer/adaptive learning, or usability/human factors).\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces (BCI)\",\n    \"task\": null,\n    \"subject_system\": null,\n    \"methods\": null,\n    \"scope\": \"Modality-, application-, and method-agnostic BCI research\",\n    \"intent\": null,\n    \"exclusions\": null\n  },\n  \"uncertainties\": [\n    \"No specific BCI modality is specified, so relevant sensors, signals, and constraints are unclear.\",\n    \"No primary application/output is specified, preventing a focused problem statement and evaluation criteria.\",\n    \"No central methods are specified, so the technical contribution and searchable keywords are underspecified.\"\n  ],\n  \"missing_fields\": [\n    \"domain\",\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"What is the single primary BCI goal you want to optimize for (e.g., spelling/communication, prosthetic/motor control, neurorehabilitation, or closed-loop neuromodulation)?\"\n    },\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Which recording modality and setting will you assume for the core work (EEG/MEG/fNIRS vs ECoG/intracortical; lab vs clinical), and what participant population (healthy vs patient group)?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What methods are central to your contribution (feature engineering + classical ML, deep learning, transfer/adaptive learning, or human factors/usability), and what performance metrics matter most?\"\n    }\n  ]\n}", "project_id": "3b9280a68d3d", "run_id": "7b46881b0439", "stage": "stage2"}
{"ts": "2026-01-22T21:44:52.263313+00:00", "event": "parse.stage2.response", "project_id": "3b9280a68d3d", "run_id": "7b46881b0439", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_helpful\": false,\n  \"normalized_understanding\": \"The research concerns brain–computer interfaces (BCIs) in a broad, modality-agnostic way, without committing to a specific recording approach (noninvasive or invasive), experimental setting (lab or clinical), target application (communication, motor control, rehabilitation, or closed-loop neuromodulation), or core methodology (signal processing, classical ML, deep learning, transfer/adaptive learning, or usability/human factors).\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces (BCI)\",\n    \"task\": null,\n    \"subject_system\": null,\n    \"methods\": null,\n    \"scope\": \"Modality-, application-, and method-agnostic BCI research\",\n    \"intent\": null,\n    \"exclusions\": null\n  },\n  \"uncertainties\": [\n    \"No specific BCI modality is specified, so relevant sensors, signals, and constraints are unclear.\",\n    \"No primary application/output is specified, preventing a focused problem statement and evaluation criteria.\",\n    \"No central methods are specified, so the technical contribution and searchable keywords are underspecified.\"\n  ],\n  \"missing_fields\": [\n    \"domain\",\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"What is the single primary BCI goal you want to optimize for (e.g., spelling/communication, prosthetic/motor control, neurorehabilitation, or closed-loop neuromodulation)?\"\n    },\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Which recording modality and setting will you assume for the core work (EEG/MEG/fNIRS vs ECoG/intracortical; lab vs clinical), and what participant population (healthy vs patient group)?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What methods are central to your contribution (feature engineering + classical ML, deep learning, transfer/adaptive learning, or human factors/usability), and what performance metrics matter most?\"\n    }\n  ]\n}"}
{"ts": "2026-01-22T23:06:39.912746+00:00", "event": "parse.stage1.prompt", "project_id": "3b9280a68d3d", "run_id": "e9de860e934a", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage1_understanding.md", "prompt": "你是“研究描述理解与规范化”模块。输入是一段纯文本候选研究描述。你的目标是帮助用户把研究描述变得合理且清晰，便于后续生成文献检索查询。\n\n你必须完成：\n1) 判断这段描述是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true.\n2) 如果是研究描述,进行常识可行性判断（plausibility_level）：\n- A_impossible：明显荒诞/违背当前科技常识（无法形成合理检索任务）\n- B_plausible：合理可行\n3) 如果合理可行，给出你对该研究描述的“当前理解”（normalized_understanding），用规范化、聚焦、可检索的英语重写，\n4) 判断当前理解是否已经清晰到可以用于检索；若不清晰，列出你仍不确定的点（疑问清单），并提出最多3个澄清问题（问题必须具体可回答）。\n5) 输出结构化提要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n6) 只输出JSON，不输出任何额外文本。\n\n候选研究描述：\n\"\"\"I focus on brain-computer interface.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n}\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - ncertainties/missing_fields/suggested_questions为空数组[];\n  - structured_summary为全null；\n- normalized_understanding：300-600个英文字符，必须是你对研究的“当前理解”，语言规范、聚焦、可检索；不要写“我认为/可能”等口水话，直接用陈述句组织。\n\n- 如果 是B_plausible，且 is_clear_for_search=true，则：\n  - is_research_description = true\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空数组或只保留0-1条轻微风险\n\n- 如果 是B_plausible，且 is_clear_for_search=false，则：\n  - is_research_description = true\n  - uncertainties 至少2条\n  - missing_fields 仅列出缺失项\n  - suggested_questions 为1-3条，必须与 uncertainties/missing_fields 对应\n\n- 如果 plausibility_level=A_impossible，则：\n  - is_clear_for_search=false\n  - suggested_questions 为空\n  - uncertainties <=200英文字符：给出impossible的原因。\n"}
{"ts": "2026-01-22T23:06:52.005652+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"The research focuses on brain–computer interfaces (BCIs), i.e., systems that acquire neural signals and translate them into control commands for external devices or software. It concerns the end-to-end BCI pipeline, including neural signal acquisition (invasive or noninvasive), preprocessing, feature extraction, decoding/classification, and real-time feedback for communication, rehabilitation, or assistive control applications.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain-computer interfaces; neuroengineering; neural signal processing\",\n    \"task\": \"Decode neural activity into actionable commands for device/software control\",\n    \"subject_system\": \"Human users and BCI hardware/software (EEG/ECoG/implants; external devices)\",\n    \"methods\": \"Neural signal acquisition, preprocessing, feature extraction, machine learning/deep learning decoding, closed-loop control\",\n    \"scope\": \"Unspecified modality, application, population, and evaluation setting; general end-to-end BCI pipeline\",\n    \"intent\": \"Enable communication/control and improve assistive, rehabilitation, or interaction outcomes\",\n    \"exclusions\": null\n  },\n  \"uncertainties\": [\n    \"BCI modality is unspecified (EEG vs ECoG vs intracortical; noninvasive vs invasive).\",\n    \"Primary application and target population are unclear (communication, motor rehab, prosthetic control; healthy vs patients).\",\n    \"Methodological focus and evaluation criteria are not stated (algorithms, hardware, paradigms, datasets, metrics, real-time constraints).\"\n  ],\n  \"missing_fields\": [\n    \"scope\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which BCI modality and signal type is the focus (e.g., EEG, MEG, ECoG, intracortical spikes), and is it invasive or noninvasive?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"What is the main application scenario and user group (e.g., spelling/communication for ALS, stroke rehabilitation, prosthetic/robot control, gaming; patients vs healthy participants)?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What is the primary technical emphasis (e.g., decoding algorithms, adaptive/transfer learning, artifact removal, stimulation/closed-loop, hardware design), and what evaluation metrics matter (accuracy, ITR, latency, robustness)?\"\n    }\n  ]\n}", "project_id": "3b9280a68d3d", "run_id": "e9de860e934a", "stage": "stage1"}
{"ts": "2026-01-22T23:06:52.006087+00:00", "event": "parse.stage1.response", "project_id": "3b9280a68d3d", "run_id": "e9de860e934a", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"The research focuses on brain–computer interfaces (BCIs), i.e., systems that acquire neural signals and translate them into control commands for external devices or software. It concerns the end-to-end BCI pipeline, including neural signal acquisition (invasive or noninvasive), preprocessing, feature extraction, decoding/classification, and real-time feedback for communication, rehabilitation, or assistive control applications.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain-computer interfaces; neuroengineering; neural signal processing\",\n    \"task\": \"Decode neural activity into actionable commands for device/software control\",\n    \"subject_system\": \"Human users and BCI hardware/software (EEG/ECoG/implants; external devices)\",\n    \"methods\": \"Neural signal acquisition, preprocessing, feature extraction, machine learning/deep learning decoding, closed-loop control\",\n    \"scope\": \"Unspecified modality, application, population, and evaluation setting; general end-to-end BCI pipeline\",\n    \"intent\": \"Enable communication/control and improve assistive, rehabilitation, or interaction outcomes\",\n    \"exclusions\": null\n  },\n  \"uncertainties\": [\n    \"BCI modality is unspecified (EEG vs ECoG vs intracortical; noninvasive vs invasive).\",\n    \"Primary application and target population are unclear (communication, motor rehab, prosthetic control; healthy vs patients).\",\n    \"Methodological focus and evaluation criteria are not stated (algorithms, hardware, paradigms, datasets, metrics, real-time constraints).\"\n  ],\n  \"missing_fields\": [\n    \"scope\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"scope\",\n      \"question\": \"Which BCI modality and signal type is the focus (e.g., EEG, MEG, ECoG, intracortical spikes), and is it invasive or noninvasive?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"What is the main application scenario and user group (e.g., spelling/communication for ALS, stroke rehabilitation, prosthetic/robot control, gaming; patients vs healthy participants)?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What is the primary technical emphasis (e.g., decoding algorithms, adaptive/transfer learning, artifact removal, stimulation/closed-loop, hardware design), and what evaluation metrics matter (accuracy, ITR, latency, robustness)?\"\n    }\n  ]\n}"}
{"ts": "2026-01-22T23:07:50.313413+00:00", "event": "parse.stage2.prompt", "project_id": "3b9280a68d3d", "run_id": "e9de860e934a", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage2_converge.md", "prompt": "你是“研究描述自我收敛器”。你将收到三段文本：\n(1) 当前候选研究描述 current_description\n(2) 关于当前研究描述的问题question_for_user\n(3) 用户回答question_for_user的内容 user_additional_info（可能回答了问题，也可能没有）\n\n你的任务是：\n1) 判断用户回答的内容user_additional_info是不是在current_description框架下对question_for_user的正面回答，还是其他不相关的回答（比如小说，诗歌，日志，或者是和current_description不相关的研究领域等）。如果是直接的正面回答，就根据用户回答调整你对研究内容的理解，并判断更新后的研究内容是否合理：\n- A_impossible：明显荒诞/违背当前科技常识，无法形成合理检索任务\n- B_plausible：合理可行\n2) 如果A_impossible，给出简单的理由。如果新的理解是合理可行的，就用规范、聚焦、可检索的英文重写研究描述（300-600英文字符），这段重写用于帮助用户组织语言与规范表述。\n3) 判断用户回答的内容user_additional_info是不是在current_description框架下对question_for_user的正面回答。正面回答的话就返回 is_answered=true，否则返回 is_answered=false。\n\n4) 如果在新增信息后仍不清晰：输出你仍不确定的点（uncertainties），并提出最多3个澄清问题（具体可回答，优先信息增益最大）。\n5) 如果已经清晰：不要再提问题；只输出你的理解与结构化摘要。\n6) 输出结构化摘要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n只输出JSON，不输出任何额外文字。\n\ncurrent_description：\n\"\"\"I focus on brain-computer interface.\"\"\"\n\nquestion_for_user：\n\"\"\"Which BCI modality and signal type is the focus (e.g., EEG, MEG, ECoG, intracortical spikes), and is it invasive or noninvasive?\nWhat is the main application scenario and user group (e.g., spelling/communication for ALS, stroke rehabilitation, prosthetic/robot control, gaming; patients vs healthy participants)?\nWhat is the primary technical emphasis (e.g., decoding algorithms, adaptive/transfer learning, artifact removal, stimulation/closed-loop, hardware design), and what evaluation metrics matter (accuracy, ITR, latency, robustness)?\"\"\"\n\n\nuser_additional_info（用户本轮补充信息，可能为空）：\n\"\"\"There is no restriction on the modality, application, population, technical emphasis, or evaluation metrics.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"is_answered\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n  }\n\n约束：\n- 用英文回答。\n- is_answered = false，则\n  - uncertainties 给出判断没有正面回答问题的原因。\n  - 其他所有字段都为空。\n- normalized_understanding：300-600英文字符，必须是你融合了问题和答案后的最新理解，术语一致、范围聚焦。\n- 如果 plausibility_level=B_plausible且is_clear_for_search=true：\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空或最多1条轻微风险\n- 如果 plausibility_level=B_plausible且is_clear_for_search=false：\n  - uncertainties 至少2条\n  - suggested_questions 为1-3条，必须与uncertainties/missing_fields一致\n\n- 如果 plausibility_level=A_impossible：\n  - is_clear_for_search 必须为 false\n  - suggested_questions 必须为空数组\n  - uncertainties <=200英文字符：提示用户impossible的原因。\n"}
{"ts": "2026-01-22T23:07:57.134725+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_answered\": false,\n  \"normalized_understanding\": null,\n  \"structured_summary\": {\n    \"domain\": null,\n    \"task\": null,\n    \"subject_system\": null,\n    \"methods\": null,\n    \"scope\": null,\n    \"intent\": null,\n    \"exclusions\": null\n  },\n  \"uncertainties\": [\n    \"The user did not specify any BCI modality/signal type, invasiveness, application scenario, user group, technical emphasis, or evaluation metrics; stating 'no restriction' does not answer the requested scoping details, so the research intent cannot be made searchable.\"\n  ],\n  \"missing_fields\": [\n    \"domain\",\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"To make the topic searchable, which single BCI signal/modality should be the primary focus (EEG, MEG, ECoG, intracortical, fNIRS), and is it invasive or noninvasive?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What is the main application task and user group (e.g., communication/spelling for ALS, stroke rehab, prosthetic control; patients vs healthy participants)?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What is the primary technical emphasis and key evaluation metrics (e.g., decoding/transfer learning/artifact removal/closed-loop; accuracy, ITR, latency, robustness)?\"\n    }\n  ]\n}", "project_id": "3b9280a68d3d", "run_id": "e9de860e934a", "stage": "stage2"}
{"ts": "2026-01-22T23:07:57.135569+00:00", "event": "parse.stage2.response", "project_id": "3b9280a68d3d", "run_id": "e9de860e934a", "model": "gpt-5.2", "response": "{\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_answered\": false,\n  \"normalized_understanding\": null,\n  \"structured_summary\": {\n    \"domain\": null,\n    \"task\": null,\n    \"subject_system\": null,\n    \"methods\": null,\n    \"scope\": null,\n    \"intent\": null,\n    \"exclusions\": null\n  },\n  \"uncertainties\": [\n    \"The user did not specify any BCI modality/signal type, invasiveness, application scenario, user group, technical emphasis, or evaluation metrics; stating 'no restriction' does not answer the requested scoping details, so the research intent cannot be made searchable.\"\n  ],\n  \"missing_fields\": [\n    \"domain\",\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"To make the topic searchable, which single BCI signal/modality should be the primary focus (EEG, MEG, ECoG, intracortical, fNIRS), and is it invasive or noninvasive?\"\n    },\n    {\n      \"field\": \"task\",\n      \"question\": \"What is the main application task and user group (e.g., communication/spelling for ALS, stroke rehab, prosthetic control; patients vs healthy participants)?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"What is the primary technical emphasis and key evaluation metrics (e.g., decoding/transfer learning/artifact removal/closed-loop; accuracy, ITR, latency, robustness)?\"\n    }\n  ]\n}"}
{"ts": "2026-01-22T23:22:41.389301+00:00", "event": "parse.stage1.prompt", "project_id": "3b9280a68d3d", "run_id": "b6b977aeeed1", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage1_understanding.md", "prompt": "你是“研究描述理解与规范化”模块。输入是一段纯文本候选研究描述。你的目标是帮助用户把研究描述变得合理且清晰，便于后续生成文献检索查询。\n\n你必须完成：\n1) 判断这段描述是不是关于一类研究方向的描述，还是其他（比如小说，诗歌，日志等）。如果是研究描述就返回is_research_description=true.\n2) 如果是研究描述,进行常识可行性判断（plausibility_level）：\n- A_impossible：明显荒诞/违背当前科技常识（无法形成合理检索任务）\n- B_plausible：合理可行\n3) 如果合理可行，给出你对该研究描述的“当前理解”（normalized_understanding），用规范化、聚焦、可检索的英语重写，\n4) 判断当前理解是否已经清晰到可以用于检索；若不清晰，列出你仍不确定的点（疑问清单），并提出最多3个澄清问题（问题必须具体可回答）。\n5) 输出结构化提要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n6) 只输出JSON，不输出任何额外文本。\n\n候选研究描述：\n\"\"\"I focus on brain-computer interface.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"is_research_description\": boolean,\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n}\n\n约束：\n- 用英文回答。\n- 如果is_research_description = false，则\n  - uncertainties 给出判断不是research statement的原因。\n  - ncertainties/missing_fields/suggested_questions为空数组[];\n  - structured_summary为全null；\n- normalized_understanding：300-600个英文字符，必须是你对研究的“当前理解”，语言规范、聚焦、可检索；不要写“我认为/可能”等口水话，直接用陈述句组织。\n\n- 如果 是B_plausible，且 is_clear_for_search=true，则：\n  - is_research_description = true\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空数组或只保留0-1条轻微风险\n\n- 如果 是B_plausible，且 is_clear_for_search=false，则：\n  - is_research_description = true\n  - uncertainties 至少2条\n  - missing_fields 仅列出缺失项\n  - suggested_questions 为1-3条，必须与 uncertainties/missing_fields 对应\n\n- 如果 plausibility_level=A_impossible，则：\n  - is_clear_for_search=false\n  - suggested_questions 为空\n  - uncertainties <=200英文字符：给出impossible的原因。\n"}
{"ts": "2026-01-22T23:22:51.675349+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"The research focuses on brain–computer interfaces (BCIs), i.e., systems that acquire neural signals and translate them into control commands for external devices or software. It covers the end-to-end BCI pipeline including neural signal acquisition (invasive or noninvasive), preprocessing and feature extraction, decoding or classification algorithms, real-time feedback/control, and evaluation in target applications such as communication, motor rehabilitation, assistive robotics, or neurofeedback.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces / neuroengineering\",\n    \"task\": null,\n    \"subject_system\": null,\n    \"methods\": null,\n    \"scope\": null,\n    \"intent\": null,\n    \"exclusions\": null\n  },\n  \"uncertainties\": [\n    \"The specific BCI task is unspecified (e.g., motor imagery classification, cursor control, speech decoding, SSVEP/P300 spellers).\",\n    \"The neural signal modality and setup are unclear (EEG, ECoG, intracortical, fNIRS; online vs offline; human vs animal).\",\n    \"The intended methods and evaluation focus are not stated (deep learning vs classical ML, adaptive decoding, closed-loop control, clinical trials).\"\n  ],\n  \"missing_fields\": [\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"What specific BCI application/task are you targeting (e.g., motor imagery decoding, SSVEP/P300 speller, continuous cursor/robot control, speech decoding, neurofeedback)?\"\n    },\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Which neural recording modality and population are in scope (EEG/ECoG/intracortical/fNIRS; healthy participants vs patients; human vs animal; online closed-loop vs offline analysis)?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"Which methodological focus should the search emphasize (signal processing features, machine learning/deep learning decoders, transfer learning/domain adaptation, adaptive/closed-loop control, hardware/electrodes)?\"\n    }\n  ]\n}", "project_id": "3b9280a68d3d", "run_id": "b6b977aeeed1", "stage": "stage1"}
{"ts": "2026-01-22T23:22:51.677814+00:00", "event": "parse.stage1.response", "project_id": "3b9280a68d3d", "run_id": "b6b977aeeed1", "model": "gpt-5.2", "response": "{\n  \"is_research_description\": true,\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"normalized_understanding\": \"The research focuses on brain–computer interfaces (BCIs), i.e., systems that acquire neural signals and translate them into control commands for external devices or software. It covers the end-to-end BCI pipeline including neural signal acquisition (invasive or noninvasive), preprocessing and feature extraction, decoding or classification algorithms, real-time feedback/control, and evaluation in target applications such as communication, motor rehabilitation, assistive robotics, or neurofeedback.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces / neuroengineering\",\n    \"task\": null,\n    \"subject_system\": null,\n    \"methods\": null,\n    \"scope\": null,\n    \"intent\": null,\n    \"exclusions\": null\n  },\n  \"uncertainties\": [\n    \"The specific BCI task is unspecified (e.g., motor imagery classification, cursor control, speech decoding, SSVEP/P300 spellers).\",\n    \"The neural signal modality and setup are unclear (EEG, ECoG, intracortical, fNIRS; online vs offline; human vs animal).\",\n    \"The intended methods and evaluation focus are not stated (deep learning vs classical ML, adaptive decoding, closed-loop control, clinical trials).\"\n  ],\n  \"missing_fields\": [\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"intent\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"What specific BCI application/task are you targeting (e.g., motor imagery decoding, SSVEP/P300 speller, continuous cursor/robot control, speech decoding, neurofeedback)?\"\n    },\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"Which neural recording modality and population are in scope (EEG/ECoG/intracortical/fNIRS; healthy participants vs patients; human vs animal; online closed-loop vs offline analysis)?\"\n    },\n    {\n      \"field\": \"methods\",\n      \"question\": \"Which methodological focus should the search emphasize (signal processing features, machine learning/deep learning decoders, transfer learning/domain adaptation, adaptive/closed-loop control, hardware/electrodes)?\"\n    }\n  ]\n}"}
{"ts": "2026-01-22T23:24:10.257877+00:00", "event": "parse.stage2.prompt", "project_id": "3b9280a68d3d", "run_id": "b6b977aeeed1", "model": "gpt-5.2", "reasoning_effort": "high", "prompt_file": "/Users/osb3922/local_code/scholarmap/prompts/parse_stage2_converge.md", "prompt": "你是“研究描述自我收敛器”。你将收到三段文本：\n(1) 当前候选研究描述 current_description\n(2) 关于当前研究描述的问题question_for_user\n(3) 用户回答question_for_user的内容 user_additional_info（可能回答了问题，也可能没有）\n\n你的任务是：\n1) 判断用户回答的内容user_additional_info是不是在current_description框架下对question_for_user的正面回应，还是其他不相关的回答（比如小说，诗歌，日志，或者是和current_description不相关的研究领域等）。如果是直接的正面回应，就根据用户回答调整你对研究内容的理解，并判断更新后的研究内容是否合理：\n- A_impossible：明显荒诞/违背当前科技常识，无法形成合理检索任务\n- B_plausible：合理可行\n正面回应不要求解答具体的问题，只要是对这个问题的处理方式给出明确的答案都行，比如当问到使用什么技术的时候，正面回应可以列举具体的技术，也可以说对技术没有限制。\n2) 如果A_impossible，给出简单的理由。如果新的理解是合理可行的，就用规范、聚焦、可检索的英文重写研究描述（300-600英文字符），这段重写用于帮助用户组织语言与规范表述。\n3) 判断用户回答的内容user_additional_info是不是在current_description框架下对question_for_user的正面回答。正面回答的话就返回 is_answered=true，否则返回 is_answered=false。\n\n4) 如果在新增信息后仍不清晰：输出你仍不确定的点（uncertainties），并提出最多3个澄清问题（具体可回答，优先信息增益最大）。\n5) 如果已经清晰：不要再提问题；只输出你的理解与结构化摘要。\n6) 输出结构化摘要（最小可检索闭包字段）：\ndomain, task, subject_system, methods, scope, intent, exclusions\n只输出JSON，不输出任何额外文字。\n\ncurrent_description：\n\"\"\"I focus on brain-computer interface.\"\"\"\n\nquestion_for_user：\n\"\"\"What specific BCI application/task are you targeting (e.g., motor imagery decoding, SSVEP/P300 speller, continuous cursor/robot control, speech decoding, neurofeedback)?\nWhich neural recording modality and population are in scope (EEG/ECoG/intracortical/fNIRS; healthy participants vs patients; human vs animal; online closed-loop vs offline analysis)?\nWhich methodological focus should the search emphasize (signal processing features, machine learning/deep learning decoders, transfer learning/domain adaptation, adaptive/closed-loop control, hardware/electrodes)?\"\"\"\n\n\nuser_additional_info（用户本轮补充信息，可能为空）：\n\"\"\"There is no restriction on the BCI task, signal modality, setup, population, or methodological focus.\"\"\"\n\n请严格按以下schema输出JSON：\n{\n  \"plausibility_level\": \"A_impossible\" | \"B_plausible\",\n  \"is_clear_for_search\": boolean,\n  \"is_answered\": boolean,\n  \"normalized_understanding\": string,\n  \"structured_summary\": {\n    \"domain\": string | null,\n    \"task\": string | null,\n    \"subject_system\": string | null,\n    \"methods\": string | null,\n    \"scope\": string | null,\n    \"intent\": string | null,\n    \"exclusions\": string | null\n  },\n  \"uncertainties\": [string],\n  \"missing_fields\": [\"domain\",\"task\",\"subject_system\",\"methods\",\"scope\",\"intent\",\"exclusions\"],\n  \"suggested_questions\": [\n    {\"field\":\"domain|task|subject_system|methods|scope|intent|exclusions\", \"question\": string},\n    {\"field\":\"...\", \"question\": string},\n    {\"field\":\"...\", \"question\": string}\n  ]\n  }\n\n约束：\n- 用英文回答。\n- 如果用户的回答没有帮助收敛，但是做出了正面回应，也应该判断为 is_answered=true。 例如问题里有问用户具体使用什么研究方法，用户没有提供具体的答案，但是回答说对这个问题没有限制。又比如说，问题里有问用户具体的研究对象是什么，用户可以回答对研究对象没有限制。\n- 如果is_answered = false，则\n  - uncertainties 给出判断没有正面回答问题的原因。\n  - 其他所有字段都为空。\n- normalized_understanding：300-600英文字符，必须是你融合了问题和答案后的最新理解，术语一致、范围聚焦。\n- 如果 plausibility_level=B_plausible且is_clear_for_search=true：\n  - suggested_questions 必须为空数组\n  - uncertainties 允许为空或最多1条轻微风险\n- 如果 plausibility_level=B_plausible且is_clear_for_search=false：\n  - uncertainties 至少2条\n  - suggested_questions 为1-3条，必须与uncertainties/missing_fields一致\n\n- 如果 plausibility_level=A_impossible：\n  - is_clear_for_search 必须为 false\n  - suggested_questions 必须为空数组\n  - uncertainties <=200英文字符：提示用户impossible的原因。\n"}
{"ts": "2026-01-22T23:24:20.901031+00:00", "event": "llm.complete_text.response", "model": "gpt-5.2", "api": "chat/completions", "raw_response": "{\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_answered\": true,\n  \"normalized_understanding\": \"The research interest is broadly in brain–computer interfaces without restricting the target application (e.g., spelling, motor control, neurofeedback), neural recording modality (EEG, ECoG, intracortical, fNIRS), experimental setup (online closed-loop or offline), participant population (healthy or patients; human or animal), or methodological emphasis (signal processing, ML/DL decoding, transfer learning, adaptive control, or hardware/electrodes). The goal is a general BCI literature search across these dimensions.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces (BCI)\",\n    \"task\": null,\n    \"subject_system\": null,\n    \"methods\": null,\n    \"scope\": null,\n    \"intent\": \"General literature search / overview across BCI tasks, modalities, populations, setups, and methods\",\n    \"exclusions\": null\n  },\n  \"uncertainties\": [\n    \"No constraints are provided on task, modality, population, or methods, making the search space too broad to form a focused, high-precision query set.\",\n    \"It is unclear whether the desired output is a survey/overview, a benchmark comparison, or guidance for implementing a specific BCI pipeline.\",\n    \"Timeframe, application priority (communication vs control vs rehabilitation), and evaluation criteria (accuracy, ITR, latency, robustness) are unspecified.\"\n  ],\n  \"missing_fields\": [\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"Which 1–2 BCI paradigms should be prioritized for the search (e.g., SSVEP/P300 speller, motor imagery, continuous control, speech decoding, neurofeedback), even if others remain secondary?\"\n    },\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"What is the primary recording modality and population to center on (e.g., noninvasive EEG in healthy humans vs invasive ECoG/intracortical in patients), or should the search explicitly compare noninvasive vs invasive?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"What scope constraints should be applied to keep results manageable (e.g., last 5–10 years, online closed-loop only, clinical/rehab focus, or top venues like IEEE TNSRE/JNE/NeuroImage)?\"\n    }\n  ]\n}", "project_id": "3b9280a68d3d", "run_id": "b6b977aeeed1", "stage": "stage2"}
{"ts": "2026-01-22T23:24:20.901894+00:00", "event": "parse.stage2.response", "project_id": "3b9280a68d3d", "run_id": "b6b977aeeed1", "model": "gpt-5.2", "response": "{\n  \"plausibility_level\": \"B_plausible\",\n  \"is_clear_for_search\": false,\n  \"is_answered\": true,\n  \"normalized_understanding\": \"The research interest is broadly in brain–computer interfaces without restricting the target application (e.g., spelling, motor control, neurofeedback), neural recording modality (EEG, ECoG, intracortical, fNIRS), experimental setup (online closed-loop or offline), participant population (healthy or patients; human or animal), or methodological emphasis (signal processing, ML/DL decoding, transfer learning, adaptive control, or hardware/electrodes). The goal is a general BCI literature search across these dimensions.\",\n  \"structured_summary\": {\n    \"domain\": \"Brain–computer interfaces (BCI)\",\n    \"task\": null,\n    \"subject_system\": null,\n    \"methods\": null,\n    \"scope\": null,\n    \"intent\": \"General literature search / overview across BCI tasks, modalities, populations, setups, and methods\",\n    \"exclusions\": null\n  },\n  \"uncertainties\": [\n    \"No constraints are provided on task, modality, population, or methods, making the search space too broad to form a focused, high-precision query set.\",\n    \"It is unclear whether the desired output is a survey/overview, a benchmark comparison, or guidance for implementing a specific BCI pipeline.\",\n    \"Timeframe, application priority (communication vs control vs rehabilitation), and evaluation criteria (accuracy, ITR, latency, robustness) are unspecified.\"\n  ],\n  \"missing_fields\": [\n    \"task\",\n    \"subject_system\",\n    \"methods\",\n    \"scope\",\n    \"exclusions\"\n  ],\n  \"suggested_questions\": [\n    {\n      \"field\": \"task\",\n      \"question\": \"Which 1–2 BCI paradigms should be prioritized for the search (e.g., SSVEP/P300 speller, motor imagery, continuous control, speech decoding, neurofeedback), even if others remain secondary?\"\n    },\n    {\n      \"field\": \"subject_system\",\n      \"question\": \"What is the primary recording modality and population to center on (e.g., noninvasive EEG in healthy humans vs invasive ECoG/intracortical in patients), or should the search explicitly compare noninvasive vs invasive?\"\n    },\n    {\n      \"field\": \"scope\",\n      \"question\": \"What scope constraints should be applied to keep results manageable (e.g., last 5–10 years, online closed-loop only, clinical/rehab focus, or top venues like IEEE TNSRE/JNE/NeuroImage)?\"\n    }\n  ]\n}"}
