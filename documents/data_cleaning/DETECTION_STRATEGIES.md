# æ•°æ®è´¨é‡æ¸…æ´—ç³»ç»Ÿ - æ£€æµ‹ç­–ç•¥è¯¦è§£

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [æ£€æµ‹å±‚çº§ 1: æå–è´¨é‡æ£€æµ‹](#æ£€æµ‹å±‚çº§-1-æå–è´¨é‡æ£€æµ‹)
- [æ£€æµ‹å±‚çº§ 2: Geocoding è´¨é‡æ£€æµ‹](#æ£€æµ‹å±‚çº§-2-geocoding-è´¨é‡æ£€æµ‹)
- [æ£€æµ‹å±‚çº§ 3: æ•°æ®ä¸€è‡´æ€§æ£€æµ‹](#æ£€æµ‹å±‚çº§-3-æ•°æ®ä¸€è‡´æ€§æ£€æµ‹)
- [é”™è¯¯åˆ†ç±»å’Œä¼˜å…ˆçº§](#é”™è¯¯åˆ†ç±»å’Œä¼˜å…ˆçº§)

---

## æ¦‚è¿°

æ•°æ®è´¨é‡æ£€æµ‹ç³»ç»Ÿé‡‡ç”¨**ä¸‰å±‚æ£€æµ‹æœºåˆ¶**ï¼Œä»ä¸åŒç»´åº¦æ£€æµ‹æ•°æ®è´¨é‡é—®é¢˜ï¼š

1. **æå–è´¨é‡æ£€æµ‹**ï¼šæ£€æµ‹åœ°ç†ä¿¡æ¯æå–è¿‡ç¨‹ä¸­çš„é”™è¯¯
2. **Geocoding è´¨é‡æ£€æµ‹**ï¼šæ£€æµ‹åæ ‡è·å–è¿‡ç¨‹ä¸­çš„é”™è¯¯
3. **æ•°æ®ä¸€è‡´æ€§æ£€æµ‹**ï¼šæ£€æµ‹æ•°æ®åº“è¡¨ä¹‹é—´çš„ä¸ä¸€è‡´

æ¯å±‚æ£€æµ‹å™¨ç‹¬ç«‹è¿è¡Œï¼Œäº§ç”Ÿé”™è¯¯è®°å½•ï¼Œæœ€åæ±‡æ€»åˆ†æã€‚

---

## æ£€æµ‹å±‚çº§ 1: æå–è´¨é‡æ£€æµ‹

### ExtractionQualityDetector

æ£€æµ‹ä» affiliation å­—ç¬¦ä¸²ä¸­æå–åœ°ç†ä¿¡æ¯ï¼ˆcountry/city/institutionï¼‰çš„è´¨é‡ã€‚

#### ä»£ç å®ç°

```python
# backend/app/cleaning/detectors/extraction_detector.py

from typing import List
from backend.app.db.models import Authorship
from backend.app.cleaning.models import ErrorRecord

class ExtractionQualityDetector:
    """æå–è´¨é‡æ£€æµ‹å™¨"""
    
    # ç¾å›½å·ç¼©å†™åˆ—è¡¨
    US_STATE_ABBRS = {
        "AL", "AK", "AZ", "AR", "CA", "CO", "CT", "DE", "FL", "GA",
        "HI", "ID", "IL", "IN", "IA", "KS", "KY", "LA", "ME", "MD",
        "MA", "MI", "MN", "MS", "MO", "MT", "NE", "NV", "NH", "NJ",
        "NM", "NY", "NC", "ND", "OH", "OK", "OR", "PA", "RI", "SC",
        "SD", "TN", "TX", "UT", "VT", "VA", "WA", "WV", "WI", "WY", "DC"
    }
    
    # æœºæ„å…³é”®è¯
    INSTITUTION_KEYWORDS = {
        "university", "college", "institute", "school", "hospital",
        "center", "laboratory", "clinic", "academy", "foundation"
    }
    
    # éƒ¨é—¨å…³é”®è¯
    DEPARTMENT_KEYWORDS = {
        "department", "division", "section", "unit", "group",
        "lab", "faculty", "office"
    }
    
    async def detect_extraction_errors(
        self, 
        authorships: List[Authorship]
    ) -> List[ErrorRecord]:
        """æ£€æµ‹æå–é”™è¯¯"""
        errors = []
        
        for auth in authorships:
            # è§„åˆ™ 1: æ£€æµ‹å·ç¼©å†™ä½œä¸ºåŸå¸‚
            if self._is_state_abbreviation(auth.city):
                errors.append(self._create_error_record(
                    authorship=auth,
                    error_category='state_as_city',
                    severity='high',
                    detection_method='validation_rule',
                    detection_reason=f'City "{auth.city}" is a U.S. state abbreviation'
                ))
            
            # è§„åˆ™ 2: æ£€æµ‹æœºæ„åä½œä¸ºåŸå¸‚
            if self._contains_institution_keywords(auth.city):
                errors.append(self._create_error_record(
                    authorship=auth,
                    error_category='institution_as_city',
                    severity='medium',
                    detection_method='validation_rule',
                    detection_reason=f'City "{auth.city}" contains institution keywords'
                ))
            
            # è§„åˆ™ 3: æ£€æµ‹éƒ¨é—¨åä½œä¸ºåŸå¸‚
            if self._contains_department_keywords(auth.city):
                errors.append(self._create_error_record(
                    authorship=auth,
                    error_category='department_as_city',
                    severity='medium',
                    detection_method='validation_rule',
                    detection_reason=f'City "{auth.city}" contains department keywords'
                ))
            
            # è§„åˆ™ 4: æ£€æµ‹ç½®ä¿¡åº¦ä½çš„æå–
            if auth.affiliation_confidence in ['low', 'none']:
                errors.append(self._create_error_record(
                    authorship=auth,
                    error_category='low_confidence',
                    severity='low' if auth.affiliation_confidence == 'low' else 'medium',
                    detection_method='confidence_threshold',
                    detection_reason=f'Affiliation confidence is {auth.affiliation_confidence}'
                ))
            
            # è§„åˆ™ 5: æ£€æµ‹å›½å®¶/åŸå¸‚ä¸åŒ¹é…
            if not await self._is_city_in_country(auth.city, auth.country):
                errors.append(self._create_error_record(
                    authorship=auth,
                    error_category='country_city_mismatch',
                    severity='high',
                    detection_method='validation_rule',
                    detection_reason=f'City "{auth.city}" does not belong to country "{auth.country}"'
                ))
            
            # è§„åˆ™ 6: æ£€æµ‹ç©ºå€¼ä½†æœ‰ affiliation
            if auth.has_author_affiliation and not auth.city and not auth.country:
                errors.append(self._create_error_record(
                    authorship=auth,
                    error_category='missing_geo_data',
                    severity='high',
                    detection_method='validation_rule',
                    detection_reason='Has affiliation but no geographic data extracted'
                ))
            
            # è§„åˆ™ 7: æ£€æµ‹åŸå¸‚ååŒ…å«æ•°å­—
            if auth.city and any(char.isdigit() for char in auth.city):
                errors.append(self._create_error_record(
                    authorship=auth,
                    error_category='city_contains_numbers',
                    severity='high',
                    detection_method='validation_rule',
                    detection_reason=f'City "{auth.city}" contains numbers'
                ))
            
            # è§„åˆ™ 8: æ£€æµ‹è¿‡çŸ­çš„åŸå¸‚åï¼ˆå¯èƒ½æ˜¯ç¼©å†™ï¼‰
            if auth.city and len(auth.city) <= 2:
                errors.append(self._create_error_record(
                    authorship=auth,
                    error_category='city_too_short',
                    severity='medium',
                    detection_method='validation_rule',
                    detection_reason=f'City "{auth.city}" is suspiciously short (â‰¤2 chars)'
                ))
        
        return errors
    
    def _is_state_abbreviation(self, city: str | None) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºç¾å›½å·ç¼©å†™"""
        if not city:
            return False
        return city.upper().strip() in self.US_STATE_ABBRS
    
    def _contains_institution_keywords(self, city: str | None) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«æœºæ„å…³é”®è¯"""
        if not city:
            return False
        city_lower = city.lower()
        return any(keyword in city_lower for keyword in self.INSTITUTION_KEYWORDS)
    
    def _contains_department_keywords(self, city: str | None) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«éƒ¨é—¨å…³é”®è¯"""
        if not city:
            return False
        city_lower = city.lower()
        # æ£€æŸ¥æ˜¯å¦ä»¥éƒ¨é—¨å…³é”®è¯å¼€å¤´
        return any(city_lower.startswith(keyword) for keyword in self.DEPARTMENT_KEYWORDS)
    
    async def _is_city_in_country(self, city: str | None, country: str | None) -> bool:
        """éªŒè¯åŸå¸‚æ˜¯å¦å±äºè¯¥å›½å®¶"""
        if not city or not country:
            return True  # å¦‚æœç¼ºå¤±ï¼Œä¸ç®—é”™è¯¯
        
        # TODO: å®ç°åŸå¸‚-å›½å®¶éªŒè¯é€»è¾‘
        # å¯ä»¥ä½¿ç”¨ï¼š
        # - æœ¬åœ°åŸå¸‚æ•°æ®åº“ï¼ˆå¦‚ GeoNamesï¼‰
        # - è°ƒç”¨ Nominatim æœç´¢
        # - ä½¿ç”¨ pycountry ç­‰åº“
        
        # ä¸´æ—¶å®ç°ï¼šè·³è¿‡éªŒè¯
        return True
    
    def _create_error_record(
        self,
        authorship: Authorship,
        error_category: str,
        severity: str,
        detection_method: str,
        detection_reason: str
    ) -> ErrorRecord:
        """åˆ›å»ºé”™è¯¯è®°å½•"""
        return ErrorRecord(
            authorship_id=authorship.id,
            pmid=authorship.pmid,
            error_type='extraction_error',
            error_category=error_category,
            severity=severity,
            detection_method=detection_method,
            detection_reason=detection_reason,
            original_affiliation=authorship.affiliation_raw_joined,
            original_country=authorship.country,
            original_city=authorship.city,
            original_institution=authorship.institution
        )
```

#### æ£€æµ‹è§„åˆ™æ€»ç»“

| è§„åˆ™ ID | æ£€æµ‹å†…å®¹ | é”™è¯¯ç±»åˆ« | ä¸¥é‡ç¨‹åº¦ | ç¤ºä¾‹ |
|---------|----------|----------|----------|------|
| 1 | å·ç¼©å†™ä½œä¸ºåŸå¸‚ | `state_as_city` | HIGH | MD, OH, CA |
| 2 | æœºæ„åä½œä¸ºåŸå¸‚ | `institution_as_city` | MEDIUM | Harvard Medical School |
| 3 | éƒ¨é—¨åä½œä¸ºåŸå¸‚ | `department_as_city` | MEDIUM | Department of Neurology |
| 4 | ä½ç½®ä¿¡åº¦æå– | `low_confidence` | LOW/MEDIUM | confidence='low' or 'none' |
| 5 | å›½å®¶åŸå¸‚ä¸åŒ¹é… | `country_city_mismatch` | HIGH | Paris in China |
| 6 | æœ‰ affiliation ä½†æ— åœ°ç†æ•°æ® | `missing_geo_data` | HIGH | affiliation å­˜åœ¨ä½† city/country ä¸ºç©º |
| 7 | åŸå¸‚ååŒ…å«æ•°å­— | `city_contains_numbers` | HIGH | Boston123 |
| 8 | åŸå¸‚åè¿‡çŸ­ | `city_too_short` | MEDIUM | MA, NY |

---

## æ£€æµ‹å±‚çº§ 2: Geocoding è´¨é‡æ£€æµ‹

### GeocodingQualityDetector

æ£€æµ‹ä» country/city è·å–åæ ‡çš„è´¨é‡ã€‚

#### ä»£ç å®ç°

```python
# backend/app/cleaning/detectors/geocoding_detector.py

import httpx
from typing import List, Tuple, Dict
from backend.app.db.models import Authorship
from backend.app.phase2.pg_geocoding import PostgresGeocoder
from backend.app.cleaning.models import ErrorRecord

class GeocodingQualityDetector:
    """Geocoding è´¨é‡æ£€æµ‹å™¨"""
    
    def __init__(self):
        self.geocoder = PostgresGeocoder()
        self._reverse_geocode_cache = {}
    
    async def detect_geocoding_errors(
        self,
        authorships: List[Authorship]
    ) -> List[ErrorRecord]:
        """æ£€æµ‹ geocoding é”™è¯¯"""
        errors = []
        
        # æ”¶é›†å”¯ä¸€çš„ location_key
        location_keys = set()
        location_to_authorships = {}
        
        for auth in authorships:
            if not auth.country:
                continue
            
            location_key = self._make_location_key(auth.country, auth.city)
            location_keys.add(location_key)
            
            if location_key not in location_to_authorships:
                location_to_authorships[location_key] = []
            location_to_authorships[location_key].append(auth)
        
        # æ‰¹é‡è·å– geocoding ç»“æœ
        cached_results = await self._batch_get_cached_coordinates(location_keys)
        
        # æ£€æŸ¥æ¯ä¸ª location
        for location_key, coords_data in cached_results.items():
            authorships_for_location = location_to_authorships[location_key]
            country, city = self._parse_location_key(location_key)
            
            # è§„åˆ™ 1: Null åæ ‡
            if coords_data is None or coords_data.get('latitude') is None:
                for auth in authorships_for_location:
                    errors.append(self._create_error_record(
                        authorship=auth,
                        error_category='geocoding_null',
                        severity='high',
                        detection_method='geocoding_failure',
                        detection_reason=f'No coordinates found for location: {location_key}'
                    ))
                continue
            
            lat, lng = coords_data['latitude'], coords_data['longitude']
            
            # è§„åˆ™ 2: åå‘éªŒè¯ï¼ˆåæ ‡ â†’ åœ°å€ï¼‰
            if not await self._validate_coordinates(lat, lng, country, city):
                for auth in authorships_for_location:
                    errors.append(self._create_error_record(
                        authorship=auth,
                        error_category='wrong_coordinates',
                        severity='critical',
                        detection_method='reverse_geocoding',
                        detection_reason=f'Reverse geocoding mismatch for {location_key} at ({lat}, {lng})',
                        coordinates={'lat': lat, 'lng': lng}
                    ))
            
            # è§„åˆ™ 3: åæ ‡å¼‚å¸¸æ£€æµ‹
            if self._is_coordinate_anomaly(lat, lng, country):
                for auth in authorships_for_location:
                    errors.append(self._create_error_record(
                        authorship=auth,
                        error_category='coordinate_anomaly',
                        severity='high',
                        detection_method='anomaly_detection',
                        detection_reason=f'Coordinates ({lat}, {lng}) appear anomalous for {country}',
                        coordinates={'lat': lat, 'lng': lng}
                    ))
        
        return errors
    
    async def _validate_coordinates(
        self,
        lat: float,
        lng: float,
        expected_country: str,
        expected_city: str | None
    ) -> bool:
        """åå‘ geocoding éªŒè¯åæ ‡æ˜¯å¦æ­£ç¡®"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{lat},{lng}"
        if cache_key in self._reverse_geocode_cache:
            result = self._reverse_geocode_cache[cache_key]
        else:
            # è°ƒç”¨ Nominatim reverse API
            result = await self._reverse_geocode(lat, lng)
            self._reverse_geocode_cache[cache_key] = result
        
        if not result:
            return True  # æ— æ³•éªŒè¯ï¼Œå‡è®¾æ­£ç¡®
        
        # æ£€æŸ¥å›½å®¶æ˜¯å¦åŒ¹é…
        result_country = result.get('country', '')
        if not self._normalize_country(result_country) == self._normalize_country(expected_country):
            return False
        
        # å¦‚æœæœ‰åŸå¸‚ï¼Œæ£€æŸ¥åŸå¸‚æ˜¯å¦åŒ¹é…
        if expected_city:
            result_city = result.get('city') or result.get('town') or result.get('village') or ''
            if result_city and not self._normalize_city(result_city) == self._normalize_city(expected_city):
                return False
        
        return True
    
    async def _reverse_geocode(self, lat: float, lng: float) -> Dict | None:
        """åå‘ geocodingï¼ˆåæ ‡ â†’ åœ°å€ï¼‰"""
        url = "https://nominatim.openstreetmap.org/reverse"
        params = {
            'lat': lat,
            'lon': lng,
            'format': 'json',
            'addressdetails': 1
        }
        headers = {'User-Agent': 'ScholarMap/1.0'}
        
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(url, params=params, headers=headers, timeout=10.0)
                if response.status_code == 200:
                    data = response.json()
                    return data.get('address', {})
        except Exception:
            pass
        
        return None
    
    def _is_coordinate_anomaly(self, lat: float, lng: float, country: str) -> bool:
        """æ£€æµ‹åæ ‡å¼‚å¸¸"""
        # è§„åˆ™ 1: åæ ‡è¶…å‡ºæœ‰æ•ˆèŒƒå›´
        if not (-90 <= lat <= 90 and -180 <= lng <= 180):
            return True
        
        # è§„åˆ™ 2: åæ ‡åœ¨æµ·æ´‹ä¸­å¿ƒï¼ˆç®€å•æ£€æŸ¥ï¼‰
        # TODO: ä½¿ç”¨æ›´ç²¾ç¡®çš„é™†åœ°/æµ·æ´‹æ•°æ®
        
        # è§„åˆ™ 3: åæ ‡ä¸å›½å®¶çš„å…¸å‹èŒƒå›´ä¸åŒ¹é…
        # TODO: å®ç°å›½å®¶è¾¹ç•Œæ£€æŸ¥
        
        return False
    
    def _make_location_key(self, country: str, city: str | None) -> str:
        """ç”Ÿæˆ location_key"""
        if city:
            return f"city:{city},{country}"
        return f"country:{country}"
    
    def _parse_location_key(self, location_key: str) -> Tuple[str, str | None]:
        """è§£æ location_key"""
        if location_key.startswith("city:"):
            parts = location_key[5:].split(",", 1)
            return parts[1], parts[0] if len(parts) == 2 else None
        elif location_key.startswith("country:"):
            return location_key[8:], None
        return location_key, None
    
    def _normalize_country(self, country: str) -> str:
        """è§„èŒƒåŒ–å›½å®¶å"""
        # å»é™¤ç©ºæ ¼ï¼Œè½¬å°å†™
        normalized = country.strip().lower()
        
        # å¸¸è§åˆ«åæ˜ å°„
        aliases = {
            'usa': 'united states',
            'us': 'united states',
            'uk': 'united kingdom',
            'korea': 'south korea',
            # ... æ›´å¤šåˆ«å
        }
        
        return aliases.get(normalized, normalized)
    
    def _normalize_city(self, city: str) -> str:
        """è§„èŒƒåŒ–åŸå¸‚å"""
        return city.strip().lower()
    
    async def _batch_get_cached_coordinates(
        self,
        location_keys: set
    ) -> Dict[str, Dict | None]:
        """æ‰¹é‡è·å–ç¼“å­˜çš„åæ ‡"""
        # TODO: å®ç°æ‰¹é‡æŸ¥è¯¢ geocoding_cache
        results = {}
        for key in location_keys:
            # æŸ¥è¯¢æ•°æ®åº“
            cached = await self.geocoder.cache_repo.get_cached(key)
            if cached:
                results[key] = {
                    'latitude': cached.latitude,
                    'longitude': cached.longitude
                }
            else:
                results[key] = None
        return results
    
    def _create_error_record(
        self,
        authorship: Authorship,
        error_category: str,
        severity: str,
        detection_method: str,
        detection_reason: str,
        coordinates: Dict | None = None
    ) -> ErrorRecord:
        """åˆ›å»ºé”™è¯¯è®°å½•"""
        return ErrorRecord(
            authorship_id=authorship.id,
            pmid=authorship.pmid,
            error_type='geocoding_error',
            error_category=error_category,
            severity=severity,
            detection_method=detection_method,
            detection_reason=detection_reason,
            original_affiliation=authorship.affiliation_raw_joined,
            original_country=authorship.country,
            original_city=authorship.city,
            original_institution=authorship.institution,
            original_coordinates=coordinates
        )
```

#### æ£€æµ‹è§„åˆ™æ€»ç»“

| è§„åˆ™ ID | æ£€æµ‹å†…å®¹ | é”™è¯¯ç±»åˆ« | ä¸¥é‡ç¨‹åº¦ | è¯´æ˜ |
|---------|----------|----------|----------|------|
| 1 | Null åæ ‡ | `geocoding_null` | HIGH | geocoding_cache ä¸­åæ ‡ä¸º null |
| 2 | åæ ‡é”™è¯¯ | `wrong_coordinates` | CRITICAL | åå‘ geocoding éªŒè¯ä¸åŒ¹é… |
| 3 | åæ ‡å¼‚å¸¸ | `coordinate_anomaly` | HIGH | åæ ‡åœ¨æµ·æ´‹ã€æ²™æ¼ ç­‰å¼‚å¸¸ä½ç½® |

---

## æ£€æµ‹å±‚çº§ 3: æ•°æ®ä¸€è‡´æ€§æ£€æµ‹

### ConsistencyDetector

æ£€æµ‹æ•°æ®åº“è¡¨ä¹‹é—´çš„ä¸ä¸€è‡´ã€‚

#### ä»£ç å®ç°

```python
# backend/app/cleaning/detectors/consistency_detector.py

from typing import List
from sqlalchemy import select, and_
from backend.app.db.models import Authorship, AffiliationCache, GeocodingCache
from backend.app.cleaning.models import ErrorRecord

class ConsistencyDetector:
    """æ•°æ®ä¸€è‡´æ€§æ£€æµ‹å™¨"""
    
    async def detect_inconsistencies(self) -> List[ErrorRecord]:
        """æ£€æµ‹æ•°æ®ä¸ä¸€è‡´"""
        errors = []
        
        # è§„åˆ™ 1: affiliation_cache vs authorship ä¸ä¸€è‡´
        errors.extend(await self._detect_cache_inconsistency())
        
        # è§„åˆ™ 2: é‡å¤/å†²çªçš„åæ ‡
        errors.extend(await self._detect_duplicate_coordinates())
        
        # è§„åˆ™ 3: ç›¸åŒ affiliation äº§ç”Ÿä¸åŒç»“æœ
        errors.extend(await self._detect_affiliation_variations())
        
        return errors
    
    async def _detect_cache_inconsistency(self) -> List[ErrorRecord]:
        """æ£€æµ‹ affiliation_cache å’Œ authorship çš„ä¸ä¸€è‡´"""
        # TODO: å®ç°
        # æŸ¥è¯¢æ‰€æœ‰ authorshipï¼Œæ£€æŸ¥å…¶ç¬¬ä¸€ä¸ª affiliation æ˜¯å¦åœ¨ cache ä¸­
        # å¦‚æœåœ¨ cache ä¸­ï¼Œæ£€æŸ¥ country/city/institution æ˜¯å¦ä¸€è‡´
        return []
    
    async def _detect_duplicate_coordinates(self) -> List[ErrorRecord]:
        """æ£€æµ‹é‡å¤/å†²çªçš„åæ ‡"""
        # TODO: å®ç°
        # æŸ¥è¯¢ geocoding_cacheï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªä¸åŒçš„ location_key æŒ‡å‘ç›¸åŒåæ ‡
        return []
    
    async def _detect_affiliation_variations(self) -> List[ErrorRecord]:
        """æ£€æµ‹ç›¸åŒ affiliation äº§ç”Ÿä¸åŒç»“æœ"""
        # TODO: å®ç°
        # è¿™å¯èƒ½å‘ç”Ÿåœ¨ä¸åŒæ—¶é—´ä½¿ç”¨ä¸åŒæå–æ–¹æ³•çš„æƒ…å†µ
        return []
```

---

## é”™è¯¯åˆ†ç±»å’Œä¼˜å…ˆçº§

### é”™è¯¯ä¸¥é‡ç¨‹åº¦å®šä¹‰

| ä¸¥é‡ç¨‹åº¦ | å®šä¹‰ | å½±å“ | å¤„ç†ä¼˜å…ˆçº§ |
|----------|------|------|-----------|
| **CRITICAL** | å¯¼è‡´ä¸¥é‡æ•°æ®é”™è¯¯ | åœ°å›¾æ˜¾ç¤ºå®Œå…¨é”™è¯¯çš„ä½ç½® | ğŸ”´ æœ€é«˜ |
| **HIGH** | å¯¼è‡´æ•°æ®ç¼ºå¤±æˆ–æ˜æ˜¾é”™è¯¯ | åœ°å›¾ç¼ºå°‘æ•°æ®æˆ–æ˜¾ç¤ºé”™è¯¯åŸå¸‚ | ğŸŸ  é«˜ |
| **MEDIUM** | å¯èƒ½å¯¼è‡´é”™è¯¯æˆ–è´¨é‡ä¸‹é™ | æ•°æ®è´¨é‡é™ä½ä½†ä¸å½±å“æ ¸å¿ƒåŠŸèƒ½ | ğŸŸ¡ ä¸­ |
| **LOW** | è½»å¾®é—®é¢˜ï¼Œå½±å“è¾ƒå° | æ•°æ®å®Œæ•´æ€§è½»å¾®å½±å“ | ğŸŸ¢ ä½ |

### é”™è¯¯åˆ†ç±»ä½“ç³»

```
extraction_error (æå–é”™è¯¯)
â”œâ”€ state_as_city (å·ç¼©å†™ä½œä¸ºåŸå¸‚) - HIGH
â”œâ”€ institution_as_city (æœºæ„åä½œä¸ºåŸå¸‚) - MEDIUM
â”œâ”€ department_as_city (éƒ¨é—¨åä½œä¸ºåŸå¸‚) - MEDIUM
â”œâ”€ low_confidence (ä½ç½®ä¿¡åº¦) - LOW/MEDIUM
â”œâ”€ country_city_mismatch (å›½å®¶åŸå¸‚ä¸åŒ¹é…) - HIGH
â”œâ”€ missing_geo_data (ç¼ºå¤±åœ°ç†æ•°æ®) - HIGH
â”œâ”€ city_contains_numbers (åŸå¸‚ååŒ…å«æ•°å­—) - HIGH
â””â”€ city_too_short (åŸå¸‚åè¿‡çŸ­) - MEDIUM

geocoding_error (Geocoding é”™è¯¯)
â”œâ”€ geocoding_null (æ— åæ ‡) - HIGH
â”œâ”€ wrong_coordinates (åæ ‡é”™è¯¯) - CRITICAL
â””â”€ coordinate_anomaly (åæ ‡å¼‚å¸¸) - HIGH

consistency_error (ä¸€è‡´æ€§é”™è¯¯)
â”œâ”€ cache_inconsistent (ç¼“å­˜ä¸ä¸€è‡´) - MEDIUM
â”œâ”€ duplicate_coordinates (é‡å¤åæ ‡) - LOW
â””â”€ affiliation_variations (ç›¸åŒ affiliation ä¸åŒç»“æœ) - MEDIUM
```

### é”™è¯¯ä¼˜å…ˆçº§æ’åº

ä¿®å¤æ—¶æŒ‰ä»¥ä¸‹é¡ºåºå¤„ç†ï¼š

1. **CRITICAL é”™è¯¯** â†’ ç«‹å³ä¿®å¤
2. **HIGH é”™è¯¯** â†’ é«˜ä¼˜å…ˆçº§ä¿®å¤
3. **MEDIUM é”™è¯¯** â†’ æ­£å¸¸ä¼˜å…ˆçº§ä¿®å¤
4. **LOW é”™è¯¯** â†’ ä½ä¼˜å…ˆçº§ä¿®å¤

åœ¨åŒä¸€ä¸¥é‡ç¨‹åº¦å†…ï¼ŒæŒ‰ä»¥ä¸‹å› ç´ æ’åºï¼š
- å½±å“çš„ authorship æ•°é‡ï¼ˆè¶Šå¤šè¶Šä¼˜å…ˆï¼‰
- é”™è¯¯æ£€æµ‹æ—¶é—´ï¼ˆè¶Šæ—©è¶Šä¼˜å…ˆï¼‰
- ä¿®å¤éš¾åº¦ï¼ˆè¶Šå®¹æ˜“è¶Šä¼˜å…ˆï¼‰

---

## å®æ–½å»ºè®®

### 1. æ¸è¿›å¼å¯ç”¨

å»ºè®®æŒ‰ä»¥ä¸‹é¡ºåºå¯ç”¨æ£€æµ‹è§„åˆ™ï¼š

**Phase 1**: å¯ç”¨åŸºæœ¬è§„åˆ™
- å·ç¼©å†™æ£€æµ‹
- Geocoding null æ£€æµ‹
- ä½ç½®ä¿¡åº¦æ£€æµ‹

**Phase 2**: å¯ç”¨ä¸­çº§è§„åˆ™
- æœºæ„åæ£€æµ‹
- éƒ¨é—¨åæ£€æµ‹
- åæ ‡å¼‚å¸¸æ£€æµ‹

**Phase 3**: å¯ç”¨é«˜çº§è§„åˆ™
- åå‘ geocoding éªŒè¯
- å›½å®¶åŸå¸‚åŒ¹é…éªŒè¯
- ä¸€è‡´æ€§æ£€æµ‹

### 2. è°ƒæ•´æ£€æµ‹é˜ˆå€¼

æ ¹æ®å®é™…è¿è¡Œç»“æœï¼Œè°ƒæ•´æ£€æµ‹é˜ˆå€¼ï¼š

```python
class DetectorConfig:
    """æ£€æµ‹å™¨é…ç½®"""
    
    # ç½®ä¿¡åº¦é˜ˆå€¼
    LOW_CONFIDENCE_THRESHOLD = 0.6  # ä½äºæ­¤å€¼è§†ä¸ºä½ç½®ä¿¡åº¦
    
    # åŸå¸‚åæœ€çŸ­é•¿åº¦
    MIN_CITY_NAME_LENGTH = 3  # çŸ­äºæ­¤é•¿åº¦è§†ä¸ºå¯ç–‘
    
    # åå‘ geocoding ç›¸ä¼¼åº¦é˜ˆå€¼
    REVERSE_GEOCODE_SIMILARITY_THRESHOLD = 0.8
    
    # åæ ‡å¼‚å¸¸æ£€æµ‹å‚æ•°
    COORDINATE_ANOMALY_ENABLED = True
```

### 3. é”™è¯¯æŠ‘åˆ¶

å¯¹äºæŸäº›å·²çŸ¥çš„"åˆæ³•"é”™è¯¯ï¼Œå¯ä»¥æ·»åŠ æŠ‘åˆ¶è§„åˆ™ï¼š

```python
# ç™½åå•ï¼šå·²çŸ¥æ­£ç¡®çš„"çŸ­"åŸå¸‚å
CITY_NAME_WHITELIST = {"NY", "LA", "SF", "DC"}  # çº½çº¦ã€æ´›æ‰çŸ¶ç­‰

# é»‘åå•ï¼šå·²çŸ¥é”™è¯¯çš„æå–ç»“æœ
CITY_NAME_BLACKLIST = {"USA", "United States", "Email"}
```

---

## ç‰ˆæœ¬å†å²

- **v1.0** (2026-01-27): åˆå§‹æ£€æµ‹ç­–ç•¥è®¾è®¡
  - ä¸‰å±‚æ£€æµ‹æœºåˆ¶
  - é”™è¯¯åˆ†ç±»ä½“ç³»
  - ä¼˜å…ˆçº§æ’åº
