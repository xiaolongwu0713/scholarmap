# æ•°æ®è´¨é‡æ¸…æ´—ç³»ç»Ÿ - æ•°æ®æ¨¡å‹è®¾è®¡

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [æ–°å¢æ•°æ®è¡¨](#æ–°å¢æ•°æ®è¡¨)
- [æ•°æ®æµ](#æ•°æ®æµ)
- [è¡¨å…³ç³»å›¾](#è¡¨å…³ç³»å›¾)
- [ç´¢å¼•è®¾è®¡](#ç´¢å¼•è®¾è®¡)

---

## æ¦‚è¿°

æœ¬æ–‡æ¡£å®šä¹‰æ•°æ®è´¨é‡æ¸…æ´—ç³»ç»Ÿæ‰€éœ€çš„æ–°æ•°æ®è¡¨ã€‚è¿™äº›è¡¨ç”¨äºè®°å½•é”™è¯¯æ£€æµ‹ã€ä¿®å¤è¿‡ç¨‹å’Œè´¨é‡æŠ¥å‘Šã€‚

### è®¾è®¡åŸåˆ™

1. **å¯è¿½æº¯æ€§**ï¼šè®°å½•æ¯ä¸ªé”™è¯¯çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸ
2. **å¯åˆ†ææ€§**ï¼šæ”¯æŒé”™è¯¯è¶‹åŠ¿åˆ†æå’Œè´¨é‡ç›‘æ§
3. **å¯æ‰©å±•æ€§**ï¼šæ˜“äºæ·»åŠ æ–°çš„é”™è¯¯ç±»å‹å’Œæ£€æµ‹æ–¹æ³•
4. **æ€§èƒ½ä¼˜åŒ–**ï¼šåˆç†çš„ç´¢å¼•è®¾è®¡ï¼Œæ”¯æŒé«˜æ•ˆæŸ¥è¯¢

---

## æ–°å¢æ•°æ®è¡¨

### 1. data_quality_logs

è®°å½•æ¯ä¸ªæ£€æµ‹åˆ°çš„é”™è¯¯çš„è¯¦ç»†ä¿¡æ¯ã€‚

```python
class DataQualityLog(Base):
    """æ•°æ®è´¨é‡æ—¥å¿—è¡¨ - è®°å½•æ¯æ¬¡æ£€æµ‹åˆ°çš„é”™è¯¯å’Œä¿®å¤è¿‡ç¨‹"""
    __tablename__ = "data_quality_logs"
    
    # ä¸»é”®
    id: Mapped[int] = mapped_column(Integer, primary_key=True, autoincrement=True)
    
    # æ‰¹æ¬¡ä¿¡æ¯
    batch_id: Mapped[str] = mapped_column(String(64), nullable=False, index=True)
    
    # å…³è”ä¿¡æ¯
    authorship_id: Mapped[int | None] = mapped_column(Integer, nullable=True, index=True)
    pmid: Mapped[str] = mapped_column(String(32), nullable=False, index=True)
    
    # ==================== é”™è¯¯ä¿¡æ¯ ====================
    
    # é”™è¯¯ç±»å‹ï¼š'extraction_error', 'geocoding_error', 'consistency_error'
    error_type: Mapped[str] = mapped_column(String(50), nullable=False, index=True)
    
    # é”™è¯¯ç±»åˆ«ï¼ˆå…·ä½“å­ç±»å‹ï¼‰
    error_category: Mapped[str] = mapped_column(String(100), nullable=False, index=True)
    # å¯èƒ½çš„å€¼ï¼š
    # - extraction_error: 'state_as_city', 'institution_as_city', 'department_as_city', 
    #                     'country_city_mismatch', 'low_confidence', 'missing_geo_data'
    # - geocoding_error: 'geocoding_null', 'wrong_coordinates', 'coordinate_anomaly'
    # - consistency_error: 'cache_inconsistent', 'duplicate_coordinates'
    
    # ä¸¥é‡ç¨‹åº¦ï¼š'critical', 'high', 'medium', 'low'
    severity: Mapped[str] = mapped_column(String(20), nullable=False, index=True)
    
    # ==================== åŸå§‹æ•°æ® ====================
    
    # åŸå§‹ affiliation å­—ç¬¦ä¸²
    original_affiliation: Mapped[str] = mapped_column(Text, nullable=False)
    
    # åŸå§‹æå–çš„åœ°ç†ä¿¡æ¯
    original_country: Mapped[str | None] = mapped_column(String(255), nullable=True)
    original_city: Mapped[str | None] = mapped_column(String(255), nullable=True)
    original_institution: Mapped[str | None] = mapped_column(String(500), nullable=True)
    
    # åŸå§‹åæ ‡ï¼ˆJSON: {lat: float, lng: float}ï¼‰
    original_coordinates: Mapped[dict | None] = mapped_column(JSONB, nullable=True)
    
    # ==================== æ£€æµ‹ä¿¡æ¯ ====================
    
    # æ£€æµ‹æ–¹æ³•
    detection_method: Mapped[str] = mapped_column(String(100), nullable=False)
    # å¯èƒ½çš„å€¼ï¼š'geocoding_failure', 'validation_rule', 'confidence_threshold', 
    #           'reverse_geocoding', 'consistency_check'
    
    # æ£€æµ‹åŸå› ï¼ˆè¯¦ç»†æè¿°ï¼‰
    detection_reason: Mapped[str] = mapped_column(Text, nullable=False)
    
    # æ£€æµ‹æ—¶é—´
    detected_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        nullable=False,
        index=True
    )
    
    # ==================== ä¿®å¤ä¿¡æ¯ ====================
    
    # æ˜¯å¦å°è¯•ä¿®å¤
    fix_attempted: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
    
    # ä¿®å¤æ–¹æ³•
    fix_method: Mapped[str | None] = mapped_column(String(100), nullable=True)
    # å¯èƒ½çš„å€¼ï¼š'llm_openai', 'llm_local', 'geocoding_retry', 
    #           'rule_correction', 'manual'
    
    # ä¿®å¤åçš„åœ°ç†ä¿¡æ¯
    fixed_country: Mapped[str | None] = mapped_column(String(255), nullable=True)
    fixed_city: Mapped[str | None] = mapped_column(String(255), nullable=True)
    fixed_institution: Mapped[str | None] = mapped_column(String(500), nullable=True)
    
    # ä¿®å¤åçš„åæ ‡ï¼ˆJSON: {lat: float, lng: float}ï¼‰
    fixed_coordinates: Mapped[dict | None] = mapped_column(JSONB, nullable=True)
    
    # ä¿®å¤æ—¶é—´
    fixed_at: Mapped[datetime | None] = mapped_column(DateTime(timezone=True), nullable=True)
    
    # ä¿®å¤æ˜¯å¦æˆåŠŸ
    fix_success: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
    
    # ä¿®å¤å¤±è´¥åŸå› 
    fix_failure_reason: Mapped[str | None] = mapped_column(Text, nullable=True)
    
    # ==================== éªŒè¯ä¿¡æ¯ ====================
    
    # æ˜¯å¦å·²éªŒè¯
    validated: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
    
    # éªŒè¯æ–¹æ³•
    validation_method: Mapped[str | None] = mapped_column(String(100), nullable=True)
    # å¯èƒ½çš„å€¼ï¼š'reverse_geocoding', 'manual_review', 'cross_reference'
    
    # éªŒè¯ç½®ä¿¡åº¦ï¼ˆ0.0-1.0ï¼‰
    validation_confidence: Mapped[float | None] = mapped_column(
        Float,
        nullable=True
    )
    
    # éªŒè¯å¤‡æ³¨
    validation_notes: Mapped[str | None] = mapped_column(Text, nullable=True)
    
    # ==================== å…ƒæ•°æ® ====================
    
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        server_default=func.now(),
        nullable=False
    )
    
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        server_default=func.now(),
        onupdate=func.now(),
        nullable=False
    )
    
    # ç´¢å¼•
    __table_args__ = (
        Index("idx_dql_batch_error_type", "batch_id", "error_type"),
        Index("idx_dql_severity_detected", "severity", "detected_at"),
        Index("idx_dql_fix_success", "fix_success", "fix_attempted"),
    )
```

### 2. data_cleaning_batches

è®°å½•æ¯æ¬¡æ¸…æ´—ä»»åŠ¡çš„æ±‡æ€»ä¿¡æ¯ã€‚

```python
class DataCleaningBatch(Base):
    """æ•°æ®æ¸…æ´—æ‰¹æ¬¡è¡¨ - è®°å½•æ¯æ¬¡æ¸…æ´—ä»»åŠ¡çš„æ±‡æ€»ä¿¡æ¯"""
    __tablename__ = "data_cleaning_batches"
    
    # ä¸»é”®
    id: Mapped[int] = mapped_column(Integer, primary_key=True, autoincrement=True)
    
    # æ‰¹æ¬¡ IDï¼ˆå”¯ä¸€æ ‡è¯†ç¬¦ï¼‰
    batch_id: Mapped[str] = mapped_column(String(64), unique=True, nullable=False, index=True)
    
    # ==================== æ‰§è¡Œä¿¡æ¯ ====================
    
    # æ¸…æ´—æ¨¡å¼ï¼š'full', 'incremental', 'validation_only'
    mode: Mapped[str] = mapped_column(String(50), nullable=False)
    
    # çŠ¶æ€ï¼š'running', 'completed', 'failed'
    status: Mapped[str] = mapped_column(String(20), nullable=False, index=True)
    
    # æ—¶é—´
    started_at: Mapped[datetime] = mapped_column(DateTime(timezone=True), nullable=False, index=True)
    completed_at: Mapped[datetime | None] = mapped_column(DateTime(timezone=True), nullable=True)
    
    # æ‰§è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰
    duration_seconds: Mapped[float | None] = mapped_column(Float, nullable=True)
    
    # ==================== ç»Ÿè®¡ä¿¡æ¯ ====================
    
    # æ£€æŸ¥çš„ authorships æ€»æ•°
    total_authorships_checked: Mapped[int] = mapped_column(Integer, default=0, nullable=False)
    
    # æ£€æµ‹åˆ°çš„é”™è¯¯æ€»æ•°
    errors_detected: Mapped[int] = mapped_column(Integer, default=0, nullable=False)
    
    # æŒ‰é”™è¯¯ç±»å‹åˆ†ç»„ç»Ÿè®¡ï¼ˆJSONï¼‰
    errors_by_type: Mapped[dict] = mapped_column(JSONB, nullable=False, default={})
    # æ ¼å¼ï¼š{"extraction_error": 100, "geocoding_error": 50, "consistency_error": 10}
    
    # æŒ‰é”™è¯¯ç±»åˆ«åˆ†ç»„ç»Ÿè®¡ï¼ˆJSONï¼‰
    errors_by_category: Mapped[dict] = mapped_column(JSONB, nullable=False, default={})
    # æ ¼å¼ï¼š{"state_as_city": 40, "geocoding_null": 30, ...}
    
    # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„ç»Ÿè®¡ï¼ˆJSONï¼‰
    errors_by_severity: Mapped[dict] = mapped_column(JSONB, nullable=False, default={})
    # æ ¼å¼ï¼š{"critical": 10, "high": 50, "medium": 80, "low": 20}
    
    # å°è¯•ä¿®å¤çš„æ•°é‡
    fixes_attempted: Mapped[int] = mapped_column(Integer, default=0, nullable=False)
    
    # ä¿®å¤æˆåŠŸçš„æ•°é‡
    fixes_successful: Mapped[int] = mapped_column(Integer, default=0, nullable=False)
    
    # ä¿®å¤å¤±è´¥çš„æ•°é‡
    fixes_failed: Mapped[int] = mapped_column(Integer, default=0, nullable=False)
    
    # ä¿®å¤æˆåŠŸç‡ï¼ˆ0.0-1.0ï¼‰
    fix_success_rate: Mapped[float | None] = mapped_column(Float, nullable=True)
    
    # ==================== é…ç½®ä¿¡æ¯ ====================
    
    # æ£€æµ‹é…ç½®ï¼ˆJSONï¼‰
    detection_config: Mapped[dict] = mapped_column(JSONB, nullable=False, default={})
    # æ ¼å¼ï¼š{"enable_extraction_check": true, "enable_geocoding_check": true, ...}
    
    # ä¿®å¤é…ç½®ï¼ˆJSONï¼‰
    fix_config: Mapped[dict] = mapped_column(JSONB, nullable=False, default={})
    # æ ¼å¼ï¼š{"use_local_llm": true, "llm_model": "llama3.1:8b", ...}
    
    # ==================== æŠ¥å‘Š ====================
    
    # æ±‡æ€»æŠ¥å‘Šï¼ˆMarkdown æ ¼å¼ï¼‰
    summary_report: Mapped[str | None] = mapped_column(Text, nullable=True)
    
    # é”™è¯¯æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœç”Ÿæˆï¼‰
    error_log_path: Mapped[str | None] = mapped_column(String(500), nullable=True)
    
    # ==================== å…ƒæ•°æ® ====================
    
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        server_default=func.now(),
        nullable=False
    )
    
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        server_default=func.now(),
        onupdate=func.now(),
        nullable=False
    )
    
    # ç´¢å¼•
    __table_args__ = (
        Index("idx_dcb_status_started", "status", "started_at"),
    )
```

### 3. geocoding_validations

éªŒè¯ geocoding ç»“æœçš„æ­£ç¡®æ€§ã€‚

```python
class GeocodingValidation(Base):
    """Geocoding éªŒè¯è¡¨ - éªŒè¯åæ ‡çš„æ­£ç¡®æ€§"""
    __tablename__ = "geocoding_validations"
    
    # ä¸»é”®ï¼ˆlocation_keyï¼‰
    location_key: Mapped[str] = mapped_column(String(500), primary_key=True)
    
    # åœ°ç†ä¿¡æ¯
    country: Mapped[str] = mapped_column(String(255), nullable=False, index=True)
    city: Mapped[str | None] = mapped_column(String(255), nullable=True, index=True)
    
    # ==================== Nominatim ç»“æœ ====================
    
    # Nominatim è¿”å›çš„åæ ‡
    nominatim_lat: Mapped[float | None] = mapped_column(Float, nullable=True)
    nominatim_lng: Mapped[float | None] = mapped_column(Float, nullable=True)
    
    # Nominatim è¿”å›çš„å®Œæ•´åœ°å€
    nominatim_display_name: Mapped[str | None] = mapped_column(Text, nullable=True)
    
    # Nominatim è¿”å›çš„è¯¦ç»†ä¿¡æ¯ï¼ˆJSONï¼‰
    nominatim_details: Mapped[dict | None] = mapped_column(JSONB, nullable=True)
    # æ ¼å¼ï¼š{"country": "United States", "state": "Massachusetts", "city": "Boston", ...}
    
    # ==================== éªŒè¯ä¿¡æ¯ ====================
    
    # æ˜¯å¦å·²éªŒè¯
    is_validated: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False, index=True)
    
    # éªŒè¯æ–¹æ³•
    validation_method: Mapped[str | None] = mapped_column(String(100), nullable=True)
    # å¯èƒ½çš„å€¼ï¼š'reverse_geocoding', 'alternative_geocoder', 'manual_review', 'cross_reference'
    
    # éªŒè¯ç½®ä¿¡åº¦ï¼ˆ0.0-1.0ï¼‰
    validation_confidence: Mapped[float | None] = mapped_column(Float, nullable=True)
    
    # éªŒè¯ç»“æœï¼š'correct', 'incorrect', 'uncertain'
    validation_result: Mapped[str | None] = mapped_column(String(20), nullable=True)
    
    # éªŒè¯å¤‡æ³¨
    validation_notes: Mapped[str | None] = mapped_column(Text, nullable=True)
    
    # ==================== ä¿®æ­£ä¿¡æ¯ ====================
    
    # å¦‚æœå‘ç°é”™è¯¯ï¼Œè®°å½•æ­£ç¡®çš„åæ ‡
    correct_lat: Mapped[float | None] = mapped_column(Float, nullable=True)
    correct_lng: Mapped[float | None] = mapped_column(Float, nullable=True)
    
    # ä¿®æ­£çš„æ¥æº
    correction_source: Mapped[str | None] = mapped_column(String(100), nullable=True)
    # å¯èƒ½çš„å€¼ï¼š'google_maps', 'mapbox', 'manual', 'alternative_geocoder'
    
    # ä¿®æ­£æ—¶é—´
    corrected_at: Mapped[datetime | None] = mapped_column(DateTime(timezone=True), nullable=True)
    
    # ==================== å…ƒæ•°æ® ====================
    
    # éªŒè¯æ—¶é—´
    validated_at: Mapped[datetime | None] = mapped_column(DateTime(timezone=True), nullable=True)
    
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        server_default=func.now(),
        nullable=False
    )
    
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        server_default=func.now(),
        onupdate=func.now(),
        nullable=False
    )
    
    # ç´¢å¼•
    __table_args__ = (
        Index("idx_gv_country_city", "country", "city"),
        Index("idx_gv_validated", "is_validated", "validation_result"),
    )
```

---

## æ•°æ®æµ

### å®Œæ•´æ•°æ®æµå›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ•°æ®æ¸…æ´—ä»»åŠ¡å¯åŠ¨                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”œâ”€> åˆ›å»º data_cleaning_batches è®°å½•
                  â”‚   ï¼ˆbatch_id, mode, status='running'ï¼‰
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              æ­¥éª¤ 1: é€‰æ‹©è¦æ£€æŸ¥çš„ authorships               â”‚
â”‚  - full: æ‰€æœ‰æ•°æ®                                            â”‚
â”‚  - incremental: æœ€è¿‘ N å¤©çš„æ•°æ®                             â”‚
â”‚  - validation_only: æœ‰é—®é¢˜çš„æ•°æ®                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              æ­¥éª¤ 2: æ£€æµ‹é”™è¯¯                                â”‚
â”‚  - ExtractionQualityDetector                                 â”‚
â”‚  - GeocodingQualityDetector                                 â”‚
â”‚  - ConsistencyDetector                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”œâ”€> å‘ç°é”™è¯¯ â†’ åˆ›å»º data_quality_logs è®°å½•
                  â”‚   ï¼ˆauthorship_id, error_type, error_category, 
                  â”‚    detection_method, original_dataï¼‰
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              æ­¥éª¤ 3: ä¿®å¤é”™è¯¯ï¼ˆå¯é€‰ï¼‰                        â”‚
â”‚  - LLM é‡æ–°æå–                                              â”‚
â”‚  - Geocoding é‡è¯•                                           â”‚
â”‚  - éªŒè¯ä¿®å¤ç»“æœ                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”œâ”€> ä¿®å¤æˆåŠŸ â†’ æ›´æ–° data_quality_logs
                  â”‚   ï¼ˆfix_attempted=true, fix_method, fixed_data,
                  â”‚    fix_success=trueï¼‰
                  â”‚
                  â”œâ”€> ä¿®å¤å¤±è´¥ â†’ æ›´æ–° data_quality_logs
                  â”‚   ï¼ˆfix_attempted=true, fix_success=false,
                  â”‚    fix_failure_reasonï¼‰
                  â”‚
                  â”œâ”€> æ›´æ–° affiliation_cacheï¼ˆä¿®å¤çš„æå–ç»“æœï¼‰
                  â”‚
                  â”œâ”€> æ›´æ–° geocoding_cacheï¼ˆä¿®å¤çš„åæ ‡ï¼‰
                  â”‚   â””â”€> åŒæ—¶æ›´æ–° geocoding_validations
                  â”‚
                  â””â”€> æ›´æ–° authorship è¡¨ï¼ˆä¿®å¤çš„åœ°ç†ä¿¡æ¯ï¼‰
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              æ­¥éª¤ 4: ç”ŸæˆæŠ¥å‘Š                                â”‚
â”‚  - ç»Ÿè®¡é”™è¯¯æ•°é‡                                             â”‚
â”‚  - åˆ†æé”™è¯¯è¶‹åŠ¿                                             â”‚
â”‚  - è¯„ä¼°ä¿®å¤æ•ˆæœ                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”œâ”€> æ›´æ–° data_cleaning_batches
                  â”‚   ï¼ˆstatus='completed', statistics, 
                  â”‚    summary_reportï¼‰
                  â”‚
                  â””â”€> å®Œæˆ
```

---

## è¡¨å…³ç³»å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  data_cleaning_batches      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  id (PK)                    â”‚
â”‚  batch_id (UNIQUE)          â”‚
â”‚  mode                       â”‚
â”‚  status                     â”‚
â”‚  statistics (JSONB)         â”‚
â”‚  summary_report (TEXT)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ 1:N
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  data_quality_logs          â”‚ N:1    â”‚  authorship          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  id (PK)                    â”‚        â”‚  id (PK)             â”‚
â”‚  batch_id (FK)              â”‚        â”‚  pmid                â”‚
â”‚  authorship_id (FK)         â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”‚  country             â”‚
â”‚  pmid                       â”‚        â”‚  city                â”‚
â”‚  error_type                 â”‚        â”‚  institution         â”‚
â”‚  error_category             â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  severity                   â”‚
â”‚  original_data (JSONB)      â”‚
â”‚  fixed_data (JSONB)         â”‚
â”‚  fix_success                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  geocoding_validations      â”‚        â”‚  geocoding_cache     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚        â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  location_key (PK)          â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”‚  location_key (PK)   â”‚
â”‚  country                    â”‚        â”‚  latitude            â”‚
â”‚  city                       â”‚        â”‚  longitude           â”‚
â”‚  nominatim_lat              â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  nominatim_lng              â”‚
â”‚  is_validated               â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  validation_result          â”‚        â”‚  affiliation_cache   â”‚
â”‚  correct_lat (nullable)     â”‚        â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  correct_lng (nullable)     â”‚        â”‚  affiliation_raw(PK) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  country             â”‚
                                        â”‚  city                â”‚
                                        â”‚  institution         â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ç´¢å¼•è®¾è®¡

### data_quality_logs ç´¢å¼•

```sql
-- æŒ‰æ‰¹æ¬¡å’Œé”™è¯¯ç±»å‹æŸ¥è¯¢
CREATE INDEX idx_dql_batch_error_type ON data_quality_logs (batch_id, error_type);

-- æŒ‰ä¸¥é‡ç¨‹åº¦å’Œæ£€æµ‹æ—¶é—´æŸ¥è¯¢ï¼ˆç”¨äºè¶‹åŠ¿åˆ†æï¼‰
CREATE INDEX idx_dql_severity_detected ON data_quality_logs (severity, detected_at);

-- æŒ‰ä¿®å¤ç»“æœæŸ¥è¯¢
CREATE INDEX idx_dql_fix_success ON data_quality_logs (fix_success, fix_attempted);

-- æŒ‰ authorship æŸ¥è¯¢ï¼ˆæŸ¥çœ‹å•ä¸ª authorship çš„é”™è¯¯å†å²ï¼‰
CREATE INDEX idx_dql_authorship_id ON data_quality_logs (authorship_id);

-- æŒ‰ PMID æŸ¥è¯¢ï¼ˆæŸ¥çœ‹å•ä¸ªè®ºæ–‡çš„æ‰€æœ‰é”™è¯¯ï¼‰
CREATE INDEX idx_dql_pmid ON data_quality_logs (pmid);

-- æŒ‰é”™è¯¯ç±»å‹æŸ¥è¯¢
CREATE INDEX idx_dql_error_type ON data_quality_logs (error_type);

-- æŒ‰é”™è¯¯ç±»åˆ«æŸ¥è¯¢
CREATE INDEX idx_dql_error_category ON data_quality_logs (error_category);
```

### data_cleaning_batches ç´¢å¼•

```sql
-- æŒ‰æ‰¹æ¬¡ ID æŸ¥è¯¢ï¼ˆå”¯ä¸€ç´¢å¼•ï¼‰
CREATE UNIQUE INDEX idx_dcb_batch_id ON data_cleaning_batches (batch_id);

-- æŒ‰çŠ¶æ€å’Œå¼€å§‹æ—¶é—´æŸ¥è¯¢
CREATE INDEX idx_dcb_status_started ON data_cleaning_batches (status, started_at);
```

### geocoding_validations ç´¢å¼•

```sql
-- æŒ‰å›½å®¶å’ŒåŸå¸‚æŸ¥è¯¢
CREATE INDEX idx_gv_country_city ON geocoding_validations (country, city);

-- æŒ‰éªŒè¯ç»“æœæŸ¥è¯¢
CREATE INDEX idx_gv_validated ON geocoding_validations (is_validated, validation_result);
```

---

## æ•°æ®åº“è¿ç§»

ä½¿ç”¨ Alembic åˆ›å»ºè¿ç§»è„šæœ¬ï¼š

```bash
# åˆ›å»ºæ–°çš„è¿ç§»
alembic revision --autogenerate -m "Add data cleaning tables"

# åº”ç”¨è¿ç§»
alembic upgrade head
```

è¿ç§»è„šæœ¬ç¤ºä¾‹ï¼š

```python
"""Add data cleaning tables

Revision ID: xxxx
Revises: yyyy
Create Date: 2026-01-27

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers
revision = 'xxxx'
down_revision = 'yyyy'

def upgrade():
    # åˆ›å»º data_quality_logs è¡¨
    op.create_table(
        'data_quality_logs',
        # ... åˆ—å®šä¹‰ ...
    )
    
    # åˆ›å»ºç´¢å¼•
    op.create_index('idx_dql_batch_error_type', 'data_quality_logs', ['batch_id', 'error_type'])
    # ... å…¶ä»–ç´¢å¼• ...
    
    # åˆ›å»º data_cleaning_batches è¡¨
    op.create_table(
        'data_cleaning_batches',
        # ... åˆ—å®šä¹‰ ...
    )
    
    # åˆ›å»º geocoding_validations è¡¨
    op.create_table(
        'geocoding_validations',
        # ... åˆ—å®šä¹‰ ...
    )

def downgrade():
    op.drop_table('geocoding_validations')
    op.drop_table('data_cleaning_batches')
    op.drop_table('data_quality_logs')
```

---

## æŸ¥è¯¢ç¤ºä¾‹

### 1. æŸ¥è¯¢ç‰¹å®šæ‰¹æ¬¡çš„æ‰€æœ‰é”™è¯¯

```python
async def get_batch_errors(batch_id: str) -> List[DataQualityLog]:
    """è·å–ç‰¹å®šæ‰¹æ¬¡çš„æ‰€æœ‰é”™è¯¯"""
    result = await session.execute(
        select(DataQualityLog)
        .where(DataQualityLog.batch_id == batch_id)
        .order_by(DataQualityLog.severity.desc(), DataQualityLog.detected_at)
    )
    return result.scalars().all()
```

### 2. ç»Ÿè®¡é”™è¯¯ç±»å‹åˆ†å¸ƒ

```python
async def get_error_distribution(start_date: datetime, end_date: datetime) -> Dict:
    """ç»Ÿè®¡æ—¶é—´æ®µå†…çš„é”™è¯¯ç±»å‹åˆ†å¸ƒ"""
    result = await session.execute(
        select(
            DataQualityLog.error_category,
            func.count(DataQualityLog.id).label('count')
        )
        .where(DataQualityLog.detected_at.between(start_date, end_date))
        .group_by(DataQualityLog.error_category)
        .order_by(func.count(DataQualityLog.id).desc())
    )
    return {row.error_category: row.count for row in result}
```

### 3. æŸ¥è¯¢ä¿®å¤æˆåŠŸç‡

```python
async def get_fix_success_rate(batch_id: str) -> float:
    """è®¡ç®—ç‰¹å®šæ‰¹æ¬¡çš„ä¿®å¤æˆåŠŸç‡"""
    result = await session.execute(
        select(
            func.count(DataQualityLog.id).filter(DataQualityLog.fix_attempted).label('attempted'),
            func.count(DataQualityLog.id).filter(DataQualityLog.fix_success).label('successful')
        )
        .where(DataQualityLog.batch_id == batch_id)
    )
    row = result.one()
    return row.successful / row.attempted if row.attempted > 0 else 0.0
```

### 4. æŸ¥è¯¢éœ€è¦äººå·¥å®¡æ ¸çš„é”™è¯¯

```python
async def get_errors_requiring_manual_review() -> List[DataQualityLog]:
    """æŸ¥è¯¢éœ€è¦äººå·¥å®¡æ ¸çš„é”™è¯¯ï¼ˆä¿®å¤å¤±è´¥æˆ–é«˜ä¸¥é‡åº¦ï¼‰"""
    result = await session.execute(
        select(DataQualityLog)
        .where(
            and_(
                DataQualityLog.fix_attempted == True,
                DataQualityLog.fix_success == False,
                DataQualityLog.severity.in_(['critical', 'high'])
            )
        )
        .order_by(DataQualityLog.severity.desc(), DataQualityLog.detected_at.desc())
    )
    return result.scalars().all()
```

---

## ç‰ˆæœ¬å†å²

- **v1.0** (2026-01-27): åˆå§‹æ•°æ®æ¨¡å‹è®¾è®¡
  - data_quality_logs è¡¨
  - data_cleaning_batches è¡¨
  - geocoding_validations è¡¨
