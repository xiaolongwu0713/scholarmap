# 数据质量清洗系统 - 总体概述

## 📋 目录

- [问题背景](#问题背景)
- [设计目标](#设计目标)
- [系统概览](#系统概览)
- [关键特性](#关键特性)
- [相关文档](#相关文档)

---

## 问题背景

### 当前数据质量问题

在 ScholarMap 的 run 创建过程中，经常发生以下数据质量问题：

#### 1. **提取错误**
程序在提取地理信息（institution/city/country）时可能出现错误：

- **Rule-based 提取错误**：
  - 将州缩写（MD, OH, CA）误识别为城市名
  - 将机构名（Harvard Medical School）误识别为城市
  - 将部门名（Department of Neurology）误识别为城市
  - 无法识别非标准格式的国家名

- **LLM 提取错误**（目前没有验证机制）：
  - LLM 也可能产生错误的提取结果
  - 提取的城市/国家可能不匹配
  - 可能返回不完整的信息

#### 2. **Geocoding 错误**
Nominatim（OpenStreetMap）可能给出错误的 geocoding 结果：

- **同名城市问题**：返回错误国家的同名城市坐标
- **拼写问题**：国家/城市名称拼写导致 geocoding 失败
- **坐标异常**：返回的坐标不在预期的国家/地区范围内
- **缓存污染**：错误的 null 坐标被缓存，影响后续查询

#### 3. **数据不一致**
数据库表之间可能存在不一致：

- `affiliation_cache` 和 `authorship` 表数据不同步
- `geocoding_cache` 中的坐标与实际地理位置不符
- 相同的 affiliation 在不同 run 中产生不同结果

### 问题影响

这些错误会导致：

❌ **地图聚合错误**：城市/国家统计不准确
❌ **可视化缺失**：无效坐标导致研究者无法在地图上显示
❌ **用户体验差**：搜索结果不准确，降低平台可信度
❌ **数据污染**：错误的缓存影响后续所有查询
❌ **难以追溯**：不知道错误的来源和原因，无法改进程序

---

## 设计目标

本数据质量清洗系统旨在解决上述问题，实现以下目标：

### 1. **自动化检测**
- ✅ 自动检测提取质量问题
- ✅ 自动检测 geocoding 质量问题
- ✅ 自动检测数据一致性问题

### 2. **系统化修复**
- ✅ 使用 LLM（OpenAI 或本地）重新提取错误数据
- ✅ 重新进行 geocoding 并验证结果
- ✅ 修复数据库中的不一致数据

### 3. **完整追溯**
- ✅ 记录每个错误的来源（哪个 affiliation、哪个 PMID）
- ✅ 记录错误的类型和原因
- ✅ 记录修复的方法和结果
- ✅ 生成详细的质量报告

### 4. **持续改进**
- ✅ 通过错误分析改进提取算法
- ✅ 识别系统性问题
- ✅ 追踪数据质量趋势
- ✅ 为程序优化提供数据支持

### 5. **灵活可配置**
- ✅ 支持全量清洗、增量清洗、仅验证模式
- ✅ 支持 OpenAI 和本地 LLM（Ollama）
- ✅ 可配置检测规则和修复策略
- ✅ 定期自动运行，无需人工干预

---

## 系统概览

### 系统架构

```
┌─────────────────────────────────────────────────────────────┐
│           数据质量清洗系统 (Cron Job)                         │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  1. 数据质量检测器 (Quality Detector)                         │
│     ├─ 提取质量检测                                           │
│     ├─ Geocoding 质量检测                                    │
│     └─ 数据一致性检测                                         │
│                                                               │
│  2. 错误分类器 (Error Classifier)                             │
│     ├─ 按错误类型分类                                         │
│     ├─ 按严重程度分级                                         │
│     └─ 记录错误来源                                           │
│                                                               │
│  3. 数据修复器 (Data Fixer)                                   │
│     ├─ LLM 重新提取                                           │
│     ├─ Geocoding 重试/验证                                    │
│     └─ 本地 LLM 支持（Ollama）                                │
│                                                               │
│  4. 质量报告器 (Quality Reporter)                             │
│     ├─ 生成清洗报告                                           │
│     ├─ 记录修复历史                                           │
│     └─ 数据质量指标                                           │
│                                                               │
└─────────────────────────────────────────────────────────────┘
```

### 工作流程

```
开始
  │
  ├─> 步骤 1: 选择要检查的数据（全量/增量/问题数据）
  │
  ├─> 步骤 2: 检测错误
  │   ├─ 提取质量检测
  │   ├─ Geocoding 质量检测
  │   └─ 数据一致性检测
  │
  ├─> 步骤 3: 分类和优先级排序
  │   ├─ 按错误类型分类
  │   ├─ 按严重程度分级
  │   └─ 记录到 data_quality_logs 表
  │
  ├─> 步骤 4: 修复错误（可选）
  │   ├─ LLM 重新提取
  │   ├─ Geocoding 重试
  │   ├─ 验证修复结果
  │   └─ 更新数据库
  │
  ├─> 步骤 5: 生成报告
  │   ├─ 统计信息
  │   ├─ 错误分析
  │   ├─ 修复结果
  │   └─ 改进建议
  │
  └─> 结束
```

---

## 关键特性

### 1. **三层检测机制**

#### 提取质量检测
- 州缩写检测
- 机构名检测
- 国家/城市匹配验证
- 置信度阈值检查

#### Geocoding 质量检测
- Null 坐标检测
- 反向 geocoding 验证
- 坐标异常检测（海洋、沙漠等）
- 国家边界验证

#### 数据一致性检测
- 缓存与数据库一致性
- 重复/冲突坐标检测
- 相同 affiliation 不同结果检测

### 2. **智能修复策略**

#### LLM 修复
- 批量重新提取错误的 affiliations
- 支持 OpenAI GPT-4 和本地 Ollama
- 验证 LLM 结果避免二次错误

#### Geocoding 修复
- 重新调用 Nominatim
- 使用替代查询策略
- 坐标验证和异常过滤

#### 缓存更新
- 覆盖错误的 affiliation_cache
- 更新 geocoding_cache
- 同步更新 authorship 表

### 3. **完整的错误追溯**

每个错误记录包含：
- **来源信息**：authorship_id, pmid, affiliation_raw
- **错误信息**：error_type, error_category, severity
- **检测信息**：detection_method, detection_reason, detected_at
- **原始数据**：original_country, original_city, original_coordinates
- **修复信息**：fix_method, fixed_data, fix_success
- **验证信息**：validation_method, validation_confidence

### 4. **灵活的运行模式**

#### 全量模式（Full）
- 检查数据库中所有 authorships
- 适合初始清洗或大规模质量审计
- 建议每周运行一次

#### 增量模式（Incremental）
- 只检查最近 N 天的数据
- 适合日常维护
- 建议每天运行一次

#### 验证模式（Validation Only）
- 只检测不修复
- 用于质量监控和报告
- 建议每小时运行一次

### 5. **本地 LLM 支持**

使用 Ollama 运行本地 LLM（如 Llama 3.1）：
- ✅ **无 API 成本**：不需要调用 OpenAI API
- ✅ **无速率限制**：可以更快地处理大量数据
- ✅ **隐私保护**：数据不离开本地服务器
- ✅ **离线运行**：不依赖外部服务

推荐模型：
- `llama3.1:8b` - 平衡性能和准确度
- `mistral:7b` - 更快的推理速度
- `qwen2.5:7b` - 中文支持更好

---

## 相关文档

本系统的详细设计文档：

1. **[ARCHITECTURE.md](./ARCHITECTURE.md)** - 系统架构设计
2. **[DATA_MODELS.md](./DATA_MODELS.md)** - 数据模型设计
3. **[DETECTION_STRATEGIES.md](./DETECTION_STRATEGIES.md)** - 检测策略详解
4. **[FIXING_STRATEGIES.md](./FIXING_STRATEGIES.md)** - 修复策略详解
5. **[IMPLEMENTATION_PLAN.md](./IMPLEMENTATION_PLAN.md)** - 实施计划
6. **[CRON_CONFIGURATION.md](./CRON_CONFIGURATION.md)** - Cron 任务配置
7. **[REPORTING.md](./REPORTING.md)** - 报告系统设计

---

## 预期效果

实施本系统后，预期达到：

### 数据质量提升
- 🎯 **提取准确率**：从 ~85% 提升至 >95%
- 🎯 **Geocoding 成功率**：从 ~70% 提升至 >90%
- 🎯 **地图可视化完整度**：从 ~60% 提升至 >85%

### 运维效率提升
- ⚡ **自动化清洗**：无需人工干预
- ⚡ **问题快速定位**：详细的错误追溯
- ⚡ **持续改进**：数据驱动的算法优化

### 用户体验提升
- 😊 **更准确的地图**：减少错误标注
- 😊 **更完整的数据**：更多研究者和机构被正确显示
- 😊 **更高的可信度**：提升平台专业性

---

## 版本历史

- **v1.0** (2026-01-27): 初始设计文档
  - 三层检测机制
  - 智能修复策略
  - 完整错误追溯
  - 本地 LLM 支持
