# æ•°æ®è´¨é‡æ¸…æ´—ç³»ç»Ÿ - Cron ä»»åŠ¡é…ç½®

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [å®‰è£…å’Œé…ç½®](#å®‰è£…å’Œé…ç½®)
- [è¿è¡Œæ¨¡å¼](#è¿è¡Œæ¨¡å¼)
- [è°ƒåº¦ç­–ç•¥](#è°ƒåº¦ç­–ç•¥)
- [æ—¥å¿—ç®¡ç†](#æ—¥å¿—ç®¡ç†)
- [ç›‘æ§å’Œå‘Šè­¦](#ç›‘æ§å’Œå‘Šè­¦)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## æ¦‚è¿°

æ•°æ®æ¸…æ´—ç³»ç»Ÿé€šè¿‡ Cron å®šæ—¶ä»»åŠ¡è‡ªåŠ¨è¿è¡Œï¼Œæ— éœ€äººå·¥å¹²é¢„ã€‚ç³»ç»Ÿæ”¯æŒä¸‰ç§è¿è¡Œæ¨¡å¼ï¼Œå¯ä»¥æ ¹æ®éœ€è¦çµæ´»è°ƒåº¦ã€‚

### ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Linux/Unix/macOS
- **Python**: 3.11+
- **æ•°æ®åº“**: PostgreSQL
- **å¯é€‰**: Ollamaï¼ˆæœ¬åœ° LLMï¼‰

---

## å®‰è£…å’Œé…ç½®

### 1. åˆ›å»ºæ¸…æ´—è„šæœ¬

**æ–‡ä»¶**: `cron_job/data_cleaning.py`

```python
#!/usr/bin/env python3
"""
æ•°æ®è´¨é‡æ¸…æ´—ä»»åŠ¡

ç”¨æ³•:
    python data_cleaning.py --mode incremental
    python data_cleaning.py --mode full --use-local-llm
    python data_cleaning.py --mode validation_only
"""

import sys
import os
import argparse
import asyncio
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from backend.app.cleaning.data_cleaning_job import DataCleaningJob, CleaningConfig
from backend.app.core.logger import get_logger

logger = get_logger(__name__)


async def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='æ•°æ®è´¨é‡æ¸…æ´—ä»»åŠ¡')
    
    parser.add_argument(
        '--mode',
        choices=['full', 'incremental', 'validation_only'],
        default='incremental',
        help='æ¸…æ´—æ¨¡å¼: full (å…¨é‡), incremental (å¢é‡), validation_only (ä»…éªŒè¯)'
    )
    
    parser.add_argument(
        '--use-local-llm',
        action='store_true',
        help='ä½¿ç”¨æœ¬åœ° LLM (Ollama) è€Œä¸æ˜¯ OpenAI'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='è¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸ä¿®å¤é”™è¯¯ï¼Œä¸æ›´æ–°æ•°æ®åº“ï¼‰'
    )
    
    parser.add_argument(
        '--batch-size',
        type=int,
        default=20,
        help='LLM æ‰¹é‡å¤„ç†å¤§å°'
    )
    
    parser.add_argument(
        '--max-errors',
        type=int,
        default=None,
        help='æœ€å¤šå¤„ç†å¤šå°‘ä¸ªé”™è¯¯ï¼ˆç”¨äºæµ‹è¯•ï¼‰'
    )
    
    args = parser.parse_args()
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = datetime.now()
    logger.info("=" * 80)
    logger.info(f"ğŸ§¹ æ•°æ®è´¨é‡æ¸…æ´—ä»»åŠ¡å¼€å§‹")
    logger.info(f"   æ¨¡å¼: {args.mode}")
    logger.info(f"   ä½¿ç”¨æœ¬åœ° LLM: {args.use_local_llm}")
    logger.info(f"   è¯•è¿è¡Œ: {args.dry_run}")
    logger.info(f"   å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 80)
    
    try:
        # åˆ›å»ºé…ç½®
        config = CleaningConfig(
            use_local_llm=args.use_local_llm,
            enable_fix=not args.dry_run,
            batch_size=args.batch_size,
            max_errors_to_process=args.max_errors
        )
        
        # åˆ›å»ºæ¸…æ´—ä»»åŠ¡
        job = DataCleaningJob(config)
        
        # è¿è¡Œæ¸…æ´—
        report = await job.run(mode=args.mode)
        
        # è¾“å‡ºæŠ¥å‘Š
        logger.info("\n" + report)
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("=" * 80)
        logger.info(f"âœ… æ•°æ®è´¨é‡æ¸…æ´—ä»»åŠ¡å®Œæˆ")
        logger.info(f"   ç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"   æ€»è€—æ—¶: {duration:.1f} ç§’ ({duration/60:.1f} åˆ†é’Ÿ)")
        logger.info("=" * 80)
        
        return 0
        
    except Exception as e:
        logger.error("=" * 80)
        logger.error(f"âŒ æ•°æ®è´¨é‡æ¸…æ´—ä»»åŠ¡å¤±è´¥")
        logger.error(f"   é”™è¯¯: {str(e)}")
        logger.error("=" * 80)
        logger.exception(e)
        return 1


if __name__ == '__main__':
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
```

### 2. åˆ›å»º Shell åŒ…è£…è„šæœ¬

**æ–‡ä»¶**: `cron_job/data_cleaning.sh`

```bash
#!/bin/bash
#
# æ•°æ®è´¨é‡æ¸…æ´—ä»»åŠ¡ Shell åŒ…è£…è„šæœ¬
#
# ç”¨æ³•:
#   ./data_cleaning.sh incremental
#   ./data_cleaning.sh full
#   ./data_cleaning.sh validation_only
#

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# ==================== é…ç½® ====================

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

# Python è§£é‡Šå™¨
PYTHON="${PROJECT_ROOT}/venv/bin/python"

# æ—¥å¿—ç›®å½•
LOG_DIR="${PROJECT_ROOT}/logs/cleaning"
mkdir -p "$LOG_DIR"

# æ¸…æ´—è„šæœ¬
CLEANING_SCRIPT="${PROJECT_ROOT}/cron_job/data_cleaning.py"

# ç¯å¢ƒå˜é‡
export PYTHONPATH="$PROJECT_ROOT"
export PYTHONUNBUFFERED=1

# åŠ è½½ .env æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
if [ -f "${PROJECT_ROOT}/.env" ]; then
    export $(cat "${PROJECT_ROOT}/.env" | grep -v '^#' | xargs)
fi

# ==================== å‚æ•° ====================

MODE="${1:-incremental}"  # é»˜è®¤å¢é‡æ¨¡å¼
USE_LOCAL_LLM="${USE_LOCAL_LLM:-false}"  # ä»ç¯å¢ƒå˜é‡è¯»å–

# æ—¥å¿—æ–‡ä»¶
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
LOG_FILE="${LOG_DIR}/cleaning_${MODE}_${TIMESTAMP}.log"

# ==================== æ‰§è¡Œ ====================

echo "ğŸ§¹ å¼€å§‹æ•°æ®æ¸…æ´—ä»»åŠ¡..."
echo "   æ¨¡å¼: $MODE"
echo "   æ—¥å¿—: $LOG_FILE"

# æ„å»ºå‘½ä»¤
CMD="$PYTHON $CLEANING_SCRIPT --mode $MODE"

if [ "$USE_LOCAL_LLM" = "true" ]; then
    CMD="$CMD --use-local-llm"
fi

# è¿è¡Œæ¸…æ´—ä»»åŠ¡ï¼Œè¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶
$CMD 2>&1 | tee "$LOG_FILE"

EXIT_CODE=${PIPESTATUS[0]}

# æ£€æŸ¥é€€å‡ºç 
if [ $EXIT_CODE -eq 0 ]; then
    echo "âœ… æ•°æ®æ¸…æ´—ä»»åŠ¡å®Œæˆ"
else
    echo "âŒ æ•°æ®æ¸…æ´—ä»»åŠ¡å¤±è´¥ (é€€å‡ºç : $EXIT_CODE)"
    
    # å‘é€å‘Šè­¦é‚®ä»¶ï¼ˆå¯é€‰ï¼‰
    if command -v mail &> /dev/null; then
        echo "æ•°æ®æ¸…æ´—ä»»åŠ¡å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—: $LOG_FILE" | \
            mail -s "[ScholarMap] æ•°æ®æ¸…æ´—å¤±è´¥" admin@scholarmap.com
    fi
fi

# ==================== æ¸…ç† ====================

# åˆ é™¤ 7 å¤©å‰çš„æ—¥å¿—æ–‡ä»¶
find "$LOG_DIR" -name "cleaning_*.log" -mtime +7 -delete

exit $EXIT_CODE
```

### 3. è®¾ç½®æƒé™

```bash
# ç»™è„šæœ¬æ·»åŠ æ‰§è¡Œæƒé™
chmod +x cron_job/data_cleaning.sh
chmod +x cron_job/data_cleaning.py
```

---

## è¿è¡Œæ¨¡å¼

### 1. Full Modeï¼ˆå…¨é‡æ¸…æ´—ï¼‰

æ£€æŸ¥æ•°æ®åº“ä¸­**æ‰€æœ‰** authorships çš„æ•°æ®è´¨é‡ã€‚

**ç‰¹ç‚¹**:
- âœ… æœ€å½»åº•çš„æ¸…æ´—
- âœ… å‘ç°æ‰€æœ‰å†å²é”™è¯¯
- âŒ è€—æ—¶é•¿ï¼ˆå¯èƒ½æ•°å°æ—¶ï¼‰
- âŒ èµ„æºæ¶ˆè€—å¤§

**é€‚ç”¨åœºæ™¯**:
- åˆæ¬¡éƒ¨ç½²æ¸…æ´—ç³»ç»Ÿ
- å¤§è§„æ¨¡æ•°æ®è´¨é‡å®¡è®¡
- æå–ç®—æ³•é‡å¤§æ›´æ–°å

**è¿è¡Œé¢‘ç‡**: æ¯å‘¨ä¸€æ¬¡ï¼ˆå»ºè®®å‘¨æœ«å‡Œæ™¨ï¼‰

**ç¤ºä¾‹**:
```bash
./cron_job/data_cleaning.sh full
```

### 2. Incremental Modeï¼ˆå¢é‡æ¸…æ´—ï¼‰

åªæ£€æŸ¥**æœ€è¿‘ N å¤©**çš„ authorshipsã€‚

**ç‰¹ç‚¹**:
- âœ… é€Ÿåº¦å¿«
- âœ… èµ„æºæ¶ˆè€—å°
- âœ… é€‚åˆæ—¥å¸¸ç»´æŠ¤
- âŒ ä¸è¦†ç›–å†å²æ•°æ®

**é…ç½®**:
```python
# backend/app/cleaning/config.py
class CleaningConfig:
    incremental_days: int = 7  # æ£€æŸ¥æœ€è¿‘ 7 å¤©çš„æ•°æ®
```

**é€‚ç”¨åœºæ™¯**:
- æ—¥å¸¸æ•°æ®è´¨é‡ç»´æŠ¤
- æ–°å¢æ•°æ®çš„è´¨é‡æ£€æŸ¥

**è¿è¡Œé¢‘ç‡**: æ¯å¤©ä¸€æ¬¡ï¼ˆå»ºè®®å‡Œæ™¨ï¼‰

**ç¤ºä¾‹**:
```bash
./cron_job/data_cleaning.sh incremental
```

### 3. Validation Only Modeï¼ˆä»…éªŒè¯ï¼‰

åªæ£€æµ‹é”™è¯¯ï¼Œ**ä¸è¿›è¡Œä¿®å¤**ã€‚

**ç‰¹ç‚¹**:
- âœ… é€Ÿåº¦å¿«
- âœ… æ— å‰¯ä½œç”¨
- âœ… é€‚åˆç›‘æ§
- âŒ ä¸ä¿®å¤é—®é¢˜

**é€‚ç”¨åœºæ™¯**:
- æ•°æ®è´¨é‡ç›‘æ§
- ç”Ÿæˆè´¨é‡æŠ¥å‘Š
- è¯„ä¼°æ¸…æ´—æ•ˆæœ

**è¿è¡Œé¢‘ç‡**: æ¯å°æ—¶ä¸€æ¬¡

**ç¤ºä¾‹**:
```bash
./cron_job/data_cleaning.sh validation_only
```

---

## è°ƒåº¦ç­–ç•¥

### æ¨èçš„ Cron é…ç½®

ç¼–è¾‘ crontabï¼š

```bash
crontab -e
```

æ·»åŠ ä»¥ä¸‹é…ç½®ï¼š

```bash
# ==================== æ•°æ®è´¨é‡æ¸…æ´—ä»»åŠ¡ ====================

# è®¾ç½®ç¯å¢ƒå˜é‡
SHELL=/bin/bash
PATH=/usr/local/bin:/usr/bin:/bin
PROJECT_ROOT=/app/scholarmap

# æ¯å¤©å‡Œæ™¨ 2 ç‚¹è¿è¡Œå¢é‡æ¸…æ´—ï¼ˆå‘¨ä¸€åˆ°å‘¨å…­ï¼‰
0 2 * * 1-6 cd $PROJECT_ROOT && ./cron_job/data_cleaning.sh incremental

# æ¯å‘¨æ—¥å‡Œæ™¨ 3 ç‚¹è¿è¡Œå…¨é‡æ¸…æ´—
0 3 * * 0 cd $PROJECT_ROOT && ./cron_job/data_cleaning.sh full

# æ¯å°æ—¶è¿è¡Œä¸€æ¬¡éªŒè¯ï¼ˆç”Ÿæˆè´¨é‡æŠ¥å‘Šï¼‰
0 * * * * cd $PROJECT_ROOT && ./cron_job/data_cleaning.sh validation_only

# ==================== å¯é€‰: ä½¿ç”¨æœ¬åœ° LLM ====================

# å¦‚æœä½¿ç”¨æœ¬åœ° LLMï¼Œè®¾ç½®ç¯å¢ƒå˜é‡
# USE_LOCAL_LLM=true

# ==================== å¯é€‰: ç›‘æ§æ¸…æ´—ä»»åŠ¡å¥åº·çŠ¶æ€ ====================

# æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡æ¸…æ´—ä»»åŠ¡æ˜¯å¦æ­£å¸¸
0 * * * * cd $PROJECT_ROOT && ./cron_job/check_cleaning_health.sh
```

### Cron æ—¶é—´è¯´æ˜

| Cron è¡¨è¾¾å¼ | è¯´æ˜ | é¢‘ç‡ |
|------------|------|------|
| `0 2 * * 1-6` | å‘¨ä¸€åˆ°å‘¨å…­å‡Œæ™¨ 2 ç‚¹ | æ¯å¤©ï¼ˆå·¥ä½œæ—¥ï¼‰ |
| `0 3 * * 0` | å‘¨æ—¥å‡Œæ™¨ 3 ç‚¹ | æ¯å‘¨ |
| `0 * * * *` | æ¯å°æ—¶æ•´ç‚¹ | æ¯å°æ—¶ |
| `*/30 * * * *` | æ¯ 30 åˆ†é’Ÿ | æ¯åŠå°æ—¶ |
| `0 0 1 * *` | æ¯æœˆ 1 å·å‡Œæ™¨ | æ¯æœˆ |

### è°ƒåº¦ç­–ç•¥å»ºè®®

#### å°å‹é¡¹ç›®ï¼ˆ< 10,000 authorshipsï¼‰

```bash
# æ¯å¤©å…¨é‡æ¸…æ´—
0 2 * * * ./cron_job/data_cleaning.sh full
```

#### ä¸­å‹é¡¹ç›®ï¼ˆ10,000 - 100,000 authorshipsï¼‰

```bash
# æ¯å¤©å¢é‡æ¸…æ´—
0 2 * * * ./cron_job/data_cleaning.sh incremental

# æ¯å‘¨å…¨é‡æ¸…æ´—
0 3 * * 0 ./cron_job/data_cleaning.sh full
```

#### å¤§å‹é¡¹ç›®ï¼ˆ> 100,000 authorshipsï¼‰

```bash
# æ¯å¤©å¢é‡æ¸…æ´—ï¼ˆæœ€è¿‘ 3 å¤©ï¼‰
0 2 * * * ./cron_job/data_cleaning.sh incremental

# æ¯å‘¨å¢é‡æ¸…æ´—ï¼ˆæœ€è¿‘ 30 å¤©ï¼‰
0 3 * * 0 INCREMENTAL_DAYS=30 ./cron_job/data_cleaning.sh incremental

# æ¯æœˆå…¨é‡æ¸…æ´—
0 4 1 * * ./cron_job/data_cleaning.sh full
```

---

## æ—¥å¿—ç®¡ç†

### æ—¥å¿—ç»“æ„

```
logs/cleaning/
â”œâ”€â”€ cleaning_incremental_20260127_020000.log
â”œâ”€â”€ cleaning_incremental_20260128_020000.log
â”œâ”€â”€ cleaning_full_20260126_030000.log
â”œâ”€â”€ cleaning_validation_only_20260127_100000.log
â””â”€â”€ ...
```

### æ—¥å¿—æ ¼å¼

```
================================================================================
ğŸ§¹ æ•°æ®è´¨é‡æ¸…æ´—ä»»åŠ¡å¼€å§‹
   æ¨¡å¼: incremental
   ä½¿ç”¨æœ¬åœ° LLM: False
   è¯•è¿è¡Œ: False
   å¼€å§‹æ—¶é—´: 2026-01-27 02:00:00
================================================================================

ğŸ” Step 1: Selecting authorships to check...
   Selected 1,234 authorships (from last 7 days)

ğŸ” Step 2: Detecting errors...
   Running ExtractionQualityDetector...
   Running GeocodingQualityDetector...
   Running ConsistencyDetector...
   Detected 156 errors

ğŸ“Š Step 3: Classifying errors...
   Error distribution:
   - extraction_error: 89 (57.1%)
   - geocoding_error: 54 (34.6%)
   - consistency_error: 13 (8.3%)

ğŸ’¾ Step 4: Recording errors...
   Recorded 156 errors to database

ğŸ”§ Step 5: Fixing errors...
   Fixing extraction errors: 89
   Using OpenAI GPT-4 for re-extraction...
   Fixed 76/89 (85.4%)
   
   Fixing geocoding errors: 54
   Retrying geocoding...
   Fixed 48/54 (88.9%)

ğŸ“ Step 6: Generating report...
   Report saved to batch clean_20260127_020000

================================================================================
âœ… æ•°æ®è´¨é‡æ¸…æ´—ä»»åŠ¡å®Œæˆ
   ç»“æŸæ—¶é—´: 2026-01-27 02:15:32
   æ€»è€—æ—¶: 932.4 ç§’ (15.5 åˆ†é’Ÿ)
================================================================================
```

### æ—¥å¿—æ¸…ç†

è‡ªåŠ¨åˆ é™¤ 7 å¤©å‰çš„æ—¥å¿—ï¼š

```bash
# åœ¨ data_cleaning.sh ä¸­å·²åŒ…å«
find "$LOG_DIR" -name "cleaning_*.log" -mtime +7 -delete
```

æ‰‹åŠ¨æ¸…ç†ï¼š

```bash
# åˆ é™¤ 30 å¤©å‰çš„æ—¥å¿—
find logs/cleaning/ -name "*.log" -mtime +30 -delete

# åˆ é™¤å¤§äº 100MB çš„æ—¥å¿—
find logs/cleaning/ -name "*.log" -size +100M -delete
```

---

## ç›‘æ§å’Œå‘Šè­¦

### 1. å¥åº·æ£€æŸ¥è„šæœ¬

**æ–‡ä»¶**: `cron_job/check_cleaning_health.sh`

```bash
#!/bin/bash
#
# æ£€æŸ¥æ•°æ®æ¸…æ´—ä»»åŠ¡çš„å¥åº·çŠ¶æ€
#

PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
PYTHON="${PROJECT_ROOT}/venv/bin/python"

# è¿è¡Œå¥åº·æ£€æŸ¥
$PYTHON <<EOF
import sys
sys.path.insert(0, "$PROJECT_ROOT")

from backend.app.cleaning.monitoring.health_check import check_cleaning_health
import asyncio

async def main():
    health = await check_cleaning_health()
    
    if not health['healthy']:
        print(f"âŒ æ¸…æ´—ä»»åŠ¡ä¸å¥åº·: {health['reason']}")
        # å‘é€å‘Šè­¦
        return 1
    
    print(f"âœ… æ¸…æ´—ä»»åŠ¡å¥åº·")
    return 0

exit_code = asyncio.run(main())
sys.exit(exit_code)
EOF
```

**å¥åº·æ£€æŸ¥é€»è¾‘**:

```python
# backend/app/cleaning/monitoring/health_check.py

async def check_cleaning_health() -> Dict:
    """æ£€æŸ¥æ¸…æ´—ä»»åŠ¡å¥åº·çŠ¶æ€"""
    
    # 1. æ£€æŸ¥æœ€è¿‘çš„æ‰¹æ¬¡
    recent_batch = await get_most_recent_batch()
    
    if not recent_batch:
        return {
            'healthy': False,
            'reason': 'No recent batch found'
        }
    
    # 2. æ£€æŸ¥æ‰¹æ¬¡æ˜¯å¦å¤ªä¹…è¿œï¼ˆè¶…è¿‡ 2 å¤©ï¼‰
    age = datetime.now() - recent_batch.completed_at
    if age.total_seconds() > 2 * 24 * 3600:
        return {
            'healthy': False,
            'reason': f'Last batch was {age.days} days ago'
        }
    
    # 3. æ£€æŸ¥é”™è¯¯ç‡æ˜¯å¦è¿‡é«˜
    if recent_batch.errors_detected / recent_batch.total_authorships_checked > 0.3:
        return {
            'healthy': False,
            'reason': f'Error rate too high: {recent_batch.errors_detected / recent_batch.total_authorships_checked:.1%}'
        }
    
    # 4. æ£€æŸ¥ä¿®å¤æˆåŠŸç‡æ˜¯å¦è¿‡ä½
    if recent_batch.fix_success_rate < 0.7:
        return {
            'healthy': False,
            'reason': f'Fix success rate too low: {recent_batch.fix_success_rate:.1%}'
        }
    
    return {
        'healthy': True,
        'reason': 'All checks passed'
    }
```

### 2. å‘Šè­¦é€šçŸ¥

#### é‚®ä»¶å‘Šè­¦

```python
# backend/app/cleaning/notifications/email_notifier.py

import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

async def send_alert_email(subject: str, body: str):
    """å‘é€å‘Šè­¦é‚®ä»¶"""
    
    msg = MIMEMultipart()
    msg['From'] = 'noreply@scholarmap.com'
    msg['To'] = 'admin@scholarmap.com'
    msg['Subject'] = f'[ScholarMap Alert] {subject}'
    
    msg.attach(MIMEText(body, 'plain'))
    
    # å‘é€é‚®ä»¶
    with smtplib.SMTP('smtp.gmail.com', 587) as server:
        server.starttls()
        server.login('user', 'password')
        server.send_message(msg)
```

#### Slack å‘Šè­¦ï¼ˆå¯é€‰ï¼‰

```python
# backend/app/cleaning/notifications/slack_notifier.py

import httpx

async def send_slack_alert(message: str):
    """å‘é€ Slack å‘Šè­¦"""
    
    webhook_url = os.getenv('SLACK_WEBHOOK_URL')
    
    payload = {
        'text': message,
        'channel': '#data-quality',
        'username': 'Data Cleaning Bot',
        'icon_emoji': ':broom:'
    }
    
    async with httpx.AsyncClient() as client:
        await client.post(webhook_url, json=payload)
```

---

## æ•…éšœæ’é™¤

### é—®é¢˜ 1: Cron ä»»åŠ¡æ²¡æœ‰è¿è¡Œ

**ç—‡çŠ¶**: æ—¥å¿—ä¸­æ²¡æœ‰æ–°çš„æ¸…æ´—è®°å½•

**æ’æŸ¥æ­¥éª¤**:

1. æ£€æŸ¥ Cron æ˜¯å¦åœ¨è¿è¡Œ
   ```bash
   sudo systemctl status cron  # Linux
   # æˆ–
   sudo launchctl list | grep cron  # macOS
   ```

2. æ£€æŸ¥ Crontab é…ç½®
   ```bash
   crontab -l
   ```

3. æ£€æŸ¥ Cron æ—¥å¿—
   ```bash
   tail -f /var/log/syslog | grep CRON  # Linux
   # æˆ–
   tail -f /var/log/system.log | grep cron  # macOS
   ```

4. æ‰‹åŠ¨è¿è¡Œè„šæœ¬æµ‹è¯•
   ```bash
   cd /app/scholarmap
   ./cron_job/data_cleaning.sh incremental
   ```

### é—®é¢˜ 2: æ¸…æ´—ä»»åŠ¡å¤±è´¥

**ç—‡çŠ¶**: æ—¥å¿—æ˜¾ç¤ºé”™è¯¯æˆ–å¼‚å¸¸é€€å‡º

**æ’æŸ¥æ­¥éª¤**:

1. æŸ¥çœ‹æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶
   ```bash
   tail -100 logs/cleaning/cleaning_*.log | less
   ```

2. æ£€æŸ¥æ•°æ®åº“è¿æ¥
   ```bash
   psql $DATABASE_URL -c "SELECT 1"
   ```

3. æ£€æŸ¥ Python ç¯å¢ƒ
   ```bash
   ./venv/bin/python --version
   ./venv/bin/pip list | grep sqlalchemy
   ```

4. ä»¥è°ƒè¯•æ¨¡å¼è¿è¡Œ
   ```bash
   export DEBUG=1
   ./cron_job/data_cleaning.sh incremental
   ```

### é—®é¢˜ 3: æœ¬åœ° LLM æ— æ³•è¿æ¥

**ç—‡çŠ¶**: é”™è¯¯ä¿¡æ¯åŒ…å« "Failed to connect to Ollama"

**æ’æŸ¥æ­¥éª¤**:

1. æ£€æŸ¥ Ollama æœåŠ¡æ˜¯å¦è¿è¡Œ
   ```bash
   ps aux | grep ollama
   curl http://localhost:11434/api/version
   ```

2. å¯åŠ¨ Ollama æœåŠ¡
   ```bash
   ollama serve
   ```

3. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½
   ```bash
   ollama list
   ```

4. ä¸‹è½½æ¨¡å‹
   ```bash
   ollama pull llama3.1:8b
   ```

### é—®é¢˜ 4: å†…å­˜ä¸è¶³

**ç—‡çŠ¶**: è¿›ç¨‹è¢« OOM killer ç»ˆæ­¢

**è§£å†³æ–¹æ¡ˆ**:

1. å‡å°æ‰¹æ¬¡å¤§å°
   ```bash
   ./cron_job/data_cleaning.py --mode incremental --batch-size 10
   ```

2. é™åˆ¶å¤„ç†çš„é”™è¯¯æ•°é‡
   ```bash
   ./cron_job/data_cleaning.py --mode incremental --max-errors 100
   ```

3. å¢åŠ ç³»ç»Ÿå†…å­˜æˆ–ä½¿ç”¨ swap

---

## ç‰ˆæœ¬å†å²

- **v1.0** (2026-01-27): åˆå§‹ Cron é…ç½®æ–‡æ¡£
  - ä¸‰ç§è¿è¡Œæ¨¡å¼
  - è°ƒåº¦ç­–ç•¥
  - æ—¥å¿—ç®¡ç†
  - ç›‘æ§å’Œå‘Šè­¦
  - æ•…éšœæ’é™¤
