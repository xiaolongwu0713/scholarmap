# æ•°æ®è´¨é‡æ¸…æ´—ç³»ç»Ÿ - ä¿®å¤ç­–ç•¥è¯¦è§£

## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [ä¿®å¤ç­–ç•¥ 1: LLM é‡æ–°æå–](#ä¿®å¤ç­–ç•¥-1-llm-é‡æ–°æå–)
- [ä¿®å¤ç­–ç•¥ 2: Geocoding é‡è¯•å’ŒéªŒè¯](#ä¿®å¤ç­–ç•¥-2-geocoding-é‡è¯•å’ŒéªŒè¯)
- [ä¿®å¤ç­–ç•¥ 3: è§„åˆ™ä¿®æ­£](#ä¿®å¤ç­–ç•¥-3-è§„åˆ™ä¿®æ­£)
- [æœ¬åœ° LLM é›†æˆ](#æœ¬åœ°-llm-é›†æˆ)
- [ä¿®å¤éªŒè¯](#ä¿®å¤éªŒè¯)

---

## æ¦‚è¿°

æ•°æ®ä¿®å¤ç³»ç»Ÿæ ¹æ®é”™è¯¯ç±»å‹é€‰æ‹©ä¸åŒçš„ä¿®å¤ç­–ç•¥ï¼š

1. **LLM é‡æ–°æå–**ï¼šç”¨äºæå–é”™è¯¯
2. **Geocoding é‡è¯•**ï¼šç”¨äº geocoding é”™è¯¯
3. **è§„åˆ™ä¿®æ­£**ï¼šç”¨äºç®€å•çš„ã€å¯é¢„æµ‹çš„é”™è¯¯

ä¿®å¤æµç¨‹ï¼š

```
é”™è¯¯è®°å½•
  â”‚
  â”œâ”€> æŒ‰é”™è¯¯ç±»å‹åˆ†ç»„
  â”‚
  â”œâ”€> extraction_error â†’ LLM é‡æ–°æå–
  â”‚
  â”œâ”€> geocoding_error â†’ Geocoding é‡è¯•/éªŒè¯
  â”‚
  â”œâ”€> consistency_error â†’ è§„åˆ™ä¿®æ­£
  â”‚
  â””â”€> éªŒè¯ä¿®å¤ç»“æœ â†’ æ›´æ–°æ•°æ®åº“
```

---

## ä¿®å¤ç­–ç•¥ 1: LLM é‡æ–°æå–

### é€‚ç”¨åœºæ™¯

- å·ç¼©å†™ä½œä¸ºåŸå¸‚ï¼ˆstate_as_cityï¼‰
- æœºæ„åä½œä¸ºåŸå¸‚ï¼ˆinstitution_as_cityï¼‰
- éƒ¨é—¨åä½œä¸ºåŸå¸‚ï¼ˆdepartment_as_cityï¼‰
- ä½ç½®ä¿¡åº¦ï¼ˆlow_confidenceï¼‰
- ç¼ºå¤±åœ°ç†æ•°æ®ï¼ˆmissing_geo_dataï¼‰

### DataFixer å®ç°

```python
# backend/app/cleaning/fixers/data_fixer.py

from typing import List, Dict
from backend.app.cleaning.models import ErrorRecord, FixResult
from backend.app.phase2.affiliation_extractor import AffiliationExtractor
from backend.app.cleaning.llm.local_llm import LocalLLM
from backend.app.phase2.pg_geocoding import PostgresGeocoder

class DataFixer:
    """æ•°æ®ä¿®å¤å™¨"""
    
    def __init__(self, use_local_llm: bool = False):
        if use_local_llm:
            self.llm_extractor = LocalLLM()
        else:
            self.llm_extractor = AffiliationExtractor()
        
        self.geocoder = PostgresGeocoder()
        self.use_local_llm = use_local_llm
    
    async def fix_errors(
        self,
        errors: List[ErrorRecord]
    ) -> List[FixResult]:
        """æ‰¹é‡ä¿®å¤é”™è¯¯"""
        results = []
        
        # æŒ‰é”™è¯¯ç±»å‹åˆ†ç»„
        grouped = self._group_by_error_type(errors)
        
        # 1. ä¿®å¤æå–é”™è¯¯ -> ä½¿ç”¨ LLM é‡æ–°æå–
        if 'extraction_error' in grouped:
            extraction_results = await self._fix_extraction_errors(
                grouped['extraction_error']
            )
            results.extend(extraction_results)
        
        # 2. ä¿®å¤ geocoding é”™è¯¯ -> é‡è¯•æˆ–ä½¿ç”¨æ›¿ä»£ç­–ç•¥
        if 'geocoding_error' in grouped:
            geocoding_results = await self._fix_geocoding_errors(
                grouped['geocoding_error']
            )
            results.extend(geocoding_results)
        
        # 3. ä¿®å¤ä¸€è‡´æ€§é”™è¯¯ -> ä½¿ç”¨è§„åˆ™ä¿®æ­£
        if 'consistency_error' in grouped:
            consistency_results = await self._fix_consistency_errors(
                grouped['consistency_error']
            )
            results.extend(consistency_results)
        
        return results
    
    async def _fix_extraction_errors(
        self,
        errors: List[ErrorRecord]
    ) -> List[FixResult]:
        """ä¿®å¤æå–é”™è¯¯"""
        # æ”¶é›†å”¯ä¸€çš„ affiliations
        affiliation_to_errors = {}
        for error in errors:
            aff = error.original_affiliation
            if aff not in affiliation_to_errors:
                affiliation_to_errors[aff] = []
            affiliation_to_errors[aff].append(error)
        
        unique_affiliations = list(affiliation_to_errors.keys())
        
        logger.info(f"ğŸ”§ Fixing {len(unique_affiliations)} unique affiliations with LLM...")
        logger.info(f"   Using {'local LLM' if self.use_local_llm else 'OpenAI'}")
        
        # æ‰¹é‡è°ƒç”¨ LLM
        llm_results = await self.llm_extractor.extract_batch(
            unique_affiliations,
            batch_size=20
        )
        
        # å¤„ç†æ¯ä¸ª affiliation çš„ä¿®å¤ç»“æœ
        fix_results = []
        
        for affiliation, geo_data in llm_results.items():
            errors_for_aff = affiliation_to_errors[affiliation]
            
            # éªŒè¯ LLM ç»“æœ
            if not self._validate_llm_result(geo_data):
                # LLM ç»“æœä¹Ÿä¸åˆæ³•
                for error in errors_for_aff:
                    fix_results.append(FixResult(
                        error_id=error.id,
                        success=False,
                        fix_method='llm_openai' if not self.use_local_llm else 'llm_local',
                        failure_reason='LLM result failed validation'
                    ))
                continue
            
            # é‡æ–° geocoding
            coords = await self.geocoder.get_coordinates(
                geo_data.country,
                geo_data.city
            )
            
            # éªŒè¯åæ ‡
            if coords:
                coords_valid = await self._validate_coordinates(
                    coords[0], coords[1],
                    geo_data.country, geo_data.city
                )
            else:
                coords_valid = False
            
            # è®°å½•ä¿®å¤ç»“æœ
            for error in errors_for_aff:
                if coords and coords_valid:
                    fix_results.append(FixResult(
                        error_id=error.id,
                        success=True,
                        fix_method='llm_openai' if not self.use_local_llm else 'llm_local',
                        fixed_country=geo_data.country,
                        fixed_city=geo_data.city,
                        fixed_institution=geo_data.institution,
                        fixed_coordinates={'lat': coords[0], 'lng': coords[1]}
                    ))
                else:
                    fix_results.append(FixResult(
                        error_id=error.id,
                        success=False,
                        fix_method='llm_openai' if not self.use_local_llm else 'llm_local',
                        failure_reason='Geocoding failed' if not coords else 'Coordinates validation failed',
                        fixed_country=geo_data.country,
                        fixed_city=geo_data.city,
                        fixed_institution=geo_data.institution
                    ))
            
            # æ›´æ–°æ•°æ®åº“
            if coords and coords_valid:
                await self._update_database(
                    affiliation, geo_data, coords, errors_for_aff
                )
        
        return fix_results
    
    def _validate_llm_result(self, geo_data) -> bool:
        """éªŒè¯ LLM æå–ç»“æœ"""
        # åº”ç”¨ç›¸åŒçš„éªŒè¯è§„åˆ™
        city = geo_data.city
        
        # æ£€æŸ¥å·ç¼©å†™
        if self._is_state_abbreviation(city):
            return False
        
        # æ£€æŸ¥æœºæ„å…³é”®è¯
        if self._contains_institution_keywords(city):
            return False
        
        # æ£€æŸ¥éƒ¨é—¨å…³é”®è¯
        if city and any(city.lower().startswith(kw) for kw in ['department', 'division', 'section']):
            return False
        
        # æ£€æŸ¥åŒ…å«æ•°å­—
        if city and any(c.isdigit() for c in city):
            return False
        
        # æ£€æŸ¥è¿‡çŸ­
        if city and len(city) <= 2:
            return False
        
        return True
    
    async def _update_database(
        self,
        affiliation: str,
        geo_data,
        coords: Tuple[float, float],
        errors: List[ErrorRecord]
    ):
        """æ›´æ–°æ•°æ®åº“"""
        # 1. æ›´æ–° affiliation_cache
        await self.affiliation_cache_repo.upsert({
            'affiliation_raw': affiliation,
            'country': geo_data.country,
            'city': geo_data.city,
            'institution': geo_data.institution,
            'confidence': geo_data.confidence
        })
        
        # 2. æ›´æ–° geocoding_cache
        location_key = self._make_location_key(geo_data.country, geo_data.city)
        await self.geocoding_cache_repo.upsert({
            'location_key': location_key,
            'latitude': coords[0],
            'longitude': coords[1]
        })
        
        # 3. æ›´æ–°æ‰€æœ‰ç›¸å…³çš„ authorships
        authorship_ids = [error.authorship_id for error in errors]
        await self.authorship_repo.batch_update(
            authorship_ids,
            {
                'country': geo_data.country,
                'city': geo_data.city,
                'institution': geo_data.institution,
                'affiliation_confidence': geo_data.confidence
            }
        )
    
    def _group_by_error_type(
        self,
        errors: List[ErrorRecord]
    ) -> Dict[str, List[ErrorRecord]]:
        """æŒ‰é”™è¯¯ç±»å‹åˆ†ç»„"""
        grouped = {}
        for error in errors:
            if error.error_type not in grouped:
                grouped[error.error_type] = []
            grouped[error.error_type].append(error)
        return grouped
```

### LLM æå–æµç¨‹

```
å”¯ä¸€çš„ affiliations
  â”‚
  â”œâ”€> æ‰¹é‡è°ƒç”¨ LLMï¼ˆbatch_size=20ï¼‰
  â”‚   â”œâ”€ OpenAI GPT-4 æˆ–
  â”‚   â””â”€ æœ¬åœ° Ollamaï¼ˆLlama 3.1ï¼‰
  â”‚
  â”œâ”€> è§£æ LLM è¿”å›çš„ JSON
  â”‚
  â”œâ”€> éªŒè¯æå–ç»“æœ
  â”‚   â”œâ”€ æ£€æŸ¥å·ç¼©å†™
  â”‚   â”œâ”€ æ£€æŸ¥æœºæ„å…³é”®è¯
  â”‚   â””â”€ æ£€æŸ¥å…¶ä»–è§„åˆ™
  â”‚
  â”œâ”€> é‡æ–° Geocoding
  â”‚   â””â”€> éªŒè¯åæ ‡
  â”‚
  â””â”€> æ›´æ–°æ•°æ®åº“
      â”œâ”€ affiliation_cache
      â”œâ”€ geocoding_cache
      â””â”€ authorship
```

---

## ä¿®å¤ç­–ç•¥ 2: Geocoding é‡è¯•å’ŒéªŒè¯

### é€‚ç”¨åœºæ™¯

- Geocoding nullï¼ˆgeocoding_nullï¼‰
- åæ ‡é”™è¯¯ï¼ˆwrong_coordinatesï¼‰
- åæ ‡å¼‚å¸¸ï¼ˆcoordinate_anomalyï¼‰

### å®ç°

```python
# backend/app/cleaning/fixers/data_fixer.py (ç»­)

class DataFixer:
    # ... å‰é¢çš„ä»£ç  ...
    
    async def _fix_geocoding_errors(
        self,
        errors: List[ErrorRecord]
    ) -> List[FixResult]:
        """ä¿®å¤ geocoding é”™è¯¯"""
        fix_results = []
        
        for error in errors:
            country = error.original_country
            city = error.original_city
            
            if not country:
                # æ— å›½å®¶ä¿¡æ¯ï¼Œæ— æ³•ä¿®å¤
                fix_results.append(FixResult(
                    error_id=error.id,
                    success=False,
                    fix_method='geocoding_retry',
                    failure_reason='Missing country information'
                ))
                continue
            
            # ç­–ç•¥ 1: ç›´æ¥é‡è¯•ï¼ˆå¯èƒ½ä¹‹å‰ Nominatim ä¸´æ—¶æ•…éšœï¼‰
            coords = await self.geocoder.get_coordinates(country, city, force_refresh=True)
            
            if not coords:
                # ç­–ç•¥ 2: å°è¯•ä¸åŒçš„æŸ¥è¯¢æ ¼å¼
                coords = await self._try_alternative_geocoding(country, city)
            
            if coords:
                # éªŒè¯åæ ‡
                coords_valid = await self._validate_coordinates(
                    coords[0], coords[1], country, city
                )
                
                if coords_valid:
                    # ä¿®å¤æˆåŠŸ
                    fix_results.append(FixResult(
                        error_id=error.id,
                        success=True,
                        fix_method='geocoding_retry',
                        fixed_coordinates={'lat': coords[0], 'lng': coords[1]}
                    ))
                    
                    # æ›´æ–° geocoding_cache
                    location_key = self._make_location_key(country, city)
                    await self.geocoding_cache_repo.upsert({
                        'location_key': location_key,
                        'latitude': coords[0],
                        'longitude': coords[1]
                    })
                else:
                    # åæ ‡éªŒè¯å¤±è´¥
                    fix_results.append(FixResult(
                        error_id=error.id,
                        success=False,
                        fix_method='geocoding_retry',
                        failure_reason='Coordinates validation failed'
                    ))
            else:
                # æ— æ³•è·å–åæ ‡ï¼Œå¯èƒ½éœ€è¦ LLM é‡æ–°æå–
                fix_results.append(FixResult(
                    error_id=error.id,
                    success=False,
                    fix_method='geocoding_retry',
                    failure_reason='Geocoding failed after retry'
                ))
        
        return fix_results
    
    async def _try_alternative_geocoding(
        self,
        country: str,
        city: str | None
    ) -> Tuple[float, float] | None:
        """å°è¯•æ›¿ä»£çš„ geocoding ç­–ç•¥"""
        # ç­–ç•¥ 1: æ·»åŠ å›½å®¶ååˆ°åŸå¸‚æŸ¥è¯¢
        if city:
            query = f"{city}, {country}"
            coords = await self._geocode_query(query)
            if coords:
                return coords
        
        # ç­–ç•¥ 2: åªä½¿ç”¨å›½å®¶
        coords = await self._geocode_query(country)
        if coords:
            return coords
        
        # ç­–ç•¥ 3: ä½¿ç”¨å›½å®¶çš„åˆ«å
        country_aliases = self._get_country_aliases(country)
        for alias in country_aliases:
            if city:
                query = f"{city}, {alias}"
            else:
                query = alias
            
            coords = await self._geocode_query(query)
            if coords:
                return coords
        
        return None
    
    def _get_country_aliases(self, country: str) -> List[str]:
        """è·å–å›½å®¶çš„åˆ«å"""
        aliases_map = {
            'United States': ['USA', 'US', 'United States of America'],
            'United Kingdom': ['UK', 'Great Britain', 'Britain'],
            'South Korea': ['Korea', 'Republic of Korea', 'ROK'],
            'China': ['PRC', 'People\'s Republic of China'],
            # ... æ›´å¤šåˆ«å
        }
        return aliases_map.get(country, [])
```

### Geocoding ä¿®å¤æµç¨‹

```
Geocoding é”™è¯¯
  â”‚
  â”œâ”€> ç­–ç•¥ 1: ç›´æ¥é‡è¯•ï¼ˆforce_refresh=Trueï¼‰
  â”‚
  â”œâ”€> ç­–ç•¥ 2: å°è¯•ä¸åŒæŸ¥è¯¢æ ¼å¼
  â”‚   â”œâ”€ "{city}, {country}"
  â”‚   â”œâ”€ "{country}" only
  â”‚   â””â”€ ä½¿ç”¨å›½å®¶åˆ«å
  â”‚
  â”œâ”€> éªŒè¯åæ ‡ï¼ˆåå‘ geocodingï¼‰
  â”‚
  â””â”€> æ›´æ–° geocoding_cache
```

---

## ä¿®å¤ç­–ç•¥ 3: è§„åˆ™ä¿®æ­£

### é€‚ç”¨åœºæ™¯

æŸäº›ç®€å•çš„ã€å¯é¢„æµ‹çš„é”™è¯¯å¯ä»¥ç”¨è§„åˆ™ç›´æ¥ä¿®æ­£ï¼Œæ— éœ€ LLMï¼š

- å·²çŸ¥çš„å·ç¼©å†™ â†’ åŸå¸‚æ˜ å°„
- å¸¸è§çš„æœºæ„ç¼©å†™ â†’ å…¨å

### å®ç°

```python
# backend/app/cleaning/fixers/rule_fixer.py

class RuleFixer:
    """åŸºäºè§„åˆ™çš„ä¿®å¤å™¨"""
    
    # å·ç¼©å†™ â†’ é¦–åºœ/æœ€å¤§åŸå¸‚æ˜ å°„
    STATE_TO_CITY = {
        'MA': ('Boston', 'United States'),
        'CA': ('Los Angeles', 'United States'),
        'NY': ('New York', 'United States'),
        'TX': ('Houston', 'United States'),
        # ... æ›´å¤šæ˜ å°„
    }
    
    def can_fix_with_rules(self, error: ErrorRecord) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¯ä»¥ç”¨è§„åˆ™ä¿®å¤"""
        if error.error_category == 'state_as_city':
            return error.original_city in self.STATE_TO_CITY
        return False
    
    def fix_with_rules(self, error: ErrorRecord) -> FixResult:
        """ä½¿ç”¨è§„åˆ™ä¿®å¤"""
        if error.error_category == 'state_as_city':
            city, country = self.STATE_TO_CITY[error.original_city]
            return FixResult(
                error_id=error.id,
                success=True,
                fix_method='rule_correction',
                fixed_city=city,
                fixed_country=country
            )
        
        return FixResult(
            error_id=error.id,
            success=False,
            fix_method='rule_correction',
            failure_reason='No rule available'
        )
```

---

## æœ¬åœ° LLM é›†æˆ

### Ollama å®‰è£…å’Œé…ç½®

#### 1. å®‰è£… Ollama

```bash
# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.com/install.sh | sh

# å¯åŠ¨ Ollama æœåŠ¡
ollama serve
```

#### 2. ä¸‹è½½æ¨¡å‹

```bash
# æ¨èï¼šLlama 3.1 8Bï¼ˆå¹³è¡¡æ€§èƒ½å’Œå‡†ç¡®åº¦ï¼‰
ollama pull llama3.1:8b

# æˆ–è€…ï¼šMistral 7Bï¼ˆæ›´å¿«ï¼‰
ollama pull mistral:7b

# æˆ–è€…ï¼šQwen 2.5 7Bï¼ˆä¸­æ–‡æ”¯æŒæ›´å¥½ï¼‰
ollama pull qwen2.5:7b
```

### LocalLLM å®ç°

```python
# backend/app/cleaning/llm/local_llm.py

import httpx
import asyncio
import json
from typing import List, Dict

class LocalLLM:
    """æœ¬åœ° LLM æå–å™¨ï¼ˆä½¿ç”¨ Ollamaï¼‰"""
    
    def __init__(self, model: str = "llama3.1:8b", base_url: str = "http://localhost:11434"):
        self.model = model
        self.base_url = base_url
    
    async def extract_batch(
        self,
        affiliations: List[str],
        batch_size: int = 10
    ) -> Dict[str, 'GeoData']:
        """æ‰¹é‡æå–åœ°ç†ä¿¡æ¯"""
        results = {}
        
        for i in range(0, len(affiliations), batch_size):
            batch = affiliations[i:i+batch_size]
            
            # æ„å»º prompt
            prompt = self._build_prompt(batch)
            
            # è°ƒç”¨ Ollama API
            try:
                response_text = await self._call_ollama(prompt)
                
                # è§£æç»“æœ
                parsed = self._parse_response(response_text, batch)
                results.update(parsed)
                
            except Exception as e:
                logger.error(f"Local LLM extraction failed for batch: {e}")
                # å¯¹å¤±è´¥çš„ batch è¿”å›ç©ºç»“æœ
                for aff in batch:
                    results[aff] = GeoData(
                        country=None,
                        city=None,
                        institution=None,
                        confidence='none'
                    )
            
            # æœ¬åœ° LLM ä¸éœ€è¦ä¸¥æ ¼çš„ rate limiting
            await asyncio.sleep(0.5)
        
        return results
    
    def _build_prompt(self, affiliations: List[str]) -> str:
        """æ„å»º prompt"""
        # è¯»å– prompt æ¨¡æ¿
        with open('prompts/affiliation_extraction.md', 'r') as f:
            template = f.read()
        
        # æ ¼å¼åŒ– affiliations
        aff_list = "\n".join([f"{i+1}. {aff}" for i, aff in enumerate(affiliations)])
        
        prompt = template.replace("{{affiliations}}", aff_list)
        
        # æ·»åŠ  JSON æ ¼å¼è¦æ±‚
        prompt += "\n\nRespond with ONLY a JSON array, no other text. Format: [{\"country\": \"...\", \"city\": \"...\", \"institution\": \"...\"}, ...]"
        
        return prompt
    
    async def _call_ollama(self, prompt: str) -> str:
        """è°ƒç”¨ Ollama API"""
        url = f"{self.base_url}/api/generate"
        
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.1,  # ä½æ¸©åº¦ä»¥æé«˜ä¸€è‡´æ€§
                "top_p": 0.9,
            }
        }
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(url, json=payload)
            response.raise_for_status()
            
            data = response.json()
            return data['response']
    
    def _parse_response(
        self,
        response_text: str,
        affiliations: List[str]
    ) -> Dict[str, 'GeoData']:
        """è§£æ LLM å“åº”"""
        # å°è¯•æå– JSON
        try:
            # æŸ¥æ‰¾ JSON æ•°ç»„
            start = response_text.find('[')
            end = response_text.rfind(']') + 1
            
            if start == -1 or end == 0:
                raise ValueError("No JSON array found in response")
            
            json_str = response_text[start:end]
            data = json.loads(json_str)
            
            # æ˜ å°„å› affiliations
            results = {}
            for i, aff in enumerate(affiliations):
                if i < len(data):
                    item = data[i]
                    results[aff] = GeoData(
                        country=item.get('country'),
                        city=item.get('city'),
                        institution=item.get('institution'),
                        confidence='high'  # æœ¬åœ° LLM çš„ç½®ä¿¡åº¦é»˜è®¤ä¸º high
                    )
                else:
                    results[aff] = GeoData(
                        country=None,
                        city=None,
                        institution=None,
                        confidence='none'
                    )
            
            return results
            
        except Exception as e:
            logger.error(f"Failed to parse LLM response: {e}")
            logger.debug(f"Response text: {response_text}")
            
            # è¿”å›ç©ºç»“æœ
            return {aff: GeoData(None, None, None, 'none') for aff in affiliations}
```

### é…ç½®é€‰æ‹©

```python
# backend/app/cleaning/config.py

class CleaningConfig:
    """æ¸…æ´—ä»»åŠ¡é…ç½®"""
    
    # LLM é…ç½®
    use_local_llm: bool = False  # æ˜¯å¦ä½¿ç”¨æœ¬åœ° LLM
    local_llm_model: str = "llama3.1:8b"  # æœ¬åœ° LLM æ¨¡å‹
    local_llm_url: str = "http://localhost:11434"  # Ollama API URL
    
    # OpenAI é…ç½®
    openai_api_key: str = ""  # ä»ç¯å¢ƒå˜é‡è¯»å–
    openai_model: str = "gpt-4"
    
    # Rate limiting
    rate_limit_delay: float = 2.0  # OpenAI çš„å»¶è¿Ÿ
    local_llm_delay: float = 0.5  # æœ¬åœ° LLM çš„å»¶è¿Ÿ
```

### æœ¬åœ° LLM vs OpenAI å¯¹æ¯”

| ç‰¹æ€§ | æœ¬åœ° LLM (Ollama) | OpenAI GPT-4 |
|------|-------------------|--------------|
| **æˆæœ¬** | ğŸŸ¢ å…è´¹ | ğŸ”´ æŒ‰ token è®¡è´¹ |
| **é€Ÿåº¦** | ğŸŸ¡ ä¸­ç­‰ï¼ˆå–å†³äºç¡¬ä»¶ï¼‰ | ğŸŸ¢ å¿« |
| **å‡†ç¡®åº¦** | ğŸŸ¡ è‰¯å¥½ï¼ˆ~90%ï¼‰ | ğŸŸ¢ ä¼˜ç§€ï¼ˆ~95%ï¼‰ |
| **éšç§** | ğŸŸ¢ æ•°æ®ä¸ç¦»å¼€æœ¬åœ° | ğŸ”´ æ•°æ®å‘é€åˆ° OpenAI |
| **é™åˆ¶** | ğŸŸ¢ æ—  API é™åˆ¶ | ğŸ”´ æœ‰ rate limit |
| **ç¡¬ä»¶è¦æ±‚** | ğŸ”´ éœ€è¦ GPUï¼ˆæ¨èï¼‰ | ğŸŸ¢ æ— è¦æ±‚ |

**å»ºè®®**ï¼š
- **å¼€å‘/æµ‹è¯•**ï¼šä½¿ç”¨æœ¬åœ° LLM
- **ç”Ÿäº§ç¯å¢ƒï¼ˆå°è§„æ¨¡ï¼‰**ï¼šä½¿ç”¨ OpenAI
- **ç”Ÿäº§ç¯å¢ƒï¼ˆå¤§è§„æ¨¡ï¼‰**ï¼šä½¿ç”¨æœ¬åœ° LLMï¼ˆæˆæœ¬æ•ˆç›Šï¼‰

---

## ä¿®å¤éªŒè¯

### éªŒè¯æµç¨‹

æ¯ä¸ªä¿®å¤ç»“æœéƒ½éœ€è¦ç»è¿‡éªŒè¯ï¼š

```python
class FixValidator:
    """ä¿®å¤éªŒè¯å™¨"""
    
    async def validate_fix(self, fix_result: FixResult) -> bool:
        """éªŒè¯ä¿®å¤ç»“æœ"""
        # 1. æ£€æŸ¥ä¿®å¤çš„æ•°æ®æ˜¯å¦åˆæ³•
        if not self._is_valid_geo_data(fix_result):
            return False
        
        # 2. æ£€æŸ¥åæ ‡æ˜¯å¦æœ‰æ•ˆ
        if fix_result.fixed_coordinates:
            if not self._is_valid_coordinates(fix_result.fixed_coordinates):
                return False
            
            # 3. åå‘ geocoding éªŒè¯
            if not await self._reverse_geocode_validate(fix_result):
                return False
        
        return True
    
    def _is_valid_geo_data(self, fix_result: FixResult) -> bool:
        """æ£€æŸ¥åœ°ç†æ•°æ®æ˜¯å¦åˆæ³•"""
        # åº”ç”¨ç›¸åŒçš„éªŒè¯è§„åˆ™
        city = fix_result.fixed_city
        
        if not city:
            return True  # å…è®¸åŸå¸‚ä¸ºç©º
        
        # æ£€æŸ¥å·ç¼©å†™
        if city.upper() in US_STATE_ABBRS:
            return False
        
        # æ£€æŸ¥æœºæ„å…³é”®è¯
        if any(kw in city.lower() for kw in INSTITUTION_KEYWORDS):
            return False
        
        return True
```

---

## ç‰ˆæœ¬å†å²

- **v1.0** (2026-01-27): åˆå§‹ä¿®å¤ç­–ç•¥è®¾è®¡
  - LLM é‡æ–°æå–
  - Geocoding é‡è¯•
  - è§„åˆ™ä¿®æ­£
  - æœ¬åœ° LLM æ”¯æŒ
